{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "学习 [简单粗暴 TensorFlow 2](https://tf.wiki/zh_hans/) (github页 https://github.com/snowkylin/tensorflow-handbook)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import datetime\n",
    "import os \n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_colwidth = 80\n",
    "pd.options.display.precision = 4\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.float_format = '{:.4f}'.format  # 防止科学计数法，小数显示4位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义一个随机数（标量）\n",
    "random_float = tf.random.uniform(shape=())\n",
    "\n",
    "# 定义一个有2个元素的零向量\n",
    "zero_vector = tf.zeros(shape=(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.6756563>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_float"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=float32, numpy=array([0., 0.], dtype=float32)>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "zero_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义两个2×2的常量矩阵\n",
    "A = tf.constant([[1., 2.], [3., 4.]])\n",
    "B = tf.constant([[5., 6.], [7., 8.]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2, 2)\n",
      "<dtype: 'float32'>\n",
      "[[1. 2.]\n",
      " [3. 4.]]\n"
     ]
    }
   ],
   "source": [
    "print(A.shape)\n",
    "print(A.dtype)\n",
    "print(A.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = tf.add(A, B)\n",
    "D = tf.matmul(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[ 6.,  8.],\n",
       "       [10., 12.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2, 2), dtype=float32, numpy=\n",
       "array([[19., 22.],\n",
       "       [43., 50.]], dtype=float32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C\n",
    "D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(9.0, shape=(), dtype=float32)\n",
      "tf.Tensor(6.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "x = tf.Variable(initial_value=3.)\n",
    "with tf.GradientTape() as tape:     # 在 tf.GradientTape() 的上下文内，所有计算步骤都会被记录以用于求导\n",
    "    y = tf.square(x)\n",
    "y_grad = tape.gradient(y, x)        # 计算y关于x的导数\n",
    "print(y, y_grad, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(125.0, shape=(), dtype=float32)\n",
      "tf.Tensor(\n",
      "[[ 70.]\n",
      " [100.]], shape=(2, 1), dtype=float32)\n",
      "tf.Tensor(30.0, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "X = tf.constant([[1., 2.], [3., 4.]])\n",
    "y = tf.constant([[1.], [2.]])\n",
    "w = tf.Variable(initial_value=[[1.], [2.]])\n",
    "b = tf.Variable(initial_value=1.)\n",
    "with tf.GradientTape() as tape:\n",
    "    L = tf.reduce_sum(tf.square(tf.matmul(X, w) + b - y))\n",
    "w_grad, b_grad = tape.gradient(L, [w, b])        # 计算L(w, b)关于w, b的偏导数\n",
    "print(L, w_grad, b_grad, sep = '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_raw = np.array([2013, 2014, 2015, 2016, 2017], dtype=np.float32)\n",
    "y_raw = np.array([12000, 14000, 15000, 16500, 17500], dtype=np.float32)\n",
    "\n",
    "X = (X_raw - X_raw.min()) / (X_raw.max() - X_raw.min())\n",
    "y = (y_raw - y_raw.min()) / (y_raw.max() - y_raw.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.  , 0.25, 0.5 , 0.75, 1.  ], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.36363637, 0.54545456, 0.8181818 , 1.        ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用Numpy线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9763702027872221 0.057564988311377796\n"
     ]
    }
   ],
   "source": [
    "a, b = 0, 0\n",
    "\n",
    "num_epoch = 10000\n",
    "learning_rate = 5e-4\n",
    "for e in range(num_epoch):\n",
    "    # 手动计算损失函数关于自变量（模型参数）的梯度\n",
    "    y_pred = a * X + b\n",
    "    grad_a, grad_b = 2 * (y_pred - y).dot(X), 2 * (y_pred - y).sum()\n",
    "\n",
    "    # 更新参数\n",
    "    a, b = a - learning_rate * grad_a, b - learning_rate * grad_b\n",
    "\n",
    "print(a, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 尝试Tensorflow线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tf.constant(X)\n",
    "y = tf.constant(y)\n",
    "\n",
    "a = tf.Variable(initial_value=0.)\n",
    "b = tf.Variable(initial_value=0.)\n",
    "variables = [a, b]\n",
    "\n",
    "num_epoch = 10000\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=5e-4)\n",
    "for e in range(num_epoch):\n",
    "    # 使用tf.GradientTape()记录损失函数的梯度信息\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = a * X + b\n",
    "        loss = tf.reduce_sum(tf.square(y_pred - y))\n",
    "    # TensorFlow自动计算损失函数关于自变量（模型参数）的梯度\n",
    "    grads = tape.gradient(loss, variables)\n",
    "    # TensorFlow自动根据梯度更新参数\n",
    "    _ = optimizer.apply_gradients(grads_and_vars=zip(grads, variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.97637>,\n",
       " <tf.Variable 'Variable:0' shape=() dtype=float32, numpy=0.057565063>]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 1\n",
    "d = 1 \n",
    "alist = [c, d]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = 2\n",
    "alist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model与Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Variable 'linear_1/dense_1/kernel:0' shape=(3, 1) dtype=float32, numpy=\n",
      "array([[4.8735565e-06],\n",
      "       [1.1111153e+00],\n",
      "       [2.2222164e+00]], dtype=float32)>, <tf.Variable 'linear_1/dense_1/bias:0' shape=(1,) dtype=float32, numpy=array([1.1111081], dtype=float32)>]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "X = tf.constant([[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]])\n",
    "y = tf.constant([[10.0], [20.0]])\n",
    "\n",
    "\n",
    "class Linear(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.dense = tf.keras.layers.Dense(\n",
    "            units=1,\n",
    "            activation=None,\n",
    "            kernel_initializer=tf.zeros_initializer(),\n",
    "            bias_initializer=tf.zeros_initializer()\n",
    "        )\n",
    "\n",
    "    def call(self, input):\n",
    "        output = self.dense(input)\n",
    "        return output\n",
    "\n",
    "\n",
    "# 以下代码结构与前节类似\n",
    "model = Linear()\n",
    "optimizer = tf.keras.optimizers.SGD(learning_rate=0.01)\n",
    "for i in range(10000):\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(X)      # 调用模型 y_pred = model(X) 而不是显式写出 y_pred = a * X + b\n",
    "        loss = tf.reduce_mean(tf.square(y_pred - y))\n",
    "    grads = tape.gradient(loss, model.variables)    # 使用 model.variables 这一属性直接获得模型中的所有变量\n",
    "    _ = optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))\n",
    "print(model.variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Variable 'UnreadVariable' shape=() dtype=int64, numpy=10000>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 基础示例：多层感知机(MLP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTLoader():\n",
    "    def __init__(self):\n",
    "        mnist = tf.keras.datasets.mnist\n",
    "        (self.train_data, self.train_label), (self.test_data, self.test_label) = mnist.load_data()\n",
    "        # MNIST中的图像默认为uint8（0-255的数字）。以下代码将其归一化到0-1之间的浮点数，并在最后增加一维作为颜色通道\n",
    "        self.train_data = np.expand_dims(self.train_data.astype(np.float32) / 255.0, axis=-1)      # [60000, 28, 28, 1]\n",
    "        self.test_data = np.expand_dims(self.test_data.astype(np.float32) / 255.0, axis=-1)        # [10000, 28, 28, 1]\n",
    "        self.train_label = self.train_label.astype(np.int32)    # [60000]\n",
    "        self.test_label = self.test_label.astype(np.int32)      # [10000]\n",
    "        self.num_train_data, self.num_test_data = self.train_data.shape[0], self.test_data.shape[0]\n",
    "\n",
    "    def get_batch(self, batch_size):\n",
    "        # 从数据集中随机取出batch_size个元素并返回\n",
    "        index = np.random.randint(0, self.num_train_data, batch_size)\n",
    "        return self.train_data[index, :], self.train_label[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.flatten = tf.keras.layers.Flatten()    # Flatten层将除第一维（batch_size）以外的维度展平\n",
    "        self.dense1 = tf.keras.layers.Dense(units=100, activation=tf.nn.relu)\n",
    "        self.dense2 = tf.keras.layers.Dense(units=10)\n",
    "\n",
    "    def call(self, inputs):         # [batch_size, 28, 28, 1]\n",
    "        x = self.flatten(inputs)    # [batch_size, 784]\n",
    "        x = self.dense1(x)          # [batch_size, 100]\n",
    "        x = self.dense2(x)          # [batch_size, 10]\n",
    "        output = tf.nn.softmax(x)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 5\n",
    "batch_size = 50\n",
    "learning_rate = 0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MLP()\n",
    "data_loader = MNISTLoader()\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 0: loss 0.027174\n",
      "batch 1: loss 0.053722\n",
      "batch 2: loss 0.037445\n",
      "batch 3: loss 0.040360\n",
      "batch 4: loss 0.113464\n",
      "batch 5: loss 0.101838\n",
      "batch 6: loss 0.056415\n",
      "batch 7: loss 0.039312\n",
      "batch 8: loss 0.053956\n",
      "batch 9: loss 0.021681\n",
      "batch 10: loss 0.085016\n",
      "batch 11: loss 0.004939\n",
      "batch 12: loss 0.019586\n",
      "batch 13: loss 0.017728\n",
      "batch 14: loss 0.035495\n",
      "batch 15: loss 0.027303\n",
      "batch 16: loss 0.026122\n",
      "batch 17: loss 0.056961\n",
      "batch 18: loss 0.092513\n",
      "batch 19: loss 0.028139\n",
      "batch 20: loss 0.020823\n",
      "batch 21: loss 0.044066\n",
      "batch 22: loss 0.145612\n",
      "batch 23: loss 0.032172\n",
      "batch 24: loss 0.071870\n",
      "batch 25: loss 0.190534\n",
      "batch 26: loss 0.093715\n",
      "batch 27: loss 0.008391\n",
      "batch 28: loss 0.048420\n",
      "batch 29: loss 0.019753\n",
      "batch 30: loss 0.006633\n",
      "batch 31: loss 0.039991\n",
      "batch 32: loss 0.063499\n",
      "batch 33: loss 0.105380\n",
      "batch 34: loss 0.155985\n",
      "batch 35: loss 0.009560\n",
      "batch 36: loss 0.027525\n",
      "batch 37: loss 0.059563\n",
      "batch 38: loss 0.011615\n",
      "batch 39: loss 0.051134\n",
      "batch 40: loss 0.055502\n",
      "batch 41: loss 0.079165\n",
      "batch 42: loss 0.123828\n",
      "batch 43: loss 0.075195\n",
      "batch 44: loss 0.022819\n",
      "batch 45: loss 0.013497\n",
      "batch 46: loss 0.008126\n",
      "batch 47: loss 0.017784\n",
      "batch 48: loss 0.045592\n",
      "batch 49: loss 0.049881\n",
      "batch 50: loss 0.131573\n",
      "batch 51: loss 0.057314\n",
      "batch 52: loss 0.012109\n",
      "batch 53: loss 0.035904\n",
      "batch 54: loss 0.068167\n",
      "batch 55: loss 0.025840\n",
      "batch 56: loss 0.034809\n",
      "batch 57: loss 0.007369\n",
      "batch 58: loss 0.016930\n",
      "batch 59: loss 0.040772\n",
      "batch 60: loss 0.018605\n",
      "batch 61: loss 0.070739\n",
      "batch 62: loss 0.044019\n",
      "batch 63: loss 0.113737\n",
      "batch 64: loss 0.107161\n",
      "batch 65: loss 0.015616\n",
      "batch 66: loss 0.012902\n",
      "batch 67: loss 0.020702\n",
      "batch 68: loss 0.049976\n",
      "batch 69: loss 0.025300\n",
      "batch 70: loss 0.033607\n",
      "batch 71: loss 0.051470\n",
      "batch 72: loss 0.078760\n",
      "batch 73: loss 0.019234\n",
      "batch 74: loss 0.059051\n",
      "batch 75: loss 0.065727\n",
      "batch 76: loss 0.038831\n",
      "batch 77: loss 0.051478\n",
      "batch 78: loss 0.027193\n",
      "batch 79: loss 0.070197\n",
      "batch 80: loss 0.047293\n",
      "batch 81: loss 0.039635\n",
      "batch 82: loss 0.020148\n",
      "batch 83: loss 0.014220\n",
      "batch 84: loss 0.068799\n",
      "batch 85: loss 0.124467\n",
      "batch 86: loss 0.029536\n",
      "batch 87: loss 0.063885\n",
      "batch 88: loss 0.080310\n",
      "batch 89: loss 0.087339\n",
      "batch 90: loss 0.012139\n",
      "batch 91: loss 0.070560\n",
      "batch 92: loss 0.012410\n",
      "batch 93: loss 0.009187\n",
      "batch 94: loss 0.055444\n",
      "batch 95: loss 0.062904\n",
      "batch 96: loss 0.009151\n",
      "batch 97: loss 0.059545\n",
      "batch 98: loss 0.043091\n",
      "batch 99: loss 0.147447\n",
      "batch 100: loss 0.105416\n",
      "batch 101: loss 0.235485\n",
      "batch 102: loss 0.078431\n",
      "batch 103: loss 0.028100\n",
      "batch 104: loss 0.020466\n",
      "batch 105: loss 0.015992\n",
      "batch 106: loss 0.087150\n",
      "batch 107: loss 0.049618\n",
      "batch 108: loss 0.077980\n",
      "batch 109: loss 0.069077\n",
      "batch 110: loss 0.024840\n",
      "batch 111: loss 0.026691\n",
      "batch 112: loss 0.035052\n",
      "batch 113: loss 0.055476\n",
      "batch 114: loss 0.029725\n",
      "batch 115: loss 0.016511\n",
      "batch 116: loss 0.020301\n",
      "batch 117: loss 0.074166\n",
      "batch 118: loss 0.022185\n",
      "batch 119: loss 0.117587\n",
      "batch 120: loss 0.031210\n",
      "batch 121: loss 0.123379\n",
      "batch 122: loss 0.014898\n",
      "batch 123: loss 0.059791\n",
      "batch 124: loss 0.016040\n",
      "batch 125: loss 0.220774\n",
      "batch 126: loss 0.084024\n",
      "batch 127: loss 0.031884\n",
      "batch 128: loss 0.003817\n",
      "batch 129: loss 0.020163\n",
      "batch 130: loss 0.040401\n",
      "batch 131: loss 0.010380\n",
      "batch 132: loss 0.033900\n",
      "batch 133: loss 0.071949\n",
      "batch 134: loss 0.014004\n",
      "batch 135: loss 0.022363\n",
      "batch 136: loss 0.030343\n",
      "batch 137: loss 0.009176\n",
      "batch 138: loss 0.100038\n",
      "batch 139: loss 0.041503\n",
      "batch 140: loss 0.035763\n",
      "batch 141: loss 0.020915\n",
      "batch 142: loss 0.058253\n",
      "batch 143: loss 0.030715\n",
      "batch 144: loss 0.019098\n",
      "batch 145: loss 0.040948\n",
      "batch 146: loss 0.059583\n",
      "batch 147: loss 0.106710\n",
      "batch 148: loss 0.086392\n",
      "batch 149: loss 0.051368\n",
      "batch 150: loss 0.017376\n",
      "batch 151: loss 0.034524\n",
      "batch 152: loss 0.019036\n",
      "batch 153: loss 0.002336\n",
      "batch 154: loss 0.072920\n",
      "batch 155: loss 0.013962\n",
      "batch 156: loss 0.087622\n",
      "batch 157: loss 0.009078\n",
      "batch 158: loss 0.058937\n",
      "batch 159: loss 0.034258\n",
      "batch 160: loss 0.017498\n",
      "batch 161: loss 0.024316\n",
      "batch 162: loss 0.018368\n",
      "batch 163: loss 0.022149\n",
      "batch 164: loss 0.128058\n",
      "batch 165: loss 0.028504\n",
      "batch 166: loss 0.016755\n",
      "batch 167: loss 0.056149\n",
      "batch 168: loss 0.008660\n",
      "batch 169: loss 0.060303\n",
      "batch 170: loss 0.028827\n",
      "batch 171: loss 0.006628\n",
      "batch 172: loss 0.082884\n",
      "batch 173: loss 0.029443\n",
      "batch 174: loss 0.077740\n",
      "batch 175: loss 0.040593\n",
      "batch 176: loss 0.019095\n",
      "batch 177: loss 0.072425\n",
      "batch 178: loss 0.088382\n",
      "batch 179: loss 0.111550\n",
      "batch 180: loss 0.008866\n",
      "batch 181: loss 0.067975\n",
      "batch 182: loss 0.019666\n",
      "batch 183: loss 0.023917\n",
      "batch 184: loss 0.027814\n",
      "batch 185: loss 0.027093\n",
      "batch 186: loss 0.330994\n",
      "batch 187: loss 0.024619\n",
      "batch 188: loss 0.018415\n",
      "batch 189: loss 0.024511\n",
      "batch 190: loss 0.058881\n",
      "batch 191: loss 0.084961\n",
      "batch 192: loss 0.017714\n",
      "batch 193: loss 0.005593\n",
      "batch 194: loss 0.034366\n",
      "batch 195: loss 0.039248\n",
      "batch 196: loss 0.022346\n",
      "batch 197: loss 0.036726\n",
      "batch 198: loss 0.033589\n",
      "batch 199: loss 0.007225\n",
      "batch 200: loss 0.055568\n",
      "batch 201: loss 0.027135\n",
      "batch 202: loss 0.049987\n",
      "batch 203: loss 0.011276\n",
      "batch 204: loss 0.065977\n",
      "batch 205: loss 0.173956\n",
      "batch 206: loss 0.020383\n",
      "batch 207: loss 0.078753\n",
      "batch 208: loss 0.146546\n",
      "batch 209: loss 0.070149\n",
      "batch 210: loss 0.059288\n",
      "batch 211: loss 0.021894\n",
      "batch 212: loss 0.010923\n",
      "batch 213: loss 0.016161\n",
      "batch 214: loss 0.004506\n",
      "batch 215: loss 0.011271\n",
      "batch 216: loss 0.028451\n",
      "batch 217: loss 0.004033\n",
      "batch 218: loss 0.021082\n",
      "batch 219: loss 0.019514\n",
      "batch 220: loss 0.069418\n",
      "batch 221: loss 0.030120\n",
      "batch 222: loss 0.011717\n",
      "batch 223: loss 0.068188\n",
      "batch 224: loss 0.107705\n",
      "batch 225: loss 0.176679\n",
      "batch 226: loss 0.062284\n",
      "batch 227: loss 0.029442\n",
      "batch 228: loss 0.014453\n",
      "batch 229: loss 0.014766\n",
      "batch 230: loss 0.072178\n",
      "batch 231: loss 0.016941\n",
      "batch 232: loss 0.026420\n",
      "batch 233: loss 0.089486\n",
      "batch 234: loss 0.037223\n",
      "batch 235: loss 0.045236\n",
      "batch 236: loss 0.074098\n",
      "batch 237: loss 0.054919\n",
      "batch 238: loss 0.022255\n",
      "batch 239: loss 0.020781\n",
      "batch 240: loss 0.003415\n",
      "batch 241: loss 0.033303\n",
      "batch 242: loss 0.059703\n",
      "batch 243: loss 0.004242\n",
      "batch 244: loss 0.049029\n",
      "batch 245: loss 0.115987\n",
      "batch 246: loss 0.211196\n",
      "batch 247: loss 0.045978\n",
      "batch 248: loss 0.013058\n",
      "batch 249: loss 0.154098\n",
      "batch 250: loss 0.056751\n",
      "batch 251: loss 0.006567\n",
      "batch 252: loss 0.160154\n",
      "batch 253: loss 0.060014\n",
      "batch 254: loss 0.050236\n",
      "batch 255: loss 0.014378\n",
      "batch 256: loss 0.019915\n",
      "batch 257: loss 0.046645\n",
      "batch 258: loss 0.066766\n",
      "batch 259: loss 0.017284\n",
      "batch 260: loss 0.029406\n",
      "batch 261: loss 0.011857\n",
      "batch 262: loss 0.056848\n",
      "batch 263: loss 0.021781\n",
      "batch 264: loss 0.013192\n",
      "batch 265: loss 0.012800\n",
      "batch 266: loss 0.027729\n",
      "batch 267: loss 0.070819\n",
      "batch 268: loss 0.033753\n",
      "batch 269: loss 0.031802\n",
      "batch 270: loss 0.031126\n",
      "batch 271: loss 0.009207\n",
      "batch 272: loss 0.043233\n",
      "batch 273: loss 0.021467\n",
      "batch 274: loss 0.016451\n",
      "batch 275: loss 0.080734\n",
      "batch 276: loss 0.025655\n",
      "batch 277: loss 0.079597\n",
      "batch 278: loss 0.008785\n",
      "batch 279: loss 0.012167\n",
      "batch 280: loss 0.016542\n",
      "batch 281: loss 0.021143\n",
      "batch 282: loss 0.010542\n",
      "batch 283: loss 0.025631\n",
      "batch 284: loss 0.016409\n",
      "batch 285: loss 0.114688\n",
      "batch 286: loss 0.031738\n",
      "batch 287: loss 0.010878\n",
      "batch 288: loss 0.066293\n",
      "batch 289: loss 0.055446\n",
      "batch 290: loss 0.061010\n",
      "batch 291: loss 0.104995\n",
      "batch 292: loss 0.008632\n",
      "batch 293: loss 0.045779\n",
      "batch 294: loss 0.014046\n",
      "batch 295: loss 0.008750\n",
      "batch 296: loss 0.006871\n",
      "batch 297: loss 0.039256\n",
      "batch 298: loss 0.054870\n",
      "batch 299: loss 0.009595\n",
      "batch 300: loss 0.005614\n",
      "batch 301: loss 0.017018\n",
      "batch 302: loss 0.020033\n",
      "batch 303: loss 0.014936\n",
      "batch 304: loss 0.087219\n",
      "batch 305: loss 0.010486\n",
      "batch 306: loss 0.013315\n",
      "batch 307: loss 0.034927\n",
      "batch 308: loss 0.030725\n",
      "batch 309: loss 0.053867\n",
      "batch 310: loss 0.028270\n",
      "batch 311: loss 0.036338\n",
      "batch 312: loss 0.030241\n",
      "batch 313: loss 0.014188\n",
      "batch 314: loss 0.079934\n",
      "batch 315: loss 0.201862\n",
      "batch 316: loss 0.012845\n",
      "batch 317: loss 0.142036\n",
      "batch 318: loss 0.049377\n",
      "batch 319: loss 0.015116\n",
      "batch 320: loss 0.081987\n",
      "batch 321: loss 0.030412\n",
      "batch 322: loss 0.034507\n",
      "batch 323: loss 0.040110\n",
      "batch 324: loss 0.008293\n",
      "batch 325: loss 0.032560\n",
      "batch 326: loss 0.088072\n",
      "batch 327: loss 0.039216\n",
      "batch 328: loss 0.051407\n",
      "batch 329: loss 0.029613\n",
      "batch 330: loss 0.027826\n",
      "batch 331: loss 0.051556\n",
      "batch 332: loss 0.021288\n",
      "batch 333: loss 0.037020\n",
      "batch 334: loss 0.079726\n",
      "batch 335: loss 0.006161\n",
      "batch 336: loss 0.016747\n",
      "batch 337: loss 0.018339\n",
      "batch 338: loss 0.080458\n",
      "batch 339: loss 0.033366\n",
      "batch 340: loss 0.029978\n",
      "batch 341: loss 0.012212\n",
      "batch 342: loss 0.104871\n",
      "batch 343: loss 0.013981\n",
      "batch 344: loss 0.022181\n",
      "batch 345: loss 0.019500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 346: loss 0.154429\n",
      "batch 347: loss 0.017737\n",
      "batch 348: loss 0.073637\n",
      "batch 349: loss 0.215291\n",
      "batch 350: loss 0.010954\n",
      "batch 351: loss 0.051547\n",
      "batch 352: loss 0.014291\n",
      "batch 353: loss 0.011932\n",
      "batch 354: loss 0.075875\n",
      "batch 355: loss 0.064897\n",
      "batch 356: loss 0.009475\n",
      "batch 357: loss 0.091193\n",
      "batch 358: loss 0.013639\n",
      "batch 359: loss 0.016796\n",
      "batch 360: loss 0.027518\n",
      "batch 361: loss 0.023205\n",
      "batch 362: loss 0.164686\n",
      "batch 363: loss 0.011505\n",
      "batch 364: loss 0.036221\n",
      "batch 365: loss 0.004177\n",
      "batch 366: loss 0.020029\n",
      "batch 367: loss 0.033472\n",
      "batch 368: loss 0.023946\n",
      "batch 369: loss 0.005163\n",
      "batch 370: loss 0.068575\n",
      "batch 371: loss 0.049143\n",
      "batch 372: loss 0.090909\n",
      "batch 373: loss 0.027526\n",
      "batch 374: loss 0.042742\n",
      "batch 375: loss 0.108374\n",
      "batch 376: loss 0.008816\n",
      "batch 377: loss 0.036353\n",
      "batch 378: loss 0.143558\n",
      "batch 379: loss 0.045974\n",
      "batch 380: loss 0.020335\n",
      "batch 381: loss 0.072126\n",
      "batch 382: loss 0.037960\n",
      "batch 383: loss 0.165111\n",
      "batch 384: loss 0.023666\n",
      "batch 385: loss 0.057682\n",
      "batch 386: loss 0.016267\n",
      "batch 387: loss 0.098381\n",
      "batch 388: loss 0.025962\n",
      "batch 389: loss 0.094067\n",
      "batch 390: loss 0.018808\n",
      "batch 391: loss 0.089337\n",
      "batch 392: loss 0.028830\n",
      "batch 393: loss 0.038210\n",
      "batch 394: loss 0.035436\n",
      "batch 395: loss 0.049353\n",
      "batch 396: loss 0.041816\n",
      "batch 397: loss 0.032789\n",
      "batch 398: loss 0.083577\n",
      "batch 399: loss 0.008923\n",
      "batch 400: loss 0.033562\n",
      "batch 401: loss 0.077031\n",
      "batch 402: loss 0.083761\n",
      "batch 403: loss 0.045858\n",
      "batch 404: loss 0.010862\n",
      "batch 405: loss 0.193998\n",
      "batch 406: loss 0.038277\n",
      "batch 407: loss 0.037013\n",
      "batch 408: loss 0.042146\n",
      "batch 409: loss 0.033500\n",
      "batch 410: loss 0.062863\n",
      "batch 411: loss 0.114114\n",
      "batch 412: loss 0.061853\n",
      "batch 413: loss 0.006839\n",
      "batch 414: loss 0.042752\n",
      "batch 415: loss 0.029334\n",
      "batch 416: loss 0.066796\n",
      "batch 417: loss 0.103818\n",
      "batch 418: loss 0.038779\n",
      "batch 419: loss 0.067150\n",
      "batch 420: loss 0.091571\n",
      "batch 421: loss 0.045252\n",
      "batch 422: loss 0.025799\n",
      "batch 423: loss 0.038852\n",
      "batch 424: loss 0.028914\n",
      "batch 425: loss 0.086391\n",
      "batch 426: loss 0.003604\n",
      "batch 427: loss 0.031106\n",
      "batch 428: loss 0.018233\n",
      "batch 429: loss 0.051588\n",
      "batch 430: loss 0.024906\n",
      "batch 431: loss 0.048435\n",
      "batch 432: loss 0.190632\n",
      "batch 433: loss 0.074288\n",
      "batch 434: loss 0.010799\n",
      "batch 435: loss 0.008283\n",
      "batch 436: loss 0.045129\n",
      "batch 437: loss 0.149494\n",
      "batch 438: loss 0.021643\n",
      "batch 439: loss 0.007727\n",
      "batch 440: loss 0.023257\n",
      "batch 441: loss 0.019689\n",
      "batch 442: loss 0.010098\n",
      "batch 443: loss 0.043347\n",
      "batch 444: loss 0.036139\n",
      "batch 445: loss 0.151412\n",
      "batch 446: loss 0.075822\n",
      "batch 447: loss 0.074509\n",
      "batch 448: loss 0.057244\n",
      "batch 449: loss 0.211755\n",
      "batch 450: loss 0.015222\n",
      "batch 451: loss 0.004628\n",
      "batch 452: loss 0.017867\n",
      "batch 453: loss 0.013507\n",
      "batch 454: loss 0.046180\n",
      "batch 455: loss 0.011271\n",
      "batch 456: loss 0.075347\n",
      "batch 457: loss 0.073041\n",
      "batch 458: loss 0.056937\n",
      "batch 459: loss 0.023761\n",
      "batch 460: loss 0.014962\n",
      "batch 461: loss 0.023751\n",
      "batch 462: loss 0.008719\n",
      "batch 463: loss 0.030738\n",
      "batch 464: loss 0.015007\n",
      "batch 465: loss 0.043381\n",
      "batch 466: loss 0.005557\n",
      "batch 467: loss 0.042816\n",
      "batch 468: loss 0.050588\n",
      "batch 469: loss 0.073884\n",
      "batch 470: loss 0.014942\n",
      "batch 471: loss 0.010507\n",
      "batch 472: loss 0.040663\n",
      "batch 473: loss 0.069861\n",
      "batch 474: loss 0.033721\n",
      "batch 475: loss 0.008569\n",
      "batch 476: loss 0.026893\n",
      "batch 477: loss 0.037400\n",
      "batch 478: loss 0.023646\n",
      "batch 479: loss 0.036023\n",
      "batch 480: loss 0.017321\n",
      "batch 481: loss 0.165873\n",
      "batch 482: loss 0.025484\n",
      "batch 483: loss 0.047091\n",
      "batch 484: loss 0.007794\n",
      "batch 485: loss 0.029118\n",
      "batch 486: loss 0.006900\n",
      "batch 487: loss 0.036974\n",
      "batch 488: loss 0.147210\n",
      "batch 489: loss 0.006934\n",
      "batch 490: loss 0.038911\n",
      "batch 491: loss 0.153489\n",
      "batch 492: loss 0.057613\n",
      "batch 493: loss 0.019464\n",
      "batch 494: loss 0.144312\n",
      "batch 495: loss 0.009917\n",
      "batch 496: loss 0.075104\n",
      "batch 497: loss 0.009481\n",
      "batch 498: loss 0.018303\n",
      "batch 499: loss 0.082614\n",
      "batch 500: loss 0.152143\n",
      "batch 501: loss 0.140295\n",
      "batch 502: loss 0.022352\n",
      "batch 503: loss 0.071493\n",
      "batch 504: loss 0.110757\n",
      "batch 505: loss 0.020869\n",
      "batch 506: loss 0.011099\n",
      "batch 507: loss 0.173888\n",
      "batch 508: loss 0.006369\n",
      "batch 509: loss 0.044549\n",
      "batch 510: loss 0.025019\n",
      "batch 511: loss 0.018770\n",
      "batch 512: loss 0.022155\n",
      "batch 513: loss 0.007274\n",
      "batch 514: loss 0.094820\n",
      "batch 515: loss 0.040530\n",
      "batch 516: loss 0.020136\n",
      "batch 517: loss 0.040685\n",
      "batch 518: loss 0.123542\n",
      "batch 519: loss 0.038078\n",
      "batch 520: loss 0.014741\n",
      "batch 521: loss 0.029929\n",
      "batch 522: loss 0.057854\n",
      "batch 523: loss 0.101759\n",
      "batch 524: loss 0.033380\n",
      "batch 525: loss 0.084383\n",
      "batch 526: loss 0.039647\n",
      "batch 527: loss 0.021557\n",
      "batch 528: loss 0.029799\n",
      "batch 529: loss 0.030754\n",
      "batch 530: loss 0.046986\n",
      "batch 531: loss 0.029887\n",
      "batch 532: loss 0.059001\n",
      "batch 533: loss 0.028437\n",
      "batch 534: loss 0.011198\n",
      "batch 535: loss 0.029608\n",
      "batch 536: loss 0.052911\n",
      "batch 537: loss 0.015343\n",
      "batch 538: loss 0.005765\n",
      "batch 539: loss 0.010737\n",
      "batch 540: loss 0.007019\n",
      "batch 541: loss 0.006479\n",
      "batch 542: loss 0.020883\n",
      "batch 543: loss 0.024185\n",
      "batch 544: loss 0.079974\n",
      "batch 545: loss 0.074849\n",
      "batch 546: loss 0.099821\n",
      "batch 547: loss 0.036063\n",
      "batch 548: loss 0.029450\n",
      "batch 549: loss 0.023315\n",
      "batch 550: loss 0.087601\n",
      "batch 551: loss 0.005850\n",
      "batch 552: loss 0.171921\n",
      "batch 553: loss 0.018537\n",
      "batch 554: loss 0.040559\n",
      "batch 555: loss 0.022469\n",
      "batch 556: loss 0.049648\n",
      "batch 557: loss 0.023404\n",
      "batch 558: loss 0.073485\n",
      "batch 559: loss 0.088240\n",
      "batch 560: loss 0.051179\n",
      "batch 561: loss 0.144412\n",
      "batch 562: loss 0.039153\n",
      "batch 563: loss 0.056627\n",
      "batch 564: loss 0.027783\n",
      "batch 565: loss 0.107050\n",
      "batch 566: loss 0.011051\n",
      "batch 567: loss 0.034001\n",
      "batch 568: loss 0.035231\n",
      "batch 569: loss 0.278599\n",
      "batch 570: loss 0.111355\n",
      "batch 571: loss 0.171428\n",
      "batch 572: loss 0.043039\n",
      "batch 573: loss 0.047473\n",
      "batch 574: loss 0.052190\n",
      "batch 575: loss 0.005088\n",
      "batch 576: loss 0.037578\n",
      "batch 577: loss 0.008891\n",
      "batch 578: loss 0.018252\n",
      "batch 579: loss 0.031356\n",
      "batch 580: loss 0.093889\n",
      "batch 581: loss 0.019081\n",
      "batch 582: loss 0.028194\n",
      "batch 583: loss 0.027659\n",
      "batch 584: loss 0.054707\n",
      "batch 585: loss 0.141177\n",
      "batch 586: loss 0.085979\n",
      "batch 587: loss 0.032722\n",
      "batch 588: loss 0.031707\n",
      "batch 589: loss 0.011996\n",
      "batch 590: loss 0.117720\n",
      "batch 591: loss 0.092777\n",
      "batch 592: loss 0.043424\n",
      "batch 593: loss 0.053117\n",
      "batch 594: loss 0.076607\n",
      "batch 595: loss 0.093778\n",
      "batch 596: loss 0.064747\n",
      "batch 597: loss 0.035612\n",
      "batch 598: loss 0.039522\n",
      "batch 599: loss 0.021353\n",
      "batch 600: loss 0.007930\n",
      "batch 601: loss 0.024321\n",
      "batch 602: loss 0.099904\n",
      "batch 603: loss 0.050399\n",
      "batch 604: loss 0.068893\n",
      "batch 605: loss 0.077539\n",
      "batch 606: loss 0.112894\n",
      "batch 607: loss 0.009865\n",
      "batch 608: loss 0.058929\n",
      "batch 609: loss 0.015891\n",
      "batch 610: loss 0.033100\n",
      "batch 611: loss 0.025390\n",
      "batch 612: loss 0.072300\n",
      "batch 613: loss 0.059567\n",
      "batch 614: loss 0.011260\n",
      "batch 615: loss 0.016343\n",
      "batch 616: loss 0.013103\n",
      "batch 617: loss 0.007054\n",
      "batch 618: loss 0.012549\n",
      "batch 619: loss 0.012898\n",
      "batch 620: loss 0.017202\n",
      "batch 621: loss 0.137645\n",
      "batch 622: loss 0.030734\n",
      "batch 623: loss 0.067352\n",
      "batch 624: loss 0.124337\n",
      "batch 625: loss 0.031615\n",
      "batch 626: loss 0.082695\n",
      "batch 627: loss 0.007331\n",
      "batch 628: loss 0.041788\n",
      "batch 629: loss 0.117908\n",
      "batch 630: loss 0.073623\n",
      "batch 631: loss 0.031525\n",
      "batch 632: loss 0.028621\n",
      "batch 633: loss 0.079051\n",
      "batch 634: loss 0.012101\n",
      "batch 635: loss 0.143850\n",
      "batch 636: loss 0.011552\n",
      "batch 637: loss 0.019267\n",
      "batch 638: loss 0.013623\n",
      "batch 639: loss 0.073618\n",
      "batch 640: loss 0.052170\n",
      "batch 641: loss 0.084539\n",
      "batch 642: loss 0.039680\n",
      "batch 643: loss 0.016877\n",
      "batch 644: loss 0.009318\n",
      "batch 645: loss 0.008774\n",
      "batch 646: loss 0.030195\n",
      "batch 647: loss 0.059596\n",
      "batch 648: loss 0.046350\n",
      "batch 649: loss 0.123924\n",
      "batch 650: loss 0.019079\n",
      "batch 651: loss 0.103449\n",
      "batch 652: loss 0.018849\n",
      "batch 653: loss 0.079951\n",
      "batch 654: loss 0.144174\n",
      "batch 655: loss 0.030001\n",
      "batch 656: loss 0.182411\n",
      "batch 657: loss 0.038159\n",
      "batch 658: loss 0.049763\n",
      "batch 659: loss 0.011204\n",
      "batch 660: loss 0.048033\n",
      "batch 661: loss 0.060698\n",
      "batch 662: loss 0.025899\n",
      "batch 663: loss 0.035613\n",
      "batch 664: loss 0.103424\n",
      "batch 665: loss 0.024004\n",
      "batch 666: loss 0.003675\n",
      "batch 667: loss 0.125977\n",
      "batch 668: loss 0.026912\n",
      "batch 669: loss 0.027402\n",
      "batch 670: loss 0.009936\n",
      "batch 671: loss 0.013356\n",
      "batch 672: loss 0.082080\n",
      "batch 673: loss 0.016118\n",
      "batch 674: loss 0.086023\n",
      "batch 675: loss 0.128167\n",
      "batch 676: loss 0.086476\n",
      "batch 677: loss 0.072332\n",
      "batch 678: loss 0.008194\n",
      "batch 679: loss 0.012125\n",
      "batch 680: loss 0.016550\n",
      "batch 681: loss 0.019878\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 682: loss 0.004848\n",
      "batch 683: loss 0.019753\n",
      "batch 684: loss 0.125232\n",
      "batch 685: loss 0.042461\n",
      "batch 686: loss 0.046523\n",
      "batch 687: loss 0.034602\n",
      "batch 688: loss 0.182959\n",
      "batch 689: loss 0.063681\n",
      "batch 690: loss 0.084642\n",
      "batch 691: loss 0.010894\n",
      "batch 692: loss 0.059165\n",
      "batch 693: loss 0.015719\n",
      "batch 694: loss 0.039780\n",
      "batch 695: loss 0.039223\n",
      "batch 696: loss 0.060472\n",
      "batch 697: loss 0.049201\n",
      "batch 698: loss 0.036549\n",
      "batch 699: loss 0.012944\n",
      "batch 700: loss 0.011723\n",
      "batch 701: loss 0.027787\n",
      "batch 702: loss 0.002452\n",
      "batch 703: loss 0.025258\n",
      "batch 704: loss 0.122908\n",
      "batch 705: loss 0.013927\n",
      "batch 706: loss 0.118726\n",
      "batch 707: loss 0.032002\n",
      "batch 708: loss 0.012810\n",
      "batch 709: loss 0.183252\n",
      "batch 710: loss 0.041288\n",
      "batch 711: loss 0.044542\n",
      "batch 712: loss 0.043158\n",
      "batch 713: loss 0.009210\n",
      "batch 714: loss 0.031241\n",
      "batch 715: loss 0.095207\n",
      "batch 716: loss 0.040645\n",
      "batch 717: loss 0.004063\n",
      "batch 718: loss 0.017087\n",
      "batch 719: loss 0.027027\n",
      "batch 720: loss 0.022512\n",
      "batch 721: loss 0.022109\n",
      "batch 722: loss 0.024791\n",
      "batch 723: loss 0.013641\n",
      "batch 724: loss 0.105207\n",
      "batch 725: loss 0.027962\n",
      "batch 726: loss 0.101879\n",
      "batch 727: loss 0.008872\n",
      "batch 728: loss 0.075470\n",
      "batch 729: loss 0.029326\n",
      "batch 730: loss 0.018423\n",
      "batch 731: loss 0.054780\n",
      "batch 732: loss 0.021567\n",
      "batch 733: loss 0.015090\n",
      "batch 734: loss 0.027119\n",
      "batch 735: loss 0.064654\n",
      "batch 736: loss 0.033081\n",
      "batch 737: loss 0.115427\n",
      "batch 738: loss 0.043179\n",
      "batch 739: loss 0.020927\n",
      "batch 740: loss 0.029641\n",
      "batch 741: loss 0.040745\n",
      "batch 742: loss 0.005592\n",
      "batch 743: loss 0.081288\n",
      "batch 744: loss 0.017593\n",
      "batch 745: loss 0.009189\n",
      "batch 746: loss 0.099848\n",
      "batch 747: loss 0.086722\n",
      "batch 748: loss 0.019192\n",
      "batch 749: loss 0.038699\n",
      "batch 750: loss 0.039424\n",
      "batch 751: loss 0.094750\n",
      "batch 752: loss 0.016902\n",
      "batch 753: loss 0.029858\n",
      "batch 754: loss 0.010332\n",
      "batch 755: loss 0.081161\n",
      "batch 756: loss 0.016719\n",
      "batch 757: loss 0.048561\n",
      "batch 758: loss 0.026529\n",
      "batch 759: loss 0.025772\n",
      "batch 760: loss 0.070900\n",
      "batch 761: loss 0.042648\n",
      "batch 762: loss 0.012101\n",
      "batch 763: loss 0.031136\n",
      "batch 764: loss 0.085948\n",
      "batch 765: loss 0.013581\n",
      "batch 766: loss 0.015489\n",
      "batch 767: loss 0.009572\n",
      "batch 768: loss 0.016207\n",
      "batch 769: loss 0.019623\n",
      "batch 770: loss 0.042894\n",
      "batch 771: loss 0.029345\n",
      "batch 772: loss 0.043034\n",
      "batch 773: loss 0.082119\n",
      "batch 774: loss 0.029070\n",
      "batch 775: loss 0.120615\n",
      "batch 776: loss 0.016939\n",
      "batch 777: loss 0.010459\n",
      "batch 778: loss 0.124592\n",
      "batch 779: loss 0.047427\n",
      "batch 780: loss 0.057719\n",
      "batch 781: loss 0.050764\n",
      "batch 782: loss 0.026658\n",
      "batch 783: loss 0.007296\n",
      "batch 784: loss 0.011206\n",
      "batch 785: loss 0.099913\n",
      "batch 786: loss 0.020269\n",
      "batch 787: loss 0.012890\n",
      "batch 788: loss 0.007781\n",
      "batch 789: loss 0.100163\n",
      "batch 790: loss 0.064093\n",
      "batch 791: loss 0.022775\n",
      "batch 792: loss 0.026579\n",
      "batch 793: loss 0.006056\n",
      "batch 794: loss 0.012806\n",
      "batch 795: loss 0.173779\n",
      "batch 796: loss 0.046677\n",
      "batch 797: loss 0.015497\n",
      "batch 798: loss 0.055585\n",
      "batch 799: loss 0.013710\n",
      "batch 800: loss 0.116601\n",
      "batch 801: loss 0.030359\n",
      "batch 802: loss 0.022569\n",
      "batch 803: loss 0.009728\n",
      "batch 804: loss 0.018607\n",
      "batch 805: loss 0.051934\n",
      "batch 806: loss 0.019367\n",
      "batch 807: loss 0.070332\n",
      "batch 808: loss 0.014217\n",
      "batch 809: loss 0.009155\n",
      "batch 810: loss 0.024947\n",
      "batch 811: loss 0.051845\n",
      "batch 812: loss 0.079530\n",
      "batch 813: loss 0.004538\n",
      "batch 814: loss 0.031838\n",
      "batch 815: loss 0.016387\n",
      "batch 816: loss 0.146952\n",
      "batch 817: loss 0.031550\n",
      "batch 818: loss 0.023944\n",
      "batch 819: loss 0.075322\n",
      "batch 820: loss 0.037430\n",
      "batch 821: loss 0.050517\n",
      "batch 822: loss 0.015728\n",
      "batch 823: loss 0.027380\n",
      "batch 824: loss 0.022756\n",
      "batch 825: loss 0.035934\n",
      "batch 826: loss 0.040386\n",
      "batch 827: loss 0.039307\n",
      "batch 828: loss 0.056385\n",
      "batch 829: loss 0.018749\n",
      "batch 830: loss 0.011164\n",
      "batch 831: loss 0.059062\n",
      "batch 832: loss 0.025303\n",
      "batch 833: loss 0.017556\n",
      "batch 834: loss 0.011928\n",
      "batch 835: loss 0.004840\n",
      "batch 836: loss 0.009044\n",
      "batch 837: loss 0.043943\n",
      "batch 838: loss 0.067556\n",
      "batch 839: loss 0.003609\n",
      "batch 840: loss 0.110186\n",
      "batch 841: loss 0.038224\n",
      "batch 842: loss 0.007617\n",
      "batch 843: loss 0.158343\n",
      "batch 844: loss 0.025381\n",
      "batch 845: loss 0.091149\n",
      "batch 846: loss 0.008715\n",
      "batch 847: loss 0.029409\n",
      "batch 848: loss 0.023424\n",
      "batch 849: loss 0.038375\n",
      "batch 850: loss 0.045590\n",
      "batch 851: loss 0.057266\n",
      "batch 852: loss 0.018286\n",
      "batch 853: loss 0.061225\n",
      "batch 854: loss 0.033109\n",
      "batch 855: loss 0.041265\n",
      "batch 856: loss 0.024951\n",
      "batch 857: loss 0.018781\n",
      "batch 858: loss 0.021050\n",
      "batch 859: loss 0.082775\n",
      "batch 860: loss 0.108270\n",
      "batch 861: loss 0.045504\n",
      "batch 862: loss 0.015042\n",
      "batch 863: loss 0.030552\n",
      "batch 864: loss 0.039543\n",
      "batch 865: loss 0.092551\n",
      "batch 866: loss 0.031605\n",
      "batch 867: loss 0.026944\n",
      "batch 868: loss 0.034927\n",
      "batch 869: loss 0.008151\n",
      "batch 870: loss 0.037569\n",
      "batch 871: loss 0.035191\n",
      "batch 872: loss 0.056516\n",
      "batch 873: loss 0.062023\n",
      "batch 874: loss 0.085738\n",
      "batch 875: loss 0.029505\n",
      "batch 876: loss 0.031110\n",
      "batch 877: loss 0.024822\n",
      "batch 878: loss 0.039151\n",
      "batch 879: loss 0.013081\n",
      "batch 880: loss 0.008135\n",
      "batch 881: loss 0.114890\n",
      "batch 882: loss 0.011624\n",
      "batch 883: loss 0.055112\n",
      "batch 884: loss 0.038717\n",
      "batch 885: loss 0.065560\n",
      "batch 886: loss 0.038059\n",
      "batch 887: loss 0.011606\n",
      "batch 888: loss 0.097735\n",
      "batch 889: loss 0.021712\n",
      "batch 890: loss 0.018629\n",
      "batch 891: loss 0.025210\n",
      "batch 892: loss 0.029367\n",
      "batch 893: loss 0.080972\n",
      "batch 894: loss 0.046770\n",
      "batch 895: loss 0.026197\n",
      "batch 896: loss 0.143581\n",
      "batch 897: loss 0.011419\n",
      "batch 898: loss 0.040061\n",
      "batch 899: loss 0.032802\n",
      "batch 900: loss 0.063008\n",
      "batch 901: loss 0.010253\n",
      "batch 902: loss 0.014595\n",
      "batch 903: loss 0.003580\n",
      "batch 904: loss 0.039744\n",
      "batch 905: loss 0.009376\n",
      "batch 906: loss 0.015998\n",
      "batch 907: loss 0.056330\n",
      "batch 908: loss 0.016048\n",
      "batch 909: loss 0.004121\n",
      "batch 910: loss 0.019518\n",
      "batch 911: loss 0.043332\n",
      "batch 912: loss 0.007889\n",
      "batch 913: loss 0.012739\n",
      "batch 914: loss 0.001766\n",
      "batch 915: loss 0.008017\n",
      "batch 916: loss 0.017305\n",
      "batch 917: loss 0.067159\n",
      "batch 918: loss 0.004519\n",
      "batch 919: loss 0.017126\n",
      "batch 920: loss 0.016466\n",
      "batch 921: loss 0.061285\n",
      "batch 922: loss 0.140764\n",
      "batch 923: loss 0.017151\n",
      "batch 924: loss 0.003455\n",
      "batch 925: loss 0.014630\n",
      "batch 926: loss 0.005884\n",
      "batch 927: loss 0.027991\n",
      "batch 928: loss 0.020093\n",
      "batch 929: loss 0.066227\n",
      "batch 930: loss 0.013905\n",
      "batch 931: loss 0.118468\n",
      "batch 932: loss 0.077983\n",
      "batch 933: loss 0.012772\n",
      "batch 934: loss 0.099635\n",
      "batch 935: loss 0.007158\n",
      "batch 936: loss 0.051750\n",
      "batch 937: loss 0.051276\n",
      "batch 938: loss 0.178418\n",
      "batch 939: loss 0.083389\n",
      "batch 940: loss 0.028978\n",
      "batch 941: loss 0.034407\n",
      "batch 942: loss 0.005927\n",
      "batch 943: loss 0.019259\n",
      "batch 944: loss 0.049893\n",
      "batch 945: loss 0.027334\n",
      "batch 946: loss 0.019740\n",
      "batch 947: loss 0.007887\n",
      "batch 948: loss 0.040151\n",
      "batch 949: loss 0.035478\n",
      "batch 950: loss 0.028876\n",
      "batch 951: loss 0.018624\n",
      "batch 952: loss 0.082792\n",
      "batch 953: loss 0.021862\n",
      "batch 954: loss 0.008953\n",
      "batch 955: loss 0.182192\n",
      "batch 956: loss 0.015937\n",
      "batch 957: loss 0.009984\n",
      "batch 958: loss 0.081734\n",
      "batch 959: loss 0.031169\n",
      "batch 960: loss 0.051774\n",
      "batch 961: loss 0.075937\n",
      "batch 962: loss 0.047741\n",
      "batch 963: loss 0.125747\n",
      "batch 964: loss 0.005289\n",
      "batch 965: loss 0.022138\n",
      "batch 966: loss 0.007001\n",
      "batch 967: loss 0.160458\n",
      "batch 968: loss 0.010360\n",
      "batch 969: loss 0.033377\n",
      "batch 970: loss 0.213083\n",
      "batch 971: loss 0.012577\n",
      "batch 972: loss 0.028588\n",
      "batch 973: loss 0.032430\n",
      "batch 974: loss 0.015384\n",
      "batch 975: loss 0.012496\n",
      "batch 976: loss 0.011613\n",
      "batch 977: loss 0.013980\n",
      "batch 978: loss 0.020391\n",
      "batch 979: loss 0.030888\n",
      "batch 980: loss 0.077476\n",
      "batch 981: loss 0.004760\n",
      "batch 982: loss 0.006858\n",
      "batch 983: loss 0.035581\n",
      "batch 984: loss 0.027988\n",
      "batch 985: loss 0.010677\n",
      "batch 986: loss 0.135427\n",
      "batch 987: loss 0.019724\n",
      "batch 988: loss 0.025322\n",
      "batch 989: loss 0.036650\n",
      "batch 990: loss 0.012820\n",
      "batch 991: loss 0.062770\n",
      "batch 992: loss 0.062678\n",
      "batch 993: loss 0.119881\n",
      "batch 994: loss 0.064107\n",
      "batch 995: loss 0.128082\n",
      "batch 996: loss 0.062073\n",
      "batch 997: loss 0.025043\n",
      "batch 998: loss 0.005466\n",
      "batch 999: loss 0.016162\n",
      "batch 1000: loss 0.022925\n",
      "batch 1001: loss 0.050440\n",
      "batch 1002: loss 0.005884\n",
      "batch 1003: loss 0.098032\n",
      "batch 1004: loss 0.017686\n",
      "batch 1005: loss 0.081810\n",
      "batch 1006: loss 0.003114\n",
      "batch 1007: loss 0.056348\n",
      "batch 1008: loss 0.024589\n",
      "batch 1009: loss 0.004782\n",
      "batch 1010: loss 0.006332\n",
      "batch 1011: loss 0.027767\n",
      "batch 1012: loss 0.007961\n",
      "batch 1013: loss 0.040827\n",
      "batch 1014: loss 0.020559\n",
      "batch 1015: loss 0.044972\n",
      "batch 1016: loss 0.049066\n",
      "batch 1017: loss 0.040359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1018: loss 0.049235\n",
      "batch 1019: loss 0.054541\n",
      "batch 1020: loss 0.019808\n",
      "batch 1021: loss 0.018229\n",
      "batch 1022: loss 0.017634\n",
      "batch 1023: loss 0.075808\n",
      "batch 1024: loss 0.028664\n",
      "batch 1025: loss 0.018941\n",
      "batch 1026: loss 0.022299\n",
      "batch 1027: loss 0.029203\n",
      "batch 1028: loss 0.043654\n",
      "batch 1029: loss 0.151648\n",
      "batch 1030: loss 0.031644\n",
      "batch 1031: loss 0.026843\n",
      "batch 1032: loss 0.027090\n",
      "batch 1033: loss 0.007005\n",
      "batch 1034: loss 0.062424\n",
      "batch 1035: loss 0.082140\n",
      "batch 1036: loss 0.008871\n",
      "batch 1037: loss 0.064578\n",
      "batch 1038: loss 0.027467\n",
      "batch 1039: loss 0.212468\n",
      "batch 1040: loss 0.029698\n",
      "batch 1041: loss 0.022028\n",
      "batch 1042: loss 0.026772\n",
      "batch 1043: loss 0.039174\n",
      "batch 1044: loss 0.006890\n",
      "batch 1045: loss 0.041393\n",
      "batch 1046: loss 0.034018\n",
      "batch 1047: loss 0.006918\n",
      "batch 1048: loss 0.004376\n",
      "batch 1049: loss 0.009802\n",
      "batch 1050: loss 0.041921\n",
      "batch 1051: loss 0.095212\n",
      "batch 1052: loss 0.011746\n",
      "batch 1053: loss 0.072940\n",
      "batch 1054: loss 0.057788\n",
      "batch 1055: loss 0.009074\n",
      "batch 1056: loss 0.018012\n",
      "batch 1057: loss 0.114822\n",
      "batch 1058: loss 0.013349\n",
      "batch 1059: loss 0.048373\n",
      "batch 1060: loss 0.041044\n",
      "batch 1061: loss 0.034669\n",
      "batch 1062: loss 0.024600\n",
      "batch 1063: loss 0.050130\n",
      "batch 1064: loss 0.015865\n",
      "batch 1065: loss 0.024887\n",
      "batch 1066: loss 0.034356\n",
      "batch 1067: loss 0.080247\n",
      "batch 1068: loss 0.024586\n",
      "batch 1069: loss 0.013589\n",
      "batch 1070: loss 0.008092\n",
      "batch 1071: loss 0.052276\n",
      "batch 1072: loss 0.030091\n",
      "batch 1073: loss 0.009902\n",
      "batch 1074: loss 0.023572\n",
      "batch 1075: loss 0.022494\n",
      "batch 1076: loss 0.016297\n",
      "batch 1077: loss 0.021612\n",
      "batch 1078: loss 0.037093\n",
      "batch 1079: loss 0.008398\n",
      "batch 1080: loss 0.059435\n",
      "batch 1081: loss 0.018853\n",
      "batch 1082: loss 0.018989\n",
      "batch 1083: loss 0.032638\n",
      "batch 1084: loss 0.062071\n",
      "batch 1085: loss 0.086713\n",
      "batch 1086: loss 0.098849\n",
      "batch 1087: loss 0.016715\n",
      "batch 1088: loss 0.065819\n",
      "batch 1089: loss 0.036467\n",
      "batch 1090: loss 0.039888\n",
      "batch 1091: loss 0.016213\n",
      "batch 1092: loss 0.011066\n",
      "batch 1093: loss 0.059341\n",
      "batch 1094: loss 0.139713\n",
      "batch 1095: loss 0.004753\n",
      "batch 1096: loss 0.098787\n",
      "batch 1097: loss 0.013539\n",
      "batch 1098: loss 0.017701\n",
      "batch 1099: loss 0.051656\n",
      "batch 1100: loss 0.038811\n",
      "batch 1101: loss 0.114251\n",
      "batch 1102: loss 0.017079\n",
      "batch 1103: loss 0.009034\n",
      "batch 1104: loss 0.006830\n",
      "batch 1105: loss 0.010624\n",
      "batch 1106: loss 0.013172\n",
      "batch 1107: loss 0.007928\n",
      "batch 1108: loss 0.025788\n",
      "batch 1109: loss 0.038203\n",
      "batch 1110: loss 0.073505\n",
      "batch 1111: loss 0.132819\n",
      "batch 1112: loss 0.010975\n",
      "batch 1113: loss 0.013991\n",
      "batch 1114: loss 0.021691\n",
      "batch 1115: loss 0.093001\n",
      "batch 1116: loss 0.012469\n",
      "batch 1117: loss 0.009269\n",
      "batch 1118: loss 0.030331\n",
      "batch 1119: loss 0.003950\n",
      "batch 1120: loss 0.081755\n",
      "batch 1121: loss 0.027548\n",
      "batch 1122: loss 0.046580\n",
      "batch 1123: loss 0.056537\n",
      "batch 1124: loss 0.039194\n",
      "batch 1125: loss 0.022417\n",
      "batch 1126: loss 0.023610\n",
      "batch 1127: loss 0.054888\n",
      "batch 1128: loss 0.032972\n",
      "batch 1129: loss 0.004411\n",
      "batch 1130: loss 0.049355\n",
      "batch 1131: loss 0.145582\n",
      "batch 1132: loss 0.004579\n",
      "batch 1133: loss 0.031529\n",
      "batch 1134: loss 0.017157\n",
      "batch 1135: loss 0.007368\n",
      "batch 1136: loss 0.007645\n",
      "batch 1137: loss 0.044883\n",
      "batch 1138: loss 0.012238\n",
      "batch 1139: loss 0.053633\n",
      "batch 1140: loss 0.010139\n",
      "batch 1141: loss 0.031585\n",
      "batch 1142: loss 0.009701\n",
      "batch 1143: loss 0.055739\n",
      "batch 1144: loss 0.062026\n",
      "batch 1145: loss 0.010852\n",
      "batch 1146: loss 0.080907\n",
      "batch 1147: loss 0.002092\n",
      "batch 1148: loss 0.062414\n",
      "batch 1149: loss 0.068137\n",
      "batch 1150: loss 0.026544\n",
      "batch 1151: loss 0.007440\n",
      "batch 1152: loss 0.076822\n",
      "batch 1153: loss 0.009277\n",
      "batch 1154: loss 0.004241\n",
      "batch 1155: loss 0.027903\n",
      "batch 1156: loss 0.005208\n",
      "batch 1157: loss 0.014500\n",
      "batch 1158: loss 0.070582\n",
      "batch 1159: loss 0.001909\n",
      "batch 1160: loss 0.013468\n",
      "batch 1161: loss 0.007396\n",
      "batch 1162: loss 0.015292\n",
      "batch 1163: loss 0.015436\n",
      "batch 1164: loss 0.073895\n",
      "batch 1165: loss 0.010172\n",
      "batch 1166: loss 0.026233\n",
      "batch 1167: loss 0.016016\n",
      "batch 1168: loss 0.012495\n",
      "batch 1169: loss 0.007860\n",
      "batch 1170: loss 0.032848\n",
      "batch 1171: loss 0.024116\n",
      "batch 1172: loss 0.020104\n",
      "batch 1173: loss 0.056405\n",
      "batch 1174: loss 0.064099\n",
      "batch 1175: loss 0.050185\n",
      "batch 1176: loss 0.022772\n",
      "batch 1177: loss 0.065757\n",
      "batch 1178: loss 0.025923\n",
      "batch 1179: loss 0.014049\n",
      "batch 1180: loss 0.046560\n",
      "batch 1181: loss 0.010542\n",
      "batch 1182: loss 0.015913\n",
      "batch 1183: loss 0.011919\n",
      "batch 1184: loss 0.017429\n",
      "batch 1185: loss 0.034472\n",
      "batch 1186: loss 0.018732\n",
      "batch 1187: loss 0.082234\n",
      "batch 1188: loss 0.007815\n",
      "batch 1189: loss 0.012511\n",
      "batch 1190: loss 0.010688\n",
      "batch 1191: loss 0.020515\n",
      "batch 1192: loss 0.019641\n",
      "batch 1193: loss 0.170565\n",
      "batch 1194: loss 0.015711\n",
      "batch 1195: loss 0.035315\n",
      "batch 1196: loss 0.006417\n",
      "batch 1197: loss 0.018048\n",
      "batch 1198: loss 0.010732\n",
      "batch 1199: loss 0.087388\n",
      "batch 1200: loss 0.021346\n",
      "batch 1201: loss 0.141176\n",
      "batch 1202: loss 0.060728\n",
      "batch 1203: loss 0.021417\n",
      "batch 1204: loss 0.026506\n",
      "batch 1205: loss 0.007747\n",
      "batch 1206: loss 0.080967\n",
      "batch 1207: loss 0.027582\n",
      "batch 1208: loss 0.039012\n",
      "batch 1209: loss 0.089420\n",
      "batch 1210: loss 0.056958\n",
      "batch 1211: loss 0.014420\n",
      "batch 1212: loss 0.025626\n",
      "batch 1213: loss 0.028103\n",
      "batch 1214: loss 0.084210\n",
      "batch 1215: loss 0.026622\n",
      "batch 1216: loss 0.033252\n",
      "batch 1217: loss 0.049692\n",
      "batch 1218: loss 0.058598\n",
      "batch 1219: loss 0.030318\n",
      "batch 1220: loss 0.037187\n",
      "batch 1221: loss 0.057912\n",
      "batch 1222: loss 0.042715\n",
      "batch 1223: loss 0.079889\n",
      "batch 1224: loss 0.011920\n",
      "batch 1225: loss 0.030558\n",
      "batch 1226: loss 0.074773\n",
      "batch 1227: loss 0.073453\n",
      "batch 1228: loss 0.034210\n",
      "batch 1229: loss 0.052780\n",
      "batch 1230: loss 0.014030\n",
      "batch 1231: loss 0.014339\n",
      "batch 1232: loss 0.070258\n",
      "batch 1233: loss 0.037290\n",
      "batch 1234: loss 0.131183\n",
      "batch 1235: loss 0.021885\n",
      "batch 1236: loss 0.068502\n",
      "batch 1237: loss 0.011497\n",
      "batch 1238: loss 0.041569\n",
      "batch 1239: loss 0.078978\n",
      "batch 1240: loss 0.157904\n",
      "batch 1241: loss 0.018090\n",
      "batch 1242: loss 0.008472\n",
      "batch 1243: loss 0.007210\n",
      "batch 1244: loss 0.011612\n",
      "batch 1245: loss 0.060200\n",
      "batch 1246: loss 0.010313\n",
      "batch 1247: loss 0.024291\n",
      "batch 1248: loss 0.003938\n",
      "batch 1249: loss 0.011712\n",
      "batch 1250: loss 0.022681\n",
      "batch 1251: loss 0.015049\n",
      "batch 1252: loss 0.019879\n",
      "batch 1253: loss 0.026226\n",
      "batch 1254: loss 0.083267\n",
      "batch 1255: loss 0.034581\n",
      "batch 1256: loss 0.015413\n",
      "batch 1257: loss 0.017207\n",
      "batch 1258: loss 0.175176\n",
      "batch 1259: loss 0.066115\n",
      "batch 1260: loss 0.019990\n",
      "batch 1261: loss 0.043292\n",
      "batch 1262: loss 0.035665\n",
      "batch 1263: loss 0.067546\n",
      "batch 1264: loss 0.023056\n",
      "batch 1265: loss 0.015483\n",
      "batch 1266: loss 0.210810\n",
      "batch 1267: loss 0.048684\n",
      "batch 1268: loss 0.039807\n",
      "batch 1269: loss 0.038178\n",
      "batch 1270: loss 0.023724\n",
      "batch 1271: loss 0.051776\n",
      "batch 1272: loss 0.075492\n",
      "batch 1273: loss 0.047157\n",
      "batch 1274: loss 0.027959\n",
      "batch 1275: loss 0.051926\n",
      "batch 1276: loss 0.019376\n",
      "batch 1277: loss 0.018033\n",
      "batch 1278: loss 0.117759\n",
      "batch 1279: loss 0.009254\n",
      "batch 1280: loss 0.046571\n",
      "batch 1281: loss 0.007080\n",
      "batch 1282: loss 0.015898\n",
      "batch 1283: loss 0.004805\n",
      "batch 1284: loss 0.008585\n",
      "batch 1285: loss 0.031550\n",
      "batch 1286: loss 0.014599\n",
      "batch 1287: loss 0.160828\n",
      "batch 1288: loss 0.109840\n",
      "batch 1289: loss 0.020729\n",
      "batch 1290: loss 0.016420\n",
      "batch 1291: loss 0.008570\n",
      "batch 1292: loss 0.036988\n",
      "batch 1293: loss 0.046362\n",
      "batch 1294: loss 0.007212\n",
      "batch 1295: loss 0.028174\n",
      "batch 1296: loss 0.142986\n",
      "batch 1297: loss 0.005862\n",
      "batch 1298: loss 0.002563\n",
      "batch 1299: loss 0.139403\n",
      "batch 1300: loss 0.015149\n",
      "batch 1301: loss 0.063527\n",
      "batch 1302: loss 0.004706\n",
      "batch 1303: loss 0.026123\n",
      "batch 1304: loss 0.008937\n",
      "batch 1305: loss 0.159029\n",
      "batch 1306: loss 0.021394\n",
      "batch 1307: loss 0.084120\n",
      "batch 1308: loss 0.049824\n",
      "batch 1309: loss 0.006053\n",
      "batch 1310: loss 0.036535\n",
      "batch 1311: loss 0.015564\n",
      "batch 1312: loss 0.223848\n",
      "batch 1313: loss 0.025090\n",
      "batch 1314: loss 0.014988\n",
      "batch 1315: loss 0.210420\n",
      "batch 1316: loss 0.005457\n",
      "batch 1317: loss 0.029668\n",
      "batch 1318: loss 0.050077\n",
      "batch 1319: loss 0.025490\n",
      "batch 1320: loss 0.011072\n",
      "batch 1321: loss 0.062946\n",
      "batch 1322: loss 0.013441\n",
      "batch 1323: loss 0.035099\n",
      "batch 1324: loss 0.011315\n",
      "batch 1325: loss 0.048946\n",
      "batch 1326: loss 0.002582\n",
      "batch 1327: loss 0.068503\n",
      "batch 1328: loss 0.038173\n",
      "batch 1329: loss 0.026921\n",
      "batch 1330: loss 0.007882\n",
      "batch 1331: loss 0.134260\n",
      "batch 1332: loss 0.043270\n",
      "batch 1333: loss 0.040268\n",
      "batch 1334: loss 0.072546\n",
      "batch 1335: loss 0.070223\n",
      "batch 1336: loss 0.019056\n",
      "batch 1337: loss 0.052506\n",
      "batch 1338: loss 0.005763\n",
      "batch 1339: loss 0.011508\n",
      "batch 1340: loss 0.013261\n",
      "batch 1341: loss 0.025614\n",
      "batch 1342: loss 0.006959\n",
      "batch 1343: loss 0.010969\n",
      "batch 1344: loss 0.038027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1345: loss 0.013628\n",
      "batch 1346: loss 0.037386\n",
      "batch 1347: loss 0.020322\n",
      "batch 1348: loss 0.080919\n",
      "batch 1349: loss 0.014107\n",
      "batch 1350: loss 0.011195\n",
      "batch 1351: loss 0.068403\n",
      "batch 1352: loss 0.011223\n",
      "batch 1353: loss 0.151989\n",
      "batch 1354: loss 0.044409\n",
      "batch 1355: loss 0.026952\n",
      "batch 1356: loss 0.033373\n",
      "batch 1357: loss 0.015391\n",
      "batch 1358: loss 0.108527\n",
      "batch 1359: loss 0.037941\n",
      "batch 1360: loss 0.006855\n",
      "batch 1361: loss 0.037990\n",
      "batch 1362: loss 0.088026\n",
      "batch 1363: loss 0.078235\n",
      "batch 1364: loss 0.003535\n",
      "batch 1365: loss 0.046135\n",
      "batch 1366: loss 0.073160\n",
      "batch 1367: loss 0.046077\n",
      "batch 1368: loss 0.023011\n",
      "batch 1369: loss 0.038801\n",
      "batch 1370: loss 0.020895\n",
      "batch 1371: loss 0.017901\n",
      "batch 1372: loss 0.037317\n",
      "batch 1373: loss 0.020662\n",
      "batch 1374: loss 0.075727\n",
      "batch 1375: loss 0.219017\n",
      "batch 1376: loss 0.225964\n",
      "batch 1377: loss 0.081201\n",
      "batch 1378: loss 0.022470\n",
      "batch 1379: loss 0.018435\n",
      "batch 1380: loss 0.018522\n",
      "batch 1381: loss 0.033465\n",
      "batch 1382: loss 0.009728\n",
      "batch 1383: loss 0.082137\n",
      "batch 1384: loss 0.005557\n",
      "batch 1385: loss 0.021577\n",
      "batch 1386: loss 0.091575\n",
      "batch 1387: loss 0.010492\n",
      "batch 1388: loss 0.017252\n",
      "batch 1389: loss 0.058365\n",
      "batch 1390: loss 0.067560\n",
      "batch 1391: loss 0.023149\n",
      "batch 1392: loss 0.072594\n",
      "batch 1393: loss 0.009046\n",
      "batch 1394: loss 0.023748\n",
      "batch 1395: loss 0.022401\n",
      "batch 1396: loss 0.041034\n",
      "batch 1397: loss 0.055617\n",
      "batch 1398: loss 0.064499\n",
      "batch 1399: loss 0.043924\n",
      "batch 1400: loss 0.050470\n",
      "batch 1401: loss 0.071046\n",
      "batch 1402: loss 0.085161\n",
      "batch 1403: loss 0.083938\n",
      "batch 1404: loss 0.133264\n",
      "batch 1405: loss 0.020182\n",
      "batch 1406: loss 0.017915\n",
      "batch 1407: loss 0.030415\n",
      "batch 1408: loss 0.015498\n",
      "batch 1409: loss 0.036061\n",
      "batch 1410: loss 0.015578\n",
      "batch 1411: loss 0.098147\n",
      "batch 1412: loss 0.015898\n",
      "batch 1413: loss 0.033092\n",
      "batch 1414: loss 0.026362\n",
      "batch 1415: loss 0.011523\n",
      "batch 1416: loss 0.037021\n",
      "batch 1417: loss 0.014091\n",
      "batch 1418: loss 0.016481\n",
      "batch 1419: loss 0.010903\n",
      "batch 1420: loss 0.012152\n",
      "batch 1421: loss 0.025187\n",
      "batch 1422: loss 0.032491\n",
      "batch 1423: loss 0.004865\n",
      "batch 1424: loss 0.006995\n",
      "batch 1425: loss 0.067879\n",
      "batch 1426: loss 0.028539\n",
      "batch 1427: loss 0.013905\n",
      "batch 1428: loss 0.034259\n",
      "batch 1429: loss 0.025372\n",
      "batch 1430: loss 0.010650\n",
      "batch 1431: loss 0.030488\n",
      "batch 1432: loss 0.012379\n",
      "batch 1433: loss 0.051256\n",
      "batch 1434: loss 0.023290\n",
      "batch 1435: loss 0.013590\n",
      "batch 1436: loss 0.015802\n",
      "batch 1437: loss 0.039278\n",
      "batch 1438: loss 0.151557\n",
      "batch 1439: loss 0.012759\n",
      "batch 1440: loss 0.092583\n",
      "batch 1441: loss 0.034284\n",
      "batch 1442: loss 0.043629\n",
      "batch 1443: loss 0.046328\n",
      "batch 1444: loss 0.042245\n",
      "batch 1445: loss 0.040010\n",
      "batch 1446: loss 0.015972\n",
      "batch 1447: loss 0.096352\n",
      "batch 1448: loss 0.037016\n",
      "batch 1449: loss 0.035215\n",
      "batch 1450: loss 0.035382\n",
      "batch 1451: loss 0.016495\n",
      "batch 1452: loss 0.012338\n",
      "batch 1453: loss 0.082316\n",
      "batch 1454: loss 0.017115\n",
      "batch 1455: loss 0.028544\n",
      "batch 1456: loss 0.027202\n",
      "batch 1457: loss 0.004639\n",
      "batch 1458: loss 0.039271\n",
      "batch 1459: loss 0.027817\n",
      "batch 1460: loss 0.025915\n",
      "batch 1461: loss 0.012652\n",
      "batch 1462: loss 0.013629\n",
      "batch 1463: loss 0.045382\n",
      "batch 1464: loss 0.048175\n",
      "batch 1465: loss 0.020579\n",
      "batch 1466: loss 0.014135\n",
      "batch 1467: loss 0.033847\n",
      "batch 1468: loss 0.049677\n",
      "batch 1469: loss 0.119819\n",
      "batch 1470: loss 0.005888\n",
      "batch 1471: loss 0.067591\n",
      "batch 1472: loss 0.037724\n",
      "batch 1473: loss 0.032949\n",
      "batch 1474: loss 0.029976\n",
      "batch 1475: loss 0.033091\n",
      "batch 1476: loss 0.057425\n",
      "batch 1477: loss 0.042420\n",
      "batch 1478: loss 0.011530\n",
      "batch 1479: loss 0.050793\n",
      "batch 1480: loss 0.018084\n",
      "batch 1481: loss 0.069741\n",
      "batch 1482: loss 0.010217\n",
      "batch 1483: loss 0.032565\n",
      "batch 1484: loss 0.024967\n",
      "batch 1485: loss 0.016229\n",
      "batch 1486: loss 0.025574\n",
      "batch 1487: loss 0.033564\n",
      "batch 1488: loss 0.020133\n",
      "batch 1489: loss 0.006909\n",
      "batch 1490: loss 0.029503\n",
      "batch 1491: loss 0.006209\n",
      "batch 1492: loss 0.037842\n",
      "batch 1493: loss 0.010048\n",
      "batch 1494: loss 0.073442\n",
      "batch 1495: loss 0.032881\n",
      "batch 1496: loss 0.006049\n",
      "batch 1497: loss 0.014697\n",
      "batch 1498: loss 0.006253\n",
      "batch 1499: loss 0.008047\n",
      "batch 1500: loss 0.016842\n",
      "batch 1501: loss 0.036691\n",
      "batch 1502: loss 0.073103\n",
      "batch 1503: loss 0.017987\n",
      "batch 1504: loss 0.007704\n",
      "batch 1505: loss 0.023650\n",
      "batch 1506: loss 0.025957\n",
      "batch 1507: loss 0.100888\n",
      "batch 1508: loss 0.003173\n",
      "batch 1509: loss 0.049045\n",
      "batch 1510: loss 0.027353\n",
      "batch 1511: loss 0.009035\n",
      "batch 1512: loss 0.034029\n",
      "batch 1513: loss 0.007265\n",
      "batch 1514: loss 0.097774\n",
      "batch 1515: loss 0.015374\n",
      "batch 1516: loss 0.006198\n",
      "batch 1517: loss 0.009832\n",
      "batch 1518: loss 0.007070\n",
      "batch 1519: loss 0.028246\n",
      "batch 1520: loss 0.016222\n",
      "batch 1521: loss 0.030808\n",
      "batch 1522: loss 0.015489\n",
      "batch 1523: loss 0.004373\n",
      "batch 1524: loss 0.035197\n",
      "batch 1525: loss 0.016891\n",
      "batch 1526: loss 0.009662\n",
      "batch 1527: loss 0.014916\n",
      "batch 1528: loss 0.020016\n",
      "batch 1529: loss 0.096648\n",
      "batch 1530: loss 0.012370\n",
      "batch 1531: loss 0.019005\n",
      "batch 1532: loss 0.006830\n",
      "batch 1533: loss 0.151361\n",
      "batch 1534: loss 0.016167\n",
      "batch 1535: loss 0.076389\n",
      "batch 1536: loss 0.026954\n",
      "batch 1537: loss 0.011027\n",
      "batch 1538: loss 0.021471\n",
      "batch 1539: loss 0.102247\n",
      "batch 1540: loss 0.044881\n",
      "batch 1541: loss 0.027495\n",
      "batch 1542: loss 0.031420\n",
      "batch 1543: loss 0.015906\n",
      "batch 1544: loss 0.007200\n",
      "batch 1545: loss 0.020133\n",
      "batch 1546: loss 0.264322\n",
      "batch 1547: loss 0.011978\n",
      "batch 1548: loss 0.013872\n",
      "batch 1549: loss 0.027178\n",
      "batch 1550: loss 0.009103\n",
      "batch 1551: loss 0.083442\n",
      "batch 1552: loss 0.018956\n",
      "batch 1553: loss 0.026241\n",
      "batch 1554: loss 0.019729\n",
      "batch 1555: loss 0.007567\n",
      "batch 1556: loss 0.015457\n",
      "batch 1557: loss 0.078577\n",
      "batch 1558: loss 0.015493\n",
      "batch 1559: loss 0.019007\n",
      "batch 1560: loss 0.020398\n",
      "batch 1561: loss 0.066370\n",
      "batch 1562: loss 0.005166\n",
      "batch 1563: loss 0.039128\n",
      "batch 1564: loss 0.045085\n",
      "batch 1565: loss 0.078994\n",
      "batch 1566: loss 0.012885\n",
      "batch 1567: loss 0.039912\n",
      "batch 1568: loss 0.002848\n",
      "batch 1569: loss 0.023658\n",
      "batch 1570: loss 0.010463\n",
      "batch 1571: loss 0.013776\n",
      "batch 1572: loss 0.078332\n",
      "batch 1573: loss 0.043454\n",
      "batch 1574: loss 0.081543\n",
      "batch 1575: loss 0.069428\n",
      "batch 1576: loss 0.058012\n",
      "batch 1577: loss 0.083188\n",
      "batch 1578: loss 0.008782\n",
      "batch 1579: loss 0.019315\n",
      "batch 1580: loss 0.044592\n",
      "batch 1581: loss 0.044951\n",
      "batch 1582: loss 0.092811\n",
      "batch 1583: loss 0.042274\n",
      "batch 1584: loss 0.020279\n",
      "batch 1585: loss 0.091709\n",
      "batch 1586: loss 0.010890\n",
      "batch 1587: loss 0.003657\n",
      "batch 1588: loss 0.070652\n",
      "batch 1589: loss 0.117974\n",
      "batch 1590: loss 0.074897\n",
      "batch 1591: loss 0.066882\n",
      "batch 1592: loss 0.005876\n",
      "batch 1593: loss 0.050036\n",
      "batch 1594: loss 0.004897\n",
      "batch 1595: loss 0.021630\n",
      "batch 1596: loss 0.010734\n",
      "batch 1597: loss 0.046504\n",
      "batch 1598: loss 0.161684\n",
      "batch 1599: loss 0.016174\n",
      "batch 1600: loss 0.020817\n",
      "batch 1601: loss 0.018813\n",
      "batch 1602: loss 0.049395\n",
      "batch 1603: loss 0.039334\n",
      "batch 1604: loss 0.079551\n",
      "batch 1605: loss 0.143884\n",
      "batch 1606: loss 0.024042\n",
      "batch 1607: loss 0.133775\n",
      "batch 1608: loss 0.021932\n",
      "batch 1609: loss 0.055196\n",
      "batch 1610: loss 0.013451\n",
      "batch 1611: loss 0.030124\n",
      "batch 1612: loss 0.012820\n",
      "batch 1613: loss 0.008518\n",
      "batch 1614: loss 0.017986\n",
      "batch 1615: loss 0.008377\n",
      "batch 1616: loss 0.005246\n",
      "batch 1617: loss 0.079553\n",
      "batch 1618: loss 0.012772\n",
      "batch 1619: loss 0.162411\n",
      "batch 1620: loss 0.025014\n",
      "batch 1621: loss 0.007462\n",
      "batch 1622: loss 0.060372\n",
      "batch 1623: loss 0.015901\n",
      "batch 1624: loss 0.042063\n",
      "batch 1625: loss 0.064425\n",
      "batch 1626: loss 0.035695\n",
      "batch 1627: loss 0.014596\n",
      "batch 1628: loss 0.017203\n",
      "batch 1629: loss 0.042700\n",
      "batch 1630: loss 0.019150\n",
      "batch 1631: loss 0.011600\n",
      "batch 1632: loss 0.013974\n",
      "batch 1633: loss 0.022929\n",
      "batch 1634: loss 0.011453\n",
      "batch 1635: loss 0.040893\n",
      "batch 1636: loss 0.061859\n",
      "batch 1637: loss 0.021400\n",
      "batch 1638: loss 0.081307\n",
      "batch 1639: loss 0.037054\n",
      "batch 1640: loss 0.031982\n",
      "batch 1641: loss 0.021986\n",
      "batch 1642: loss 0.036810\n",
      "batch 1643: loss 0.103222\n",
      "batch 1644: loss 0.106143\n",
      "batch 1645: loss 0.034755\n",
      "batch 1646: loss 0.080247\n",
      "batch 1647: loss 0.024975\n",
      "batch 1648: loss 0.007322\n",
      "batch 1649: loss 0.035575\n",
      "batch 1650: loss 0.005109\n",
      "batch 1651: loss 0.039950\n",
      "batch 1652: loss 0.009731\n",
      "batch 1653: loss 0.005112\n",
      "batch 1654: loss 0.070092\n",
      "batch 1655: loss 0.031218\n",
      "batch 1656: loss 0.038532\n",
      "batch 1657: loss 0.004300\n",
      "batch 1658: loss 0.031712\n",
      "batch 1659: loss 0.207409\n",
      "batch 1660: loss 0.018552\n",
      "batch 1661: loss 0.075059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1662: loss 0.005768\n",
      "batch 1663: loss 0.038207\n",
      "batch 1664: loss 0.011863\n",
      "batch 1665: loss 0.025584\n",
      "batch 1666: loss 0.044499\n",
      "batch 1667: loss 0.060639\n",
      "batch 1668: loss 0.079852\n",
      "batch 1669: loss 0.112040\n",
      "batch 1670: loss 0.045183\n",
      "batch 1671: loss 0.147740\n",
      "batch 1672: loss 0.007088\n",
      "batch 1673: loss 0.014326\n",
      "batch 1674: loss 0.025540\n",
      "batch 1675: loss 0.073377\n",
      "batch 1676: loss 0.014740\n",
      "batch 1677: loss 0.034976\n",
      "batch 1678: loss 0.012051\n",
      "batch 1679: loss 0.025508\n",
      "batch 1680: loss 0.023885\n",
      "batch 1681: loss 0.009827\n",
      "batch 1682: loss 0.112564\n",
      "batch 1683: loss 0.009741\n",
      "batch 1684: loss 0.048073\n",
      "batch 1685: loss 0.008796\n",
      "batch 1686: loss 0.045771\n",
      "batch 1687: loss 0.213729\n",
      "batch 1688: loss 0.026432\n",
      "batch 1689: loss 0.014901\n",
      "batch 1690: loss 0.002503\n",
      "batch 1691: loss 0.030869\n",
      "batch 1692: loss 0.052234\n",
      "batch 1693: loss 0.074020\n",
      "batch 1694: loss 0.073794\n",
      "batch 1695: loss 0.004448\n",
      "batch 1696: loss 0.026388\n",
      "batch 1697: loss 0.008915\n",
      "batch 1698: loss 0.019380\n",
      "batch 1699: loss 0.005726\n",
      "batch 1700: loss 0.019864\n",
      "batch 1701: loss 0.045746\n",
      "batch 1702: loss 0.023314\n",
      "batch 1703: loss 0.090940\n",
      "batch 1704: loss 0.024372\n",
      "batch 1705: loss 0.013009\n",
      "batch 1706: loss 0.034482\n",
      "batch 1707: loss 0.045590\n",
      "batch 1708: loss 0.007540\n",
      "batch 1709: loss 0.043048\n",
      "batch 1710: loss 0.032553\n",
      "batch 1711: loss 0.084632\n",
      "batch 1712: loss 0.026894\n",
      "batch 1713: loss 0.084664\n",
      "batch 1714: loss 0.032733\n",
      "batch 1715: loss 0.027914\n",
      "batch 1716: loss 0.012308\n",
      "batch 1717: loss 0.235301\n",
      "batch 1718: loss 0.063348\n",
      "batch 1719: loss 0.033927\n",
      "batch 1720: loss 0.056587\n",
      "batch 1721: loss 0.016897\n",
      "batch 1722: loss 0.085402\n",
      "batch 1723: loss 0.080922\n",
      "batch 1724: loss 0.007041\n",
      "batch 1725: loss 0.014878\n",
      "batch 1726: loss 0.010226\n",
      "batch 1727: loss 0.032763\n",
      "batch 1728: loss 0.052376\n",
      "batch 1729: loss 0.087242\n",
      "batch 1730: loss 0.018210\n",
      "batch 1731: loss 0.060108\n",
      "batch 1732: loss 0.035145\n",
      "batch 1733: loss 0.043128\n",
      "batch 1734: loss 0.027073\n",
      "batch 1735: loss 0.229632\n",
      "batch 1736: loss 0.020791\n",
      "batch 1737: loss 0.016688\n",
      "batch 1738: loss 0.088114\n",
      "batch 1739: loss 0.004097\n",
      "batch 1740: loss 0.014503\n",
      "batch 1741: loss 0.029630\n",
      "batch 1742: loss 0.008114\n",
      "batch 1743: loss 0.033663\n",
      "batch 1744: loss 0.006801\n",
      "batch 1745: loss 0.032896\n",
      "batch 1746: loss 0.006211\n",
      "batch 1747: loss 0.028907\n",
      "batch 1748: loss 0.131451\n",
      "batch 1749: loss 0.057097\n",
      "batch 1750: loss 0.032979\n",
      "batch 1751: loss 0.034684\n",
      "batch 1752: loss 0.054372\n",
      "batch 1753: loss 0.124395\n",
      "batch 1754: loss 0.006134\n",
      "batch 1755: loss 0.015951\n",
      "batch 1756: loss 0.040893\n",
      "batch 1757: loss 0.016368\n",
      "batch 1758: loss 0.031573\n",
      "batch 1759: loss 0.045168\n",
      "batch 1760: loss 0.018834\n",
      "batch 1761: loss 0.036781\n",
      "batch 1762: loss 0.035423\n",
      "batch 1763: loss 0.019307\n",
      "batch 1764: loss 0.023272\n",
      "batch 1765: loss 0.081977\n",
      "batch 1766: loss 0.046230\n",
      "batch 1767: loss 0.007941\n",
      "batch 1768: loss 0.029959\n",
      "batch 1769: loss 0.044723\n",
      "batch 1770: loss 0.061575\n",
      "batch 1771: loss 0.016051\n",
      "batch 1772: loss 0.026804\n",
      "batch 1773: loss 0.028948\n",
      "batch 1774: loss 0.049795\n",
      "batch 1775: loss 0.031393\n",
      "batch 1776: loss 0.005271\n",
      "batch 1777: loss 0.015134\n",
      "batch 1778: loss 0.006645\n",
      "batch 1779: loss 0.009587\n",
      "batch 1780: loss 0.033521\n",
      "batch 1781: loss 0.030477\n",
      "batch 1782: loss 0.018535\n",
      "batch 1783: loss 0.005737\n",
      "batch 1784: loss 0.009869\n",
      "batch 1785: loss 0.119160\n",
      "batch 1786: loss 0.001659\n",
      "batch 1787: loss 0.039368\n",
      "batch 1788: loss 0.029591\n",
      "batch 1789: loss 0.032038\n",
      "batch 1790: loss 0.004544\n",
      "batch 1791: loss 0.004771\n",
      "batch 1792: loss 0.005343\n",
      "batch 1793: loss 0.005360\n",
      "batch 1794: loss 0.041817\n",
      "batch 1795: loss 0.040961\n",
      "batch 1796: loss 0.090336\n",
      "batch 1797: loss 0.065884\n",
      "batch 1798: loss 0.059188\n",
      "batch 1799: loss 0.030985\n",
      "batch 1800: loss 0.010815\n",
      "batch 1801: loss 0.018941\n",
      "batch 1802: loss 0.017785\n",
      "batch 1803: loss 0.011491\n",
      "batch 1804: loss 0.004793\n",
      "batch 1805: loss 0.130917\n",
      "batch 1806: loss 0.013055\n",
      "batch 1807: loss 0.011538\n",
      "batch 1808: loss 0.019081\n",
      "batch 1809: loss 0.009631\n",
      "batch 1810: loss 0.008474\n",
      "batch 1811: loss 0.026781\n",
      "batch 1812: loss 0.118055\n",
      "batch 1813: loss 0.055920\n",
      "batch 1814: loss 0.080092\n",
      "batch 1815: loss 0.037539\n",
      "batch 1816: loss 0.075226\n",
      "batch 1817: loss 0.023780\n",
      "batch 1818: loss 0.120607\n",
      "batch 1819: loss 0.072110\n",
      "batch 1820: loss 0.060451\n",
      "batch 1821: loss 0.026365\n",
      "batch 1822: loss 0.009843\n",
      "batch 1823: loss 0.006295\n",
      "batch 1824: loss 0.042120\n",
      "batch 1825: loss 0.045428\n",
      "batch 1826: loss 0.030139\n",
      "batch 1827: loss 0.112728\n",
      "batch 1828: loss 0.096663\n",
      "batch 1829: loss 0.007475\n",
      "batch 1830: loss 0.012625\n",
      "batch 1831: loss 0.007088\n",
      "batch 1832: loss 0.126974\n",
      "batch 1833: loss 0.044080\n",
      "batch 1834: loss 0.131813\n",
      "batch 1835: loss 0.011812\n",
      "batch 1836: loss 0.070772\n",
      "batch 1837: loss 0.012401\n",
      "batch 1838: loss 0.106900\n",
      "batch 1839: loss 0.032413\n",
      "batch 1840: loss 0.050536\n",
      "batch 1841: loss 0.022349\n",
      "batch 1842: loss 0.007134\n",
      "batch 1843: loss 0.051094\n",
      "batch 1844: loss 0.008844\n",
      "batch 1845: loss 0.031183\n",
      "batch 1846: loss 0.049464\n",
      "batch 1847: loss 0.018929\n",
      "batch 1848: loss 0.018284\n",
      "batch 1849: loss 0.063571\n",
      "batch 1850: loss 0.112214\n",
      "batch 1851: loss 0.045498\n",
      "batch 1852: loss 0.027692\n",
      "batch 1853: loss 0.006182\n",
      "batch 1854: loss 0.024040\n",
      "batch 1855: loss 0.028570\n",
      "batch 1856: loss 0.017217\n",
      "batch 1857: loss 0.036299\n",
      "batch 1858: loss 0.023440\n",
      "batch 1859: loss 0.211034\n",
      "batch 1860: loss 0.057095\n",
      "batch 1861: loss 0.006348\n",
      "batch 1862: loss 0.008842\n",
      "batch 1863: loss 0.067480\n",
      "batch 1864: loss 0.022295\n",
      "batch 1865: loss 0.070475\n",
      "batch 1866: loss 0.132907\n",
      "batch 1867: loss 0.035143\n",
      "batch 1868: loss 0.006424\n",
      "batch 1869: loss 0.031597\n",
      "batch 1870: loss 0.012230\n",
      "batch 1871: loss 0.008275\n",
      "batch 1872: loss 0.054710\n",
      "batch 1873: loss 0.147346\n",
      "batch 1874: loss 0.004686\n",
      "batch 1875: loss 0.021771\n",
      "batch 1876: loss 0.009950\n",
      "batch 1877: loss 0.013515\n",
      "batch 1878: loss 0.013014\n",
      "batch 1879: loss 0.018147\n",
      "batch 1880: loss 0.023035\n",
      "batch 1881: loss 0.011846\n",
      "batch 1882: loss 0.009276\n",
      "batch 1883: loss 0.128238\n",
      "batch 1884: loss 0.015215\n",
      "batch 1885: loss 0.042905\n",
      "batch 1886: loss 0.002559\n",
      "batch 1887: loss 0.036452\n",
      "batch 1888: loss 0.055103\n",
      "batch 1889: loss 0.068536\n",
      "batch 1890: loss 0.060242\n",
      "batch 1891: loss 0.016953\n",
      "batch 1892: loss 0.013637\n",
      "batch 1893: loss 0.005399\n",
      "batch 1894: loss 0.009423\n",
      "batch 1895: loss 0.003469\n",
      "batch 1896: loss 0.052574\n",
      "batch 1897: loss 0.012786\n",
      "batch 1898: loss 0.017498\n",
      "batch 1899: loss 0.050194\n",
      "batch 1900: loss 0.111110\n",
      "batch 1901: loss 0.008461\n",
      "batch 1902: loss 0.044003\n",
      "batch 1903: loss 0.026013\n",
      "batch 1904: loss 0.023960\n",
      "batch 1905: loss 0.060007\n",
      "batch 1906: loss 0.031149\n",
      "batch 1907: loss 0.019651\n",
      "batch 1908: loss 0.011973\n",
      "batch 1909: loss 0.010700\n",
      "batch 1910: loss 0.008163\n",
      "batch 1911: loss 0.078245\n",
      "batch 1912: loss 0.013971\n",
      "batch 1913: loss 0.001578\n",
      "batch 1914: loss 0.047852\n",
      "batch 1915: loss 0.018046\n",
      "batch 1916: loss 0.151014\n",
      "batch 1917: loss 0.001692\n",
      "batch 1918: loss 0.044892\n",
      "batch 1919: loss 0.058189\n",
      "batch 1920: loss 0.005466\n",
      "batch 1921: loss 0.012056\n",
      "batch 1922: loss 0.005202\n",
      "batch 1923: loss 0.044944\n",
      "batch 1924: loss 0.027851\n",
      "batch 1925: loss 0.003611\n",
      "batch 1926: loss 0.007732\n",
      "batch 1927: loss 0.013899\n",
      "batch 1928: loss 0.004734\n",
      "batch 1929: loss 0.026649\n",
      "batch 1930: loss 0.011646\n",
      "batch 1931: loss 0.045132\n",
      "batch 1932: loss 0.019975\n",
      "batch 1933: loss 0.055113\n",
      "batch 1934: loss 0.056265\n",
      "batch 1935: loss 0.077239\n",
      "batch 1936: loss 0.005438\n",
      "batch 1937: loss 0.024285\n",
      "batch 1938: loss 0.017222\n",
      "batch 1939: loss 0.019367\n",
      "batch 1940: loss 0.009256\n",
      "batch 1941: loss 0.063890\n",
      "batch 1942: loss 0.032181\n",
      "batch 1943: loss 0.035345\n",
      "batch 1944: loss 0.003260\n",
      "batch 1945: loss 0.012099\n",
      "batch 1946: loss 0.036454\n",
      "batch 1947: loss 0.027004\n",
      "batch 1948: loss 0.030448\n",
      "batch 1949: loss 0.014669\n",
      "batch 1950: loss 0.026886\n",
      "batch 1951: loss 0.031065\n",
      "batch 1952: loss 0.004507\n",
      "batch 1953: loss 0.024300\n",
      "batch 1954: loss 0.004449\n",
      "batch 1955: loss 0.032038\n",
      "batch 1956: loss 0.002097\n",
      "batch 1957: loss 0.007604\n",
      "batch 1958: loss 0.008039\n",
      "batch 1959: loss 0.027393\n",
      "batch 1960: loss 0.020159\n",
      "batch 1961: loss 0.031490\n",
      "batch 1962: loss 0.019919\n",
      "batch 1963: loss 0.004754\n",
      "batch 1964: loss 0.029791\n",
      "batch 1965: loss 0.002482\n",
      "batch 1966: loss 0.021739\n",
      "batch 1967: loss 0.015118\n",
      "batch 1968: loss 0.133754\n",
      "batch 1969: loss 0.094438\n",
      "batch 1970: loss 0.019872\n",
      "batch 1971: loss 0.069164\n",
      "batch 1972: loss 0.030148\n",
      "batch 1973: loss 0.010286\n",
      "batch 1974: loss 0.109333\n",
      "batch 1975: loss 0.016317\n",
      "batch 1976: loss 0.012940\n",
      "batch 1977: loss 0.002921\n",
      "batch 1978: loss 0.042038\n",
      "batch 1979: loss 0.008076\n",
      "batch 1980: loss 0.009429\n",
      "batch 1981: loss 0.030648\n",
      "batch 1982: loss 0.106431\n",
      "batch 1983: loss 0.036800\n",
      "batch 1984: loss 0.005730\n",
      "batch 1985: loss 0.009301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 1986: loss 0.007737\n",
      "batch 1987: loss 0.002060\n",
      "batch 1988: loss 0.004504\n",
      "batch 1989: loss 0.006448\n",
      "batch 1990: loss 0.127662\n",
      "batch 1991: loss 0.022635\n",
      "batch 1992: loss 0.012209\n",
      "batch 1993: loss 0.008804\n",
      "batch 1994: loss 0.011305\n",
      "batch 1995: loss 0.071045\n",
      "batch 1996: loss 0.043240\n",
      "batch 1997: loss 0.016558\n",
      "batch 1998: loss 0.002004\n",
      "batch 1999: loss 0.047954\n",
      "batch 2000: loss 0.004894\n",
      "batch 2001: loss 0.005427\n",
      "batch 2002: loss 0.010343\n",
      "batch 2003: loss 0.022711\n",
      "batch 2004: loss 0.060528\n",
      "batch 2005: loss 0.019057\n",
      "batch 2006: loss 0.051824\n",
      "batch 2007: loss 0.038226\n",
      "batch 2008: loss 0.014305\n",
      "batch 2009: loss 0.006984\n",
      "batch 2010: loss 0.038668\n",
      "batch 2011: loss 0.010141\n",
      "batch 2012: loss 0.044087\n",
      "batch 2013: loss 0.028736\n",
      "batch 2014: loss 0.010899\n",
      "batch 2015: loss 0.014044\n",
      "batch 2016: loss 0.006110\n",
      "batch 2017: loss 0.010152\n",
      "batch 2018: loss 0.014535\n",
      "batch 2019: loss 0.062941\n",
      "batch 2020: loss 0.010763\n",
      "batch 2021: loss 0.005301\n",
      "batch 2022: loss 0.050239\n",
      "batch 2023: loss 0.018759\n",
      "batch 2024: loss 0.067229\n",
      "batch 2025: loss 0.016548\n",
      "batch 2026: loss 0.019384\n",
      "batch 2027: loss 0.009872\n",
      "batch 2028: loss 0.014318\n",
      "batch 2029: loss 0.047740\n",
      "batch 2030: loss 0.020238\n",
      "batch 2031: loss 0.005616\n",
      "batch 2032: loss 0.007653\n",
      "batch 2033: loss 0.020167\n",
      "batch 2034: loss 0.024478\n",
      "batch 2035: loss 0.026895\n",
      "batch 2036: loss 0.055543\n",
      "batch 2037: loss 0.014087\n",
      "batch 2038: loss 0.066193\n",
      "batch 2039: loss 0.199492\n",
      "batch 2040: loss 0.018962\n",
      "batch 2041: loss 0.013710\n",
      "batch 2042: loss 0.003537\n",
      "batch 2043: loss 0.016386\n",
      "batch 2044: loss 0.018263\n",
      "batch 2045: loss 0.022112\n",
      "batch 2046: loss 0.029724\n",
      "batch 2047: loss 0.120709\n",
      "batch 2048: loss 0.056661\n",
      "batch 2049: loss 0.010854\n",
      "batch 2050: loss 0.009843\n",
      "batch 2051: loss 0.026051\n",
      "batch 2052: loss 0.100495\n",
      "batch 2053: loss 0.296578\n",
      "batch 2054: loss 0.020027\n",
      "batch 2055: loss 0.085747\n",
      "batch 2056: loss 0.019132\n",
      "batch 2057: loss 0.046804\n",
      "batch 2058: loss 0.007627\n",
      "batch 2059: loss 0.013884\n",
      "batch 2060: loss 0.007080\n",
      "batch 2061: loss 0.080050\n",
      "batch 2062: loss 0.006144\n",
      "batch 2063: loss 0.012910\n",
      "batch 2064: loss 0.024914\n",
      "batch 2065: loss 0.022423\n",
      "batch 2066: loss 0.006182\n",
      "batch 2067: loss 0.084432\n",
      "batch 2068: loss 0.023346\n",
      "batch 2069: loss 0.057639\n",
      "batch 2070: loss 0.011710\n",
      "batch 2071: loss 0.068168\n",
      "batch 2072: loss 0.298168\n",
      "batch 2073: loss 0.059558\n",
      "batch 2074: loss 0.044330\n",
      "batch 2075: loss 0.027866\n",
      "batch 2076: loss 0.027223\n",
      "batch 2077: loss 0.052968\n",
      "batch 2078: loss 0.082064\n",
      "batch 2079: loss 0.040973\n",
      "batch 2080: loss 0.030510\n",
      "batch 2081: loss 0.004211\n",
      "batch 2082: loss 0.027907\n",
      "batch 2083: loss 0.026846\n",
      "batch 2084: loss 0.047213\n",
      "batch 2085: loss 0.036091\n",
      "batch 2086: loss 0.026190\n",
      "batch 2087: loss 0.009617\n",
      "batch 2088: loss 0.028358\n",
      "batch 2089: loss 0.029939\n",
      "batch 2090: loss 0.006926\n",
      "batch 2091: loss 0.004367\n",
      "batch 2092: loss 0.018004\n",
      "batch 2093: loss 0.007361\n",
      "batch 2094: loss 0.026691\n",
      "batch 2095: loss 0.016226\n",
      "batch 2096: loss 0.054260\n",
      "batch 2097: loss 0.012024\n",
      "batch 2098: loss 0.031213\n",
      "batch 2099: loss 0.017540\n",
      "batch 2100: loss 0.040514\n",
      "batch 2101: loss 0.025594\n",
      "batch 2102: loss 0.144644\n",
      "batch 2103: loss 0.082178\n",
      "batch 2104: loss 0.010325\n",
      "batch 2105: loss 0.018160\n",
      "batch 2106: loss 0.017064\n",
      "batch 2107: loss 0.013883\n",
      "batch 2108: loss 0.059961\n",
      "batch 2109: loss 0.032385\n",
      "batch 2110: loss 0.010800\n",
      "batch 2111: loss 0.007310\n",
      "batch 2112: loss 0.065631\n",
      "batch 2113: loss 0.055048\n",
      "batch 2114: loss 0.034264\n",
      "batch 2115: loss 0.009172\n",
      "batch 2116: loss 0.010242\n",
      "batch 2117: loss 0.020534\n",
      "batch 2118: loss 0.079349\n",
      "batch 2119: loss 0.009955\n",
      "batch 2120: loss 0.012683\n",
      "batch 2121: loss 0.038936\n",
      "batch 2122: loss 0.026198\n",
      "batch 2123: loss 0.044087\n",
      "batch 2124: loss 0.028354\n",
      "batch 2125: loss 0.016945\n",
      "batch 2126: loss 0.006164\n",
      "batch 2127: loss 0.022499\n",
      "batch 2128: loss 0.019301\n",
      "batch 2129: loss 0.076784\n",
      "batch 2130: loss 0.208253\n",
      "batch 2131: loss 0.017303\n",
      "batch 2132: loss 0.034915\n",
      "batch 2133: loss 0.017229\n",
      "batch 2134: loss 0.012813\n",
      "batch 2135: loss 0.059070\n",
      "batch 2136: loss 0.037820\n",
      "batch 2137: loss 0.016321\n",
      "batch 2138: loss 0.104661\n",
      "batch 2139: loss 0.022953\n",
      "batch 2140: loss 0.033556\n",
      "batch 2141: loss 0.018815\n",
      "batch 2142: loss 0.015492\n",
      "batch 2143: loss 0.009765\n",
      "batch 2144: loss 0.132776\n",
      "batch 2145: loss 0.009096\n",
      "batch 2146: loss 0.058415\n",
      "batch 2147: loss 0.181434\n",
      "batch 2148: loss 0.075259\n",
      "batch 2149: loss 0.032882\n",
      "batch 2150: loss 0.015799\n",
      "batch 2151: loss 0.025444\n",
      "batch 2152: loss 0.055400\n",
      "batch 2153: loss 0.059673\n",
      "batch 2154: loss 0.031652\n",
      "batch 2155: loss 0.019463\n",
      "batch 2156: loss 0.007239\n",
      "batch 2157: loss 0.147015\n",
      "batch 2158: loss 0.002192\n",
      "batch 2159: loss 0.020612\n",
      "batch 2160: loss 0.021013\n",
      "batch 2161: loss 0.064616\n",
      "batch 2162: loss 0.010776\n",
      "batch 2163: loss 0.012801\n",
      "batch 2164: loss 0.005832\n",
      "batch 2165: loss 0.010714\n",
      "batch 2166: loss 0.003871\n",
      "batch 2167: loss 0.009018\n",
      "batch 2168: loss 0.005261\n",
      "batch 2169: loss 0.003043\n",
      "batch 2170: loss 0.012479\n",
      "batch 2171: loss 0.039968\n",
      "batch 2172: loss 0.061091\n",
      "batch 2173: loss 0.015544\n",
      "batch 2174: loss 0.051566\n",
      "batch 2175: loss 0.004570\n",
      "batch 2176: loss 0.023288\n",
      "batch 2177: loss 0.062777\n",
      "batch 2178: loss 0.014471\n",
      "batch 2179: loss 0.007193\n",
      "batch 2180: loss 0.052448\n",
      "batch 2181: loss 0.004674\n",
      "batch 2182: loss 0.015200\n",
      "batch 2183: loss 0.016162\n",
      "batch 2184: loss 0.045237\n",
      "batch 2185: loss 0.043401\n",
      "batch 2186: loss 0.093784\n",
      "batch 2187: loss 0.022727\n",
      "batch 2188: loss 0.017351\n",
      "batch 2189: loss 0.006569\n",
      "batch 2190: loss 0.051503\n",
      "batch 2191: loss 0.036546\n",
      "batch 2192: loss 0.014426\n",
      "batch 2193: loss 0.064204\n",
      "batch 2194: loss 0.016176\n",
      "batch 2195: loss 0.055438\n",
      "batch 2196: loss 0.045987\n",
      "batch 2197: loss 0.064808\n",
      "batch 2198: loss 0.020264\n",
      "batch 2199: loss 0.019555\n",
      "batch 2200: loss 0.003281\n",
      "batch 2201: loss 0.010060\n",
      "batch 2202: loss 0.007355\n",
      "batch 2203: loss 0.010018\n",
      "batch 2204: loss 0.028883\n",
      "batch 2205: loss 0.021195\n",
      "batch 2206: loss 0.020935\n",
      "batch 2207: loss 0.037549\n",
      "batch 2208: loss 0.035722\n",
      "batch 2209: loss 0.009357\n",
      "batch 2210: loss 0.049393\n",
      "batch 2211: loss 0.016014\n",
      "batch 2212: loss 0.021408\n",
      "batch 2213: loss 0.011697\n",
      "batch 2214: loss 0.011675\n",
      "batch 2215: loss 0.148559\n",
      "batch 2216: loss 0.013426\n",
      "batch 2217: loss 0.024344\n",
      "batch 2218: loss 0.004660\n",
      "batch 2219: loss 0.005101\n",
      "batch 2220: loss 0.024856\n",
      "batch 2221: loss 0.042060\n",
      "batch 2222: loss 0.052110\n",
      "batch 2223: loss 0.005814\n",
      "batch 2224: loss 0.049686\n",
      "batch 2225: loss 0.052680\n",
      "batch 2226: loss 0.009325\n",
      "batch 2227: loss 0.047484\n",
      "batch 2228: loss 0.008523\n",
      "batch 2229: loss 0.055094\n",
      "batch 2230: loss 0.067104\n",
      "batch 2231: loss 0.081843\n",
      "batch 2232: loss 0.030975\n",
      "batch 2233: loss 0.008426\n",
      "batch 2234: loss 0.127253\n",
      "batch 2235: loss 0.038865\n",
      "batch 2236: loss 0.036448\n",
      "batch 2237: loss 0.044268\n",
      "batch 2238: loss 0.035806\n",
      "batch 2239: loss 0.032401\n",
      "batch 2240: loss 0.025757\n",
      "batch 2241: loss 0.015527\n",
      "batch 2242: loss 0.010826\n",
      "batch 2243: loss 0.020264\n",
      "batch 2244: loss 0.035110\n",
      "batch 2245: loss 0.002154\n",
      "batch 2246: loss 0.018543\n",
      "batch 2247: loss 0.007788\n",
      "batch 2248: loss 0.027671\n",
      "batch 2249: loss 0.007679\n",
      "batch 2250: loss 0.038750\n",
      "batch 2251: loss 0.005887\n",
      "batch 2252: loss 0.017755\n",
      "batch 2253: loss 0.014301\n",
      "batch 2254: loss 0.014793\n",
      "batch 2255: loss 0.060827\n",
      "batch 2256: loss 0.009273\n",
      "batch 2257: loss 0.079730\n",
      "batch 2258: loss 0.042165\n",
      "batch 2259: loss 0.014824\n",
      "batch 2260: loss 0.048589\n",
      "batch 2261: loss 0.008871\n",
      "batch 2262: loss 0.013545\n",
      "batch 2263: loss 0.014017\n",
      "batch 2264: loss 0.023895\n",
      "batch 2265: loss 0.011373\n",
      "batch 2266: loss 0.014888\n",
      "batch 2267: loss 0.005033\n",
      "batch 2268: loss 0.061836\n",
      "batch 2269: loss 0.024011\n",
      "batch 2270: loss 0.021630\n",
      "batch 2271: loss 0.028824\n",
      "batch 2272: loss 0.012999\n",
      "batch 2273: loss 0.038474\n",
      "batch 2274: loss 0.008920\n",
      "batch 2275: loss 0.009980\n",
      "batch 2276: loss 0.008180\n",
      "batch 2277: loss 0.013127\n",
      "batch 2278: loss 0.044090\n",
      "batch 2279: loss 0.075433\n",
      "batch 2280: loss 0.014699\n",
      "batch 2281: loss 0.028696\n",
      "batch 2282: loss 0.004956\n",
      "batch 2283: loss 0.114939\n",
      "batch 2284: loss 0.012129\n",
      "batch 2285: loss 0.010753\n",
      "batch 2286: loss 0.039035\n",
      "batch 2287: loss 0.010953\n",
      "batch 2288: loss 0.017814\n",
      "batch 2289: loss 0.016370\n",
      "batch 2290: loss 0.017477\n",
      "batch 2291: loss 0.026896\n",
      "batch 2292: loss 0.021496\n",
      "batch 2293: loss 0.035127\n",
      "batch 2294: loss 0.023666\n",
      "batch 2295: loss 0.032384\n",
      "batch 2296: loss 0.009559\n",
      "batch 2297: loss 0.011837\n",
      "batch 2298: loss 0.068687\n",
      "batch 2299: loss 0.049719\n",
      "batch 2300: loss 0.003419\n",
      "batch 2301: loss 0.003037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2302: loss 0.002763\n",
      "batch 2303: loss 0.024083\n",
      "batch 2304: loss 0.049028\n",
      "batch 2305: loss 0.011181\n",
      "batch 2306: loss 0.022654\n",
      "batch 2307: loss 0.023869\n",
      "batch 2308: loss 0.078209\n",
      "batch 2309: loss 0.020398\n",
      "batch 2310: loss 0.012684\n",
      "batch 2311: loss 0.134803\n",
      "batch 2312: loss 0.006810\n",
      "batch 2313: loss 0.078450\n",
      "batch 2314: loss 0.032086\n",
      "batch 2315: loss 0.014705\n",
      "batch 2316: loss 0.017439\n",
      "batch 2317: loss 0.014691\n",
      "batch 2318: loss 0.049319\n",
      "batch 2319: loss 0.015561\n",
      "batch 2320: loss 0.054366\n",
      "batch 2321: loss 0.067174\n",
      "batch 2322: loss 0.011041\n",
      "batch 2323: loss 0.017035\n",
      "batch 2324: loss 0.086789\n",
      "batch 2325: loss 0.057208\n",
      "batch 2326: loss 0.008631\n",
      "batch 2327: loss 0.036468\n",
      "batch 2328: loss 0.042507\n",
      "batch 2329: loss 0.031090\n",
      "batch 2330: loss 0.011858\n",
      "batch 2331: loss 0.024197\n",
      "batch 2332: loss 0.130480\n",
      "batch 2333: loss 0.090197\n",
      "batch 2334: loss 0.012938\n",
      "batch 2335: loss 0.008972\n",
      "batch 2336: loss 0.004590\n",
      "batch 2337: loss 0.084543\n",
      "batch 2338: loss 0.041634\n",
      "batch 2339: loss 0.095743\n",
      "batch 2340: loss 0.005361\n",
      "batch 2341: loss 0.038710\n",
      "batch 2342: loss 0.018746\n",
      "batch 2343: loss 0.002498\n",
      "batch 2344: loss 0.045291\n",
      "batch 2345: loss 0.009430\n",
      "batch 2346: loss 0.029454\n",
      "batch 2347: loss 0.003640\n",
      "batch 2348: loss 0.020151\n",
      "batch 2349: loss 0.012225\n",
      "batch 2350: loss 0.010788\n",
      "batch 2351: loss 0.016327\n",
      "batch 2352: loss 0.030888\n",
      "batch 2353: loss 0.026711\n",
      "batch 2354: loss 0.009488\n",
      "batch 2355: loss 0.008486\n",
      "batch 2356: loss 0.009024\n",
      "batch 2357: loss 0.050719\n",
      "batch 2358: loss 0.049865\n",
      "batch 2359: loss 0.068767\n",
      "batch 2360: loss 0.028240\n",
      "batch 2361: loss 0.024179\n",
      "batch 2362: loss 0.024022\n",
      "batch 2363: loss 0.047404\n",
      "batch 2364: loss 0.010542\n",
      "batch 2365: loss 0.127088\n",
      "batch 2366: loss 0.025351\n",
      "batch 2367: loss 0.014921\n",
      "batch 2368: loss 0.004403\n",
      "batch 2369: loss 0.034146\n",
      "batch 2370: loss 0.003523\n",
      "batch 2371: loss 0.102707\n",
      "batch 2372: loss 0.008863\n",
      "batch 2373: loss 0.054638\n",
      "batch 2374: loss 0.008870\n",
      "batch 2375: loss 0.007135\n",
      "batch 2376: loss 0.009111\n",
      "batch 2377: loss 0.030514\n",
      "batch 2378: loss 0.016685\n",
      "batch 2379: loss 0.003444\n",
      "batch 2380: loss 0.124170\n",
      "batch 2381: loss 0.189073\n",
      "batch 2382: loss 0.009229\n",
      "batch 2383: loss 0.026977\n",
      "batch 2384: loss 0.039451\n",
      "batch 2385: loss 0.023389\n",
      "batch 2386: loss 0.111040\n",
      "batch 2387: loss 0.030699\n",
      "batch 2388: loss 0.066451\n",
      "batch 2389: loss 0.030992\n",
      "batch 2390: loss 0.004786\n",
      "batch 2391: loss 0.003739\n",
      "batch 2392: loss 0.035646\n",
      "batch 2393: loss 0.004878\n",
      "batch 2394: loss 0.142310\n",
      "batch 2395: loss 0.032952\n",
      "batch 2396: loss 0.020670\n",
      "batch 2397: loss 0.005862\n",
      "batch 2398: loss 0.027795\n",
      "batch 2399: loss 0.022856\n",
      "batch 2400: loss 0.057881\n",
      "batch 2401: loss 0.017898\n",
      "batch 2402: loss 0.031069\n",
      "batch 2403: loss 0.015436\n",
      "batch 2404: loss 0.005088\n",
      "batch 2405: loss 0.094518\n",
      "batch 2406: loss 0.011137\n",
      "batch 2407: loss 0.039450\n",
      "batch 2408: loss 0.028577\n",
      "batch 2409: loss 0.007945\n",
      "batch 2410: loss 0.029110\n",
      "batch 2411: loss 0.061506\n",
      "batch 2412: loss 0.006395\n",
      "batch 2413: loss 0.112542\n",
      "batch 2414: loss 0.006818\n",
      "batch 2415: loss 0.126882\n",
      "batch 2416: loss 0.010231\n",
      "batch 2417: loss 0.034893\n",
      "batch 2418: loss 0.044789\n",
      "batch 2419: loss 0.110723\n",
      "batch 2420: loss 0.014072\n",
      "batch 2421: loss 0.002516\n",
      "batch 2422: loss 0.081414\n",
      "batch 2423: loss 0.021615\n",
      "batch 2424: loss 0.005178\n",
      "batch 2425: loss 0.080064\n",
      "batch 2426: loss 0.009387\n",
      "batch 2427: loss 0.033313\n",
      "batch 2428: loss 0.002967\n",
      "batch 2429: loss 0.075358\n",
      "batch 2430: loss 0.005110\n",
      "batch 2431: loss 0.006757\n",
      "batch 2432: loss 0.004697\n",
      "batch 2433: loss 0.024036\n",
      "batch 2434: loss 0.029586\n",
      "batch 2435: loss 0.062641\n",
      "batch 2436: loss 0.057184\n",
      "batch 2437: loss 0.019453\n",
      "batch 2438: loss 0.003410\n",
      "batch 2439: loss 0.006182\n",
      "batch 2440: loss 0.010460\n",
      "batch 2441: loss 0.033375\n",
      "batch 2442: loss 0.235854\n",
      "batch 2443: loss 0.020084\n",
      "batch 2444: loss 0.030287\n",
      "batch 2445: loss 0.119826\n",
      "batch 2446: loss 0.014124\n",
      "batch 2447: loss 0.016362\n",
      "batch 2448: loss 0.045613\n",
      "batch 2449: loss 0.011675\n",
      "batch 2450: loss 0.013556\n",
      "batch 2451: loss 0.112220\n",
      "batch 2452: loss 0.071431\n",
      "batch 2453: loss 0.102182\n",
      "batch 2454: loss 0.018909\n",
      "batch 2455: loss 0.007558\n",
      "batch 2456: loss 0.087420\n",
      "batch 2457: loss 0.022105\n",
      "batch 2458: loss 0.013067\n",
      "batch 2459: loss 0.060763\n",
      "batch 2460: loss 0.142740\n",
      "batch 2461: loss 0.003996\n",
      "batch 2462: loss 0.003955\n",
      "batch 2463: loss 0.038697\n",
      "batch 2464: loss 0.011458\n",
      "batch 2465: loss 0.043513\n",
      "batch 2466: loss 0.062761\n",
      "batch 2467: loss 0.011882\n",
      "batch 2468: loss 0.004301\n",
      "batch 2469: loss 0.015550\n",
      "batch 2470: loss 0.031842\n",
      "batch 2471: loss 0.003639\n",
      "batch 2472: loss 0.006603\n",
      "batch 2473: loss 0.054318\n",
      "batch 2474: loss 0.017933\n",
      "batch 2475: loss 0.004863\n",
      "batch 2476: loss 0.117990\n",
      "batch 2477: loss 0.009122\n",
      "batch 2478: loss 0.030255\n",
      "batch 2479: loss 0.002627\n",
      "batch 2480: loss 0.010931\n",
      "batch 2481: loss 0.035466\n",
      "batch 2482: loss 0.022017\n",
      "batch 2483: loss 0.004328\n",
      "batch 2484: loss 0.022736\n",
      "batch 2485: loss 0.019596\n",
      "batch 2486: loss 0.078340\n",
      "batch 2487: loss 0.063267\n",
      "batch 2488: loss 0.012229\n",
      "batch 2489: loss 0.065672\n",
      "batch 2490: loss 0.013594\n",
      "batch 2491: loss 0.021203\n",
      "batch 2492: loss 0.013370\n",
      "batch 2493: loss 0.011885\n",
      "batch 2494: loss 0.022534\n",
      "batch 2495: loss 0.018514\n",
      "batch 2496: loss 0.041289\n",
      "batch 2497: loss 0.021491\n",
      "batch 2498: loss 0.009445\n",
      "batch 2499: loss 0.016239\n",
      "batch 2500: loss 0.009880\n",
      "batch 2501: loss 0.024453\n",
      "batch 2502: loss 0.012684\n",
      "batch 2503: loss 0.021942\n",
      "batch 2504: loss 0.021455\n",
      "batch 2505: loss 0.026253\n",
      "batch 2506: loss 0.014169\n",
      "batch 2507: loss 0.034665\n",
      "batch 2508: loss 0.020317\n",
      "batch 2509: loss 0.020099\n",
      "batch 2510: loss 0.181657\n",
      "batch 2511: loss 0.009795\n",
      "batch 2512: loss 0.006557\n",
      "batch 2513: loss 0.039495\n",
      "batch 2514: loss 0.035238\n",
      "batch 2515: loss 0.007941\n",
      "batch 2516: loss 0.026255\n",
      "batch 2517: loss 0.063293\n",
      "batch 2518: loss 0.060704\n",
      "batch 2519: loss 0.012654\n",
      "batch 2520: loss 0.045615\n",
      "batch 2521: loss 0.030219\n",
      "batch 2522: loss 0.010884\n",
      "batch 2523: loss 0.047015\n",
      "batch 2524: loss 0.063132\n",
      "batch 2525: loss 0.025734\n",
      "batch 2526: loss 0.034412\n",
      "batch 2527: loss 0.006653\n",
      "batch 2528: loss 0.067847\n",
      "batch 2529: loss 0.058992\n",
      "batch 2530: loss 0.026812\n",
      "batch 2531: loss 0.046076\n",
      "batch 2532: loss 0.005312\n",
      "batch 2533: loss 0.011262\n",
      "batch 2534: loss 0.026173\n",
      "batch 2535: loss 0.022718\n",
      "batch 2536: loss 0.008668\n",
      "batch 2537: loss 0.062013\n",
      "batch 2538: loss 0.005745\n",
      "batch 2539: loss 0.051141\n",
      "batch 2540: loss 0.046482\n",
      "batch 2541: loss 0.008713\n",
      "batch 2542: loss 0.004671\n",
      "batch 2543: loss 0.019294\n",
      "batch 2544: loss 0.067582\n",
      "batch 2545: loss 0.011143\n",
      "batch 2546: loss 0.004486\n",
      "batch 2547: loss 0.012965\n",
      "batch 2548: loss 0.045469\n",
      "batch 2549: loss 0.012856\n",
      "batch 2550: loss 0.048904\n",
      "batch 2551: loss 0.007089\n",
      "batch 2552: loss 0.059425\n",
      "batch 2553: loss 0.016844\n",
      "batch 2554: loss 0.028095\n",
      "batch 2555: loss 0.036770\n",
      "batch 2556: loss 0.010063\n",
      "batch 2557: loss 0.021914\n",
      "batch 2558: loss 0.029854\n",
      "batch 2559: loss 0.043205\n",
      "batch 2560: loss 0.037612\n",
      "batch 2561: loss 0.108514\n",
      "batch 2562: loss 0.099266\n",
      "batch 2563: loss 0.048371\n",
      "batch 2564: loss 0.067395\n",
      "batch 2565: loss 0.029159\n",
      "batch 2566: loss 0.005461\n",
      "batch 2567: loss 0.042304\n",
      "batch 2568: loss 0.004229\n",
      "batch 2569: loss 0.043225\n",
      "batch 2570: loss 0.005285\n",
      "batch 2571: loss 0.025295\n",
      "batch 2572: loss 0.042826\n",
      "batch 2573: loss 0.013126\n",
      "batch 2574: loss 0.019847\n",
      "batch 2575: loss 0.099904\n",
      "batch 2576: loss 0.018779\n",
      "batch 2577: loss 0.060887\n",
      "batch 2578: loss 0.043366\n",
      "batch 2579: loss 0.018925\n",
      "batch 2580: loss 0.018784\n",
      "batch 2581: loss 0.014065\n",
      "batch 2582: loss 0.094454\n",
      "batch 2583: loss 0.042024\n",
      "batch 2584: loss 0.018393\n",
      "batch 2585: loss 0.020443\n",
      "batch 2586: loss 0.012857\n",
      "batch 2587: loss 0.044360\n",
      "batch 2588: loss 0.025284\n",
      "batch 2589: loss 0.004573\n",
      "batch 2590: loss 0.018535\n",
      "batch 2591: loss 0.008168\n",
      "batch 2592: loss 0.016533\n",
      "batch 2593: loss 0.030406\n",
      "batch 2594: loss 0.009896\n",
      "batch 2595: loss 0.017225\n",
      "batch 2596: loss 0.148584\n",
      "batch 2597: loss 0.008574\n",
      "batch 2598: loss 0.005874\n",
      "batch 2599: loss 0.045766\n",
      "batch 2600: loss 0.019585\n",
      "batch 2601: loss 0.083974\n",
      "batch 2602: loss 0.020216\n",
      "batch 2603: loss 0.004314\n",
      "batch 2604: loss 0.007795\n",
      "batch 2605: loss 0.024460\n",
      "batch 2606: loss 0.008144\n",
      "batch 2607: loss 0.001264\n",
      "batch 2608: loss 0.063590\n",
      "batch 2609: loss 0.041023\n",
      "batch 2610: loss 0.004828\n",
      "batch 2611: loss 0.006357\n",
      "batch 2612: loss 0.012383\n",
      "batch 2613: loss 0.066757\n",
      "batch 2614: loss 0.005737\n",
      "batch 2615: loss 0.038281\n",
      "batch 2616: loss 0.011086\n",
      "batch 2617: loss 0.019222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2618: loss 0.049113\n",
      "batch 2619: loss 0.030446\n",
      "batch 2620: loss 0.005588\n",
      "batch 2621: loss 0.041856\n",
      "batch 2622: loss 0.023142\n",
      "batch 2623: loss 0.028618\n",
      "batch 2624: loss 0.045134\n",
      "batch 2625: loss 0.017972\n",
      "batch 2626: loss 0.006521\n",
      "batch 2627: loss 0.010975\n",
      "batch 2628: loss 0.044433\n",
      "batch 2629: loss 0.043084\n",
      "batch 2630: loss 0.030707\n",
      "batch 2631: loss 0.009885\n",
      "batch 2632: loss 0.014742\n",
      "batch 2633: loss 0.048459\n",
      "batch 2634: loss 0.006665\n",
      "batch 2635: loss 0.001612\n",
      "batch 2636: loss 0.004245\n",
      "batch 2637: loss 0.025788\n",
      "batch 2638: loss 0.038089\n",
      "batch 2639: loss 0.017617\n",
      "batch 2640: loss 0.005271\n",
      "batch 2641: loss 0.035105\n",
      "batch 2642: loss 0.013011\n",
      "batch 2643: loss 0.055588\n",
      "batch 2644: loss 0.005508\n",
      "batch 2645: loss 0.011567\n",
      "batch 2646: loss 0.082170\n",
      "batch 2647: loss 0.005138\n",
      "batch 2648: loss 0.007259\n",
      "batch 2649: loss 0.003136\n",
      "batch 2650: loss 0.019346\n",
      "batch 2651: loss 0.004402\n",
      "batch 2652: loss 0.040812\n",
      "batch 2653: loss 0.155400\n",
      "batch 2654: loss 0.049634\n",
      "batch 2655: loss 0.005894\n",
      "batch 2656: loss 0.008266\n",
      "batch 2657: loss 0.029703\n",
      "batch 2658: loss 0.067026\n",
      "batch 2659: loss 0.077981\n",
      "batch 2660: loss 0.024208\n",
      "batch 2661: loss 0.018230\n",
      "batch 2662: loss 0.008745\n",
      "batch 2663: loss 0.059391\n",
      "batch 2664: loss 0.018997\n",
      "batch 2665: loss 0.058978\n",
      "batch 2666: loss 0.013659\n",
      "batch 2667: loss 0.016458\n",
      "batch 2668: loss 0.017838\n",
      "batch 2669: loss 0.007836\n",
      "batch 2670: loss 0.019292\n",
      "batch 2671: loss 0.006813\n",
      "batch 2672: loss 0.015607\n",
      "batch 2673: loss 0.032095\n",
      "batch 2674: loss 0.103369\n",
      "batch 2675: loss 0.012693\n",
      "batch 2676: loss 0.001980\n",
      "batch 2677: loss 0.058481\n",
      "batch 2678: loss 0.011882\n",
      "batch 2679: loss 0.085711\n",
      "batch 2680: loss 0.015676\n",
      "batch 2681: loss 0.007938\n",
      "batch 2682: loss 0.029191\n",
      "batch 2683: loss 0.012855\n",
      "batch 2684: loss 0.040407\n",
      "batch 2685: loss 0.009300\n",
      "batch 2686: loss 0.011878\n",
      "batch 2687: loss 0.094697\n",
      "batch 2688: loss 0.085624\n",
      "batch 2689: loss 0.034026\n",
      "batch 2690: loss 0.003317\n",
      "batch 2691: loss 0.014946\n",
      "batch 2692: loss 0.127831\n",
      "batch 2693: loss 0.010916\n",
      "batch 2694: loss 0.010718\n",
      "batch 2695: loss 0.081277\n",
      "batch 2696: loss 0.021033\n",
      "batch 2697: loss 0.006487\n",
      "batch 2698: loss 0.049644\n",
      "batch 2699: loss 0.009307\n",
      "batch 2700: loss 0.014174\n",
      "batch 2701: loss 0.019345\n",
      "batch 2702: loss 0.015493\n",
      "batch 2703: loss 0.057324\n",
      "batch 2704: loss 0.043666\n",
      "batch 2705: loss 0.004555\n",
      "batch 2706: loss 0.024649\n",
      "batch 2707: loss 0.024125\n",
      "batch 2708: loss 0.016360\n",
      "batch 2709: loss 0.019933\n",
      "batch 2710: loss 0.038618\n",
      "batch 2711: loss 0.125111\n",
      "batch 2712: loss 0.022064\n",
      "batch 2713: loss 0.011522\n",
      "batch 2714: loss 0.007539\n",
      "batch 2715: loss 0.009712\n",
      "batch 2716: loss 0.007737\n",
      "batch 2717: loss 0.019268\n",
      "batch 2718: loss 0.016380\n",
      "batch 2719: loss 0.072524\n",
      "batch 2720: loss 0.015611\n",
      "batch 2721: loss 0.054085\n",
      "batch 2722: loss 0.009774\n",
      "batch 2723: loss 0.023390\n",
      "batch 2724: loss 0.045986\n",
      "batch 2725: loss 0.007875\n",
      "batch 2726: loss 0.007857\n",
      "batch 2727: loss 0.001839\n",
      "batch 2728: loss 0.013856\n",
      "batch 2729: loss 0.022334\n",
      "batch 2730: loss 0.023728\n",
      "batch 2731: loss 0.022442\n",
      "batch 2732: loss 0.005854\n",
      "batch 2733: loss 0.034632\n",
      "batch 2734: loss 0.003066\n",
      "batch 2735: loss 0.008570\n",
      "batch 2736: loss 0.041849\n",
      "batch 2737: loss 0.019585\n",
      "batch 2738: loss 0.005340\n",
      "batch 2739: loss 0.027868\n",
      "batch 2740: loss 0.008530\n",
      "batch 2741: loss 0.025044\n",
      "batch 2742: loss 0.087539\n",
      "batch 2743: loss 0.028371\n",
      "batch 2744: loss 0.050097\n",
      "batch 2745: loss 0.101085\n",
      "batch 2746: loss 0.021690\n",
      "batch 2747: loss 0.029446\n",
      "batch 2748: loss 0.020995\n",
      "batch 2749: loss 0.003838\n",
      "batch 2750: loss 0.008182\n",
      "batch 2751: loss 0.011499\n",
      "batch 2752: loss 0.011186\n",
      "batch 2753: loss 0.022378\n",
      "batch 2754: loss 0.075168\n",
      "batch 2755: loss 0.017974\n",
      "batch 2756: loss 0.055092\n",
      "batch 2757: loss 0.032015\n",
      "batch 2758: loss 0.005018\n",
      "batch 2759: loss 0.012394\n",
      "batch 2760: loss 0.005417\n",
      "batch 2761: loss 0.029598\n",
      "batch 2762: loss 0.023332\n",
      "batch 2763: loss 0.009110\n",
      "batch 2764: loss 0.027659\n",
      "batch 2765: loss 0.013474\n",
      "batch 2766: loss 0.010413\n",
      "batch 2767: loss 0.006842\n",
      "batch 2768: loss 0.035134\n",
      "batch 2769: loss 0.022349\n",
      "batch 2770: loss 0.146820\n",
      "batch 2771: loss 0.024819\n",
      "batch 2772: loss 0.061679\n",
      "batch 2773: loss 0.067210\n",
      "batch 2774: loss 0.004705\n",
      "batch 2775: loss 0.003451\n",
      "batch 2776: loss 0.045879\n",
      "batch 2777: loss 0.015763\n",
      "batch 2778: loss 0.005661\n",
      "batch 2779: loss 0.005520\n",
      "batch 2780: loss 0.027138\n",
      "batch 2781: loss 0.010505\n",
      "batch 2782: loss 0.019529\n",
      "batch 2783: loss 0.007884\n",
      "batch 2784: loss 0.147608\n",
      "batch 2785: loss 0.011067\n",
      "batch 2786: loss 0.024605\n",
      "batch 2787: loss 0.053274\n",
      "batch 2788: loss 0.077432\n",
      "batch 2789: loss 0.041874\n",
      "batch 2790: loss 0.014392\n",
      "batch 2791: loss 0.054308\n",
      "batch 2792: loss 0.020520\n",
      "batch 2793: loss 0.026378\n",
      "batch 2794: loss 0.001435\n",
      "batch 2795: loss 0.069786\n",
      "batch 2796: loss 0.028473\n",
      "batch 2797: loss 0.089173\n",
      "batch 2798: loss 0.019945\n",
      "batch 2799: loss 0.004393\n",
      "batch 2800: loss 0.003248\n",
      "batch 2801: loss 0.023235\n",
      "batch 2802: loss 0.029120\n",
      "batch 2803: loss 0.010094\n",
      "batch 2804: loss 0.006357\n",
      "batch 2805: loss 0.004270\n",
      "batch 2806: loss 0.038271\n",
      "batch 2807: loss 0.023497\n",
      "batch 2808: loss 0.042357\n",
      "batch 2809: loss 0.062601\n",
      "batch 2810: loss 0.004623\n",
      "batch 2811: loss 0.012242\n",
      "batch 2812: loss 0.012978\n",
      "batch 2813: loss 0.074732\n",
      "batch 2814: loss 0.010513\n",
      "batch 2815: loss 0.026636\n",
      "batch 2816: loss 0.042779\n",
      "batch 2817: loss 0.009003\n",
      "batch 2818: loss 0.018566\n",
      "batch 2819: loss 0.045769\n",
      "batch 2820: loss 0.005328\n",
      "batch 2821: loss 0.021494\n",
      "batch 2822: loss 0.022309\n",
      "batch 2823: loss 0.028650\n",
      "batch 2824: loss 0.011539\n",
      "batch 2825: loss 0.007091\n",
      "batch 2826: loss 0.026995\n",
      "batch 2827: loss 0.115060\n",
      "batch 2828: loss 0.022179\n",
      "batch 2829: loss 0.036970\n",
      "batch 2830: loss 0.026691\n",
      "batch 2831: loss 0.010586\n",
      "batch 2832: loss 0.006917\n",
      "batch 2833: loss 0.037805\n",
      "batch 2834: loss 0.012706\n",
      "batch 2835: loss 0.052122\n",
      "batch 2836: loss 0.029251\n",
      "batch 2837: loss 0.015712\n",
      "batch 2838: loss 0.037459\n",
      "batch 2839: loss 0.017450\n",
      "batch 2840: loss 0.016676\n",
      "batch 2841: loss 0.087689\n",
      "batch 2842: loss 0.003403\n",
      "batch 2843: loss 0.007844\n",
      "batch 2844: loss 0.020568\n",
      "batch 2845: loss 0.006581\n",
      "batch 2846: loss 0.031469\n",
      "batch 2847: loss 0.019088\n",
      "batch 2848: loss 0.043376\n",
      "batch 2849: loss 0.122856\n",
      "batch 2850: loss 0.027160\n",
      "batch 2851: loss 0.090345\n",
      "batch 2852: loss 0.017990\n",
      "batch 2853: loss 0.054225\n",
      "batch 2854: loss 0.123035\n",
      "batch 2855: loss 0.013480\n",
      "batch 2856: loss 0.011826\n",
      "batch 2857: loss 0.010074\n",
      "batch 2858: loss 0.008296\n",
      "batch 2859: loss 0.035075\n",
      "batch 2860: loss 0.032096\n",
      "batch 2861: loss 0.023696\n",
      "batch 2862: loss 0.064033\n",
      "batch 2863: loss 0.003667\n",
      "batch 2864: loss 0.014864\n",
      "batch 2865: loss 0.041897\n",
      "batch 2866: loss 0.021194\n",
      "batch 2867: loss 0.023429\n",
      "batch 2868: loss 0.002270\n",
      "batch 2869: loss 0.012602\n",
      "batch 2870: loss 0.016923\n",
      "batch 2871: loss 0.055135\n",
      "batch 2872: loss 0.107518\n",
      "batch 2873: loss 0.004926\n",
      "batch 2874: loss 0.023283\n",
      "batch 2875: loss 0.006714\n",
      "batch 2876: loss 0.004879\n",
      "batch 2877: loss 0.135770\n",
      "batch 2878: loss 0.090477\n",
      "batch 2879: loss 0.074698\n",
      "batch 2880: loss 0.055980\n",
      "batch 2881: loss 0.017010\n",
      "batch 2882: loss 0.046991\n",
      "batch 2883: loss 0.005403\n",
      "batch 2884: loss 0.015930\n",
      "batch 2885: loss 0.007004\n",
      "batch 2886: loss 0.015966\n",
      "batch 2887: loss 0.003629\n",
      "batch 2888: loss 0.006686\n",
      "batch 2889: loss 0.002114\n",
      "batch 2890: loss 0.137129\n",
      "batch 2891: loss 0.017468\n",
      "batch 2892: loss 0.009008\n",
      "batch 2893: loss 0.017758\n",
      "batch 2894: loss 0.045339\n",
      "batch 2895: loss 0.056019\n",
      "batch 2896: loss 0.053650\n",
      "batch 2897: loss 0.006280\n",
      "batch 2898: loss 0.002853\n",
      "batch 2899: loss 0.191745\n",
      "batch 2900: loss 0.003559\n",
      "batch 2901: loss 0.003932\n",
      "batch 2902: loss 0.005026\n",
      "batch 2903: loss 0.044005\n",
      "batch 2904: loss 0.014446\n",
      "batch 2905: loss 0.031279\n",
      "batch 2906: loss 0.013470\n",
      "batch 2907: loss 0.026349\n",
      "batch 2908: loss 0.041713\n",
      "batch 2909: loss 0.054351\n",
      "batch 2910: loss 0.050636\n",
      "batch 2911: loss 0.018222\n",
      "batch 2912: loss 0.051494\n",
      "batch 2913: loss 0.007851\n",
      "batch 2914: loss 0.008603\n",
      "batch 2915: loss 0.013365\n",
      "batch 2916: loss 0.029853\n",
      "batch 2917: loss 0.066323\n",
      "batch 2918: loss 0.054720\n",
      "batch 2919: loss 0.061680\n",
      "batch 2920: loss 0.097644\n",
      "batch 2921: loss 0.065315\n",
      "batch 2922: loss 0.022986\n",
      "batch 2923: loss 0.036044\n",
      "batch 2924: loss 0.045017\n",
      "batch 2925: loss 0.017657\n",
      "batch 2926: loss 0.067294\n",
      "batch 2927: loss 0.053887\n",
      "batch 2928: loss 0.014205\n",
      "batch 2929: loss 0.025744\n",
      "batch 2930: loss 0.035081\n",
      "batch 2931: loss 0.054615\n",
      "batch 2932: loss 0.037351\n",
      "batch 2933: loss 0.023277\n",
      "batch 2934: loss 0.042076\n",
      "batch 2935: loss 0.022877\n",
      "batch 2936: loss 0.048229\n",
      "batch 2937: loss 0.018638\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 2938: loss 0.069314\n",
      "batch 2939: loss 0.027252\n",
      "batch 2940: loss 0.002334\n",
      "batch 2941: loss 0.023708\n",
      "batch 2942: loss 0.008834\n",
      "batch 2943: loss 0.020899\n",
      "batch 2944: loss 0.021899\n",
      "batch 2945: loss 0.004167\n",
      "batch 2946: loss 0.140748\n",
      "batch 2947: loss 0.022175\n",
      "batch 2948: loss 0.022910\n",
      "batch 2949: loss 0.036241\n",
      "batch 2950: loss 0.030639\n",
      "batch 2951: loss 0.011338\n",
      "batch 2952: loss 0.007750\n",
      "batch 2953: loss 0.018571\n",
      "batch 2954: loss 0.015781\n",
      "batch 2955: loss 0.088569\n",
      "batch 2956: loss 0.132998\n",
      "batch 2957: loss 0.016130\n",
      "batch 2958: loss 0.054112\n",
      "batch 2959: loss 0.085603\n",
      "batch 2960: loss 0.001849\n",
      "batch 2961: loss 0.089376\n",
      "batch 2962: loss 0.025163\n",
      "batch 2963: loss 0.035974\n",
      "batch 2964: loss 0.019251\n",
      "batch 2965: loss 0.028550\n",
      "batch 2966: loss 0.049444\n",
      "batch 2967: loss 0.081308\n",
      "batch 2968: loss 0.013206\n",
      "batch 2969: loss 0.011611\n",
      "batch 2970: loss 0.018307\n",
      "batch 2971: loss 0.074230\n",
      "batch 2972: loss 0.019591\n",
      "batch 2973: loss 0.014028\n",
      "batch 2974: loss 0.030318\n",
      "batch 2975: loss 0.160639\n",
      "batch 2976: loss 0.013443\n",
      "batch 2977: loss 0.057039\n",
      "batch 2978: loss 0.049852\n",
      "batch 2979: loss 0.159502\n",
      "batch 2980: loss 0.004573\n",
      "batch 2981: loss 0.058218\n",
      "batch 2982: loss 0.066580\n",
      "batch 2983: loss 0.014063\n",
      "batch 2984: loss 0.075732\n",
      "batch 2985: loss 0.030591\n",
      "batch 2986: loss 0.005383\n",
      "batch 2987: loss 0.130824\n",
      "batch 2988: loss 0.023922\n",
      "batch 2989: loss 0.010121\n",
      "batch 2990: loss 0.008084\n",
      "batch 2991: loss 0.025974\n",
      "batch 2992: loss 0.028545\n",
      "batch 2993: loss 0.032714\n",
      "batch 2994: loss 0.028462\n",
      "batch 2995: loss 0.019563\n",
      "batch 2996: loss 0.070489\n",
      "batch 2997: loss 0.005106\n",
      "batch 2998: loss 0.022787\n",
      "batch 2999: loss 0.026651\n",
      "batch 3000: loss 0.009334\n",
      "batch 3001: loss 0.011182\n",
      "batch 3002: loss 0.133180\n",
      "batch 3003: loss 0.045076\n",
      "batch 3004: loss 0.055798\n",
      "batch 3005: loss 0.019750\n",
      "batch 3006: loss 0.047087\n",
      "batch 3007: loss 0.109691\n",
      "batch 3008: loss 0.133420\n",
      "batch 3009: loss 0.008187\n",
      "batch 3010: loss 0.069051\n",
      "batch 3011: loss 0.086251\n",
      "batch 3012: loss 0.039172\n",
      "batch 3013: loss 0.014390\n",
      "batch 3014: loss 0.074250\n",
      "batch 3015: loss 0.030483\n",
      "batch 3016: loss 0.062925\n",
      "batch 3017: loss 0.067873\n",
      "batch 3018: loss 0.100655\n",
      "batch 3019: loss 0.089010\n",
      "batch 3020: loss 0.005154\n",
      "batch 3021: loss 0.015621\n",
      "batch 3022: loss 0.025789\n",
      "batch 3023: loss 0.015272\n",
      "batch 3024: loss 0.060365\n",
      "batch 3025: loss 0.017357\n",
      "batch 3026: loss 0.045501\n",
      "batch 3027: loss 0.006032\n",
      "batch 3028: loss 0.006142\n",
      "batch 3029: loss 0.025460\n",
      "batch 3030: loss 0.032677\n",
      "batch 3031: loss 0.015981\n",
      "batch 3032: loss 0.009195\n",
      "batch 3033: loss 0.060608\n",
      "batch 3034: loss 0.023455\n",
      "batch 3035: loss 0.006827\n",
      "batch 3036: loss 0.015190\n",
      "batch 3037: loss 0.021018\n",
      "batch 3038: loss 0.022696\n",
      "batch 3039: loss 0.019724\n",
      "batch 3040: loss 0.008314\n",
      "batch 3041: loss 0.006274\n",
      "batch 3042: loss 0.017735\n",
      "batch 3043: loss 0.019311\n",
      "batch 3044: loss 0.077364\n",
      "batch 3045: loss 0.023709\n",
      "batch 3046: loss 0.037476\n",
      "batch 3047: loss 0.017826\n",
      "batch 3048: loss 0.029889\n",
      "batch 3049: loss 0.008678\n",
      "batch 3050: loss 0.045677\n",
      "batch 3051: loss 0.041377\n",
      "batch 3052: loss 0.061706\n",
      "batch 3053: loss 0.029850\n",
      "batch 3054: loss 0.011656\n",
      "batch 3055: loss 0.028836\n",
      "batch 3056: loss 0.041616\n",
      "batch 3057: loss 0.023181\n",
      "batch 3058: loss 0.004641\n",
      "batch 3059: loss 0.004334\n",
      "batch 3060: loss 0.032656\n",
      "batch 3061: loss 0.048142\n",
      "batch 3062: loss 0.008030\n",
      "batch 3063: loss 0.020667\n",
      "batch 3064: loss 0.002876\n",
      "batch 3065: loss 0.018869\n",
      "batch 3066: loss 0.004128\n",
      "batch 3067: loss 0.010403\n",
      "batch 3068: loss 0.020525\n",
      "batch 3069: loss 0.021215\n",
      "batch 3070: loss 0.020350\n",
      "batch 3071: loss 0.027680\n",
      "batch 3072: loss 0.076316\n",
      "batch 3073: loss 0.002857\n",
      "batch 3074: loss 0.006715\n",
      "batch 3075: loss 0.057557\n",
      "batch 3076: loss 0.015273\n",
      "batch 3077: loss 0.045387\n",
      "batch 3078: loss 0.071432\n",
      "batch 3079: loss 0.007340\n",
      "batch 3080: loss 0.006253\n",
      "batch 3081: loss 0.020519\n",
      "batch 3082: loss 0.024183\n",
      "batch 3083: loss 0.018623\n",
      "batch 3084: loss 0.002929\n",
      "batch 3085: loss 0.006749\n",
      "batch 3086: loss 0.021125\n",
      "batch 3087: loss 0.029997\n",
      "batch 3088: loss 0.004878\n",
      "batch 3089: loss 0.006005\n",
      "batch 3090: loss 0.002234\n",
      "batch 3091: loss 0.028455\n",
      "batch 3092: loss 0.003497\n",
      "batch 3093: loss 0.005609\n",
      "batch 3094: loss 0.007623\n",
      "batch 3095: loss 0.054329\n",
      "batch 3096: loss 0.012994\n",
      "batch 3097: loss 0.006648\n",
      "batch 3098: loss 0.017216\n",
      "batch 3099: loss 0.061690\n",
      "batch 3100: loss 0.006745\n",
      "batch 3101: loss 0.010962\n",
      "batch 3102: loss 0.022346\n",
      "batch 3103: loss 0.005600\n",
      "batch 3104: loss 0.009474\n",
      "batch 3105: loss 0.013375\n",
      "batch 3106: loss 0.023842\n",
      "batch 3107: loss 0.081600\n",
      "batch 3108: loss 0.012936\n",
      "batch 3109: loss 0.007433\n",
      "batch 3110: loss 0.017704\n",
      "batch 3111: loss 0.000636\n",
      "batch 3112: loss 0.025113\n",
      "batch 3113: loss 0.040901\n",
      "batch 3114: loss 0.011318\n",
      "batch 3115: loss 0.014500\n",
      "batch 3116: loss 0.137373\n",
      "batch 3117: loss 0.017039\n",
      "batch 3118: loss 0.008198\n",
      "batch 3119: loss 0.005004\n",
      "batch 3120: loss 0.008250\n",
      "batch 3121: loss 0.007527\n",
      "batch 3122: loss 0.016448\n",
      "batch 3123: loss 0.017025\n",
      "batch 3124: loss 0.085500\n",
      "batch 3125: loss 0.115721\n",
      "batch 3126: loss 0.030444\n",
      "batch 3127: loss 0.007174\n",
      "batch 3128: loss 0.013927\n",
      "batch 3129: loss 0.006301\n",
      "batch 3130: loss 0.071869\n",
      "batch 3131: loss 0.095183\n",
      "batch 3132: loss 0.014439\n",
      "batch 3133: loss 0.031720\n",
      "batch 3134: loss 0.004140\n",
      "batch 3135: loss 0.013456\n",
      "batch 3136: loss 0.065110\n",
      "batch 3137: loss 0.004934\n",
      "batch 3138: loss 0.004679\n",
      "batch 3139: loss 0.092029\n",
      "batch 3140: loss 0.009106\n",
      "batch 3141: loss 0.074848\n",
      "batch 3142: loss 0.027504\n",
      "batch 3143: loss 0.198736\n",
      "batch 3144: loss 0.019241\n",
      "batch 3145: loss 0.021536\n",
      "batch 3146: loss 0.032757\n",
      "batch 3147: loss 0.001353\n",
      "batch 3148: loss 0.031337\n",
      "batch 3149: loss 0.014054\n",
      "batch 3150: loss 0.011550\n",
      "batch 3151: loss 0.039188\n",
      "batch 3152: loss 0.007178\n",
      "batch 3153: loss 0.003735\n",
      "batch 3154: loss 0.070383\n",
      "batch 3155: loss 0.007197\n",
      "batch 3156: loss 0.001814\n",
      "batch 3157: loss 0.134262\n",
      "batch 3158: loss 0.047043\n",
      "batch 3159: loss 0.003147\n",
      "batch 3160: loss 0.011511\n",
      "batch 3161: loss 0.056246\n",
      "batch 3162: loss 0.066728\n",
      "batch 3163: loss 0.153317\n",
      "batch 3164: loss 0.029120\n",
      "batch 3165: loss 0.025333\n",
      "batch 3166: loss 0.012296\n",
      "batch 3167: loss 0.039475\n",
      "batch 3168: loss 0.034739\n",
      "batch 3169: loss 0.021012\n",
      "batch 3170: loss 0.005100\n",
      "batch 3171: loss 0.018873\n",
      "batch 3172: loss 0.006615\n",
      "batch 3173: loss 0.003209\n",
      "batch 3174: loss 0.030621\n",
      "batch 3175: loss 0.020408\n",
      "batch 3176: loss 0.004347\n",
      "batch 3177: loss 0.009567\n",
      "batch 3178: loss 0.018851\n",
      "batch 3179: loss 0.014793\n",
      "batch 3180: loss 0.015238\n",
      "batch 3181: loss 0.011074\n",
      "batch 3182: loss 0.021308\n",
      "batch 3183: loss 0.026045\n",
      "batch 3184: loss 0.008155\n",
      "batch 3185: loss 0.109266\n",
      "batch 3186: loss 0.008093\n",
      "batch 3187: loss 0.005629\n",
      "batch 3188: loss 0.115802\n",
      "batch 3189: loss 0.032805\n",
      "batch 3190: loss 0.026633\n",
      "batch 3191: loss 0.049794\n",
      "batch 3192: loss 0.063044\n",
      "batch 3193: loss 0.058763\n",
      "batch 3194: loss 0.119263\n",
      "batch 3195: loss 0.030319\n",
      "batch 3196: loss 0.127289\n",
      "batch 3197: loss 0.039588\n",
      "batch 3198: loss 0.012342\n",
      "batch 3199: loss 0.011410\n",
      "batch 3200: loss 0.015643\n",
      "batch 3201: loss 0.043928\n",
      "batch 3202: loss 0.121966\n",
      "batch 3203: loss 0.012922\n",
      "batch 3204: loss 0.010989\n",
      "batch 3205: loss 0.018059\n",
      "batch 3206: loss 0.037024\n",
      "batch 3207: loss 0.051054\n",
      "batch 3208: loss 0.080462\n",
      "batch 3209: loss 0.014460\n",
      "batch 3210: loss 0.024917\n",
      "batch 3211: loss 0.032045\n",
      "batch 3212: loss 0.060743\n",
      "batch 3213: loss 0.043791\n",
      "batch 3214: loss 0.050620\n",
      "batch 3215: loss 0.061547\n",
      "batch 3216: loss 0.017049\n",
      "batch 3217: loss 0.008516\n",
      "batch 3218: loss 0.010811\n",
      "batch 3219: loss 0.021065\n",
      "batch 3220: loss 0.039479\n",
      "batch 3221: loss 0.021170\n",
      "batch 3222: loss 0.004310\n",
      "batch 3223: loss 0.007615\n",
      "batch 3224: loss 0.007368\n",
      "batch 3225: loss 0.003329\n",
      "batch 3226: loss 0.025401\n",
      "batch 3227: loss 0.005141\n",
      "batch 3228: loss 0.004849\n",
      "batch 3229: loss 0.047916\n",
      "batch 3230: loss 0.012907\n",
      "batch 3231: loss 0.025600\n",
      "batch 3232: loss 0.009876\n",
      "batch 3233: loss 0.029561\n",
      "batch 3234: loss 0.012557\n",
      "batch 3235: loss 0.040352\n",
      "batch 3236: loss 0.023460\n",
      "batch 3237: loss 0.042753\n",
      "batch 3238: loss 0.056455\n",
      "batch 3239: loss 0.006841\n",
      "batch 3240: loss 0.019192\n",
      "batch 3241: loss 0.049993\n",
      "batch 3242: loss 0.012566\n",
      "batch 3243: loss 0.009067\n",
      "batch 3244: loss 0.008621\n",
      "batch 3245: loss 0.024468\n",
      "batch 3246: loss 0.014963\n",
      "batch 3247: loss 0.025707\n",
      "batch 3248: loss 0.027625\n",
      "batch 3249: loss 0.017102\n",
      "batch 3250: loss 0.032135\n",
      "batch 3251: loss 0.001488\n",
      "batch 3252: loss 0.037221\n",
      "batch 3253: loss 0.093701\n",
      "batch 3254: loss 0.156488\n",
      "batch 3255: loss 0.017110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3256: loss 0.005974\n",
      "batch 3257: loss 0.012737\n",
      "batch 3258: loss 0.008710\n",
      "batch 3259: loss 0.009484\n",
      "batch 3260: loss 0.072089\n",
      "batch 3261: loss 0.041757\n",
      "batch 3262: loss 0.005165\n",
      "batch 3263: loss 0.003166\n",
      "batch 3264: loss 0.018936\n",
      "batch 3265: loss 0.023557\n",
      "batch 3266: loss 0.041887\n",
      "batch 3267: loss 0.069993\n",
      "batch 3268: loss 0.031179\n",
      "batch 3269: loss 0.047527\n",
      "batch 3270: loss 0.040447\n",
      "batch 3271: loss 0.123417\n",
      "batch 3272: loss 0.052691\n",
      "batch 3273: loss 0.015309\n",
      "batch 3274: loss 0.033449\n",
      "batch 3275: loss 0.023108\n",
      "batch 3276: loss 0.032402\n",
      "batch 3277: loss 0.020204\n",
      "batch 3278: loss 0.062195\n",
      "batch 3279: loss 0.066696\n",
      "batch 3280: loss 0.011746\n",
      "batch 3281: loss 0.008996\n",
      "batch 3282: loss 0.027520\n",
      "batch 3283: loss 0.009906\n",
      "batch 3284: loss 0.013250\n",
      "batch 3285: loss 0.025964\n",
      "batch 3286: loss 0.132059\n",
      "batch 3287: loss 0.017050\n",
      "batch 3288: loss 0.022575\n",
      "batch 3289: loss 0.011558\n",
      "batch 3290: loss 0.013591\n",
      "batch 3291: loss 0.043270\n",
      "batch 3292: loss 0.027219\n",
      "batch 3293: loss 0.060436\n",
      "batch 3294: loss 0.051177\n",
      "batch 3295: loss 0.009802\n",
      "batch 3296: loss 0.009141\n",
      "batch 3297: loss 0.044771\n",
      "batch 3298: loss 0.015364\n",
      "batch 3299: loss 0.003160\n",
      "batch 3300: loss 0.013499\n",
      "batch 3301: loss 0.040014\n",
      "batch 3302: loss 0.004944\n",
      "batch 3303: loss 0.027762\n",
      "batch 3304: loss 0.002149\n",
      "batch 3305: loss 0.038700\n",
      "batch 3306: loss 0.007837\n",
      "batch 3307: loss 0.032408\n",
      "batch 3308: loss 0.024242\n",
      "batch 3309: loss 0.003814\n",
      "batch 3310: loss 0.039205\n",
      "batch 3311: loss 0.060928\n",
      "batch 3312: loss 0.003471\n",
      "batch 3313: loss 0.021713\n",
      "batch 3314: loss 0.020541\n",
      "batch 3315: loss 0.045178\n",
      "batch 3316: loss 0.049801\n",
      "batch 3317: loss 0.017313\n",
      "batch 3318: loss 0.012769\n",
      "batch 3319: loss 0.004219\n",
      "batch 3320: loss 0.014134\n",
      "batch 3321: loss 0.104572\n",
      "batch 3322: loss 0.028540\n",
      "batch 3323: loss 0.049417\n",
      "batch 3324: loss 0.042537\n",
      "batch 3325: loss 0.017800\n",
      "batch 3326: loss 0.029639\n",
      "batch 3327: loss 0.013800\n",
      "batch 3328: loss 0.024666\n",
      "batch 3329: loss 0.047194\n",
      "batch 3330: loss 0.120873\n",
      "batch 3331: loss 0.022054\n",
      "batch 3332: loss 0.016479\n",
      "batch 3333: loss 0.034658\n",
      "batch 3334: loss 0.018926\n",
      "batch 3335: loss 0.022056\n",
      "batch 3336: loss 0.011057\n",
      "batch 3337: loss 0.008742\n",
      "batch 3338: loss 0.133906\n",
      "batch 3339: loss 0.018463\n",
      "batch 3340: loss 0.156058\n",
      "batch 3341: loss 0.011244\n",
      "batch 3342: loss 0.024032\n",
      "batch 3343: loss 0.004298\n",
      "batch 3344: loss 0.020203\n",
      "batch 3345: loss 0.040148\n",
      "batch 3346: loss 0.012505\n",
      "batch 3347: loss 0.019035\n",
      "batch 3348: loss 0.006493\n",
      "batch 3349: loss 0.054112\n",
      "batch 3350: loss 0.007962\n",
      "batch 3351: loss 0.010523\n",
      "batch 3352: loss 0.032485\n",
      "batch 3353: loss 0.028035\n",
      "batch 3354: loss 0.035141\n",
      "batch 3355: loss 0.028067\n",
      "batch 3356: loss 0.112421\n",
      "batch 3357: loss 0.017958\n",
      "batch 3358: loss 0.011720\n",
      "batch 3359: loss 0.022442\n",
      "batch 3360: loss 0.010856\n",
      "batch 3361: loss 0.015052\n",
      "batch 3362: loss 0.023578\n",
      "batch 3363: loss 0.009265\n",
      "batch 3364: loss 0.008780\n",
      "batch 3365: loss 0.010221\n",
      "batch 3366: loss 0.088202\n",
      "batch 3367: loss 0.020043\n",
      "batch 3368: loss 0.007662\n",
      "batch 3369: loss 0.014250\n",
      "batch 3370: loss 0.006938\n",
      "batch 3371: loss 0.038766\n",
      "batch 3372: loss 0.023250\n",
      "batch 3373: loss 0.058447\n",
      "batch 3374: loss 0.010266\n",
      "batch 3375: loss 0.052870\n",
      "batch 3376: loss 0.005915\n",
      "batch 3377: loss 0.066419\n",
      "batch 3378: loss 0.014681\n",
      "batch 3379: loss 0.064381\n",
      "batch 3380: loss 0.066245\n",
      "batch 3381: loss 0.024699\n",
      "batch 3382: loss 0.025010\n",
      "batch 3383: loss 0.044388\n",
      "batch 3384: loss 0.009099\n",
      "batch 3385: loss 0.029040\n",
      "batch 3386: loss 0.127742\n",
      "batch 3387: loss 0.003512\n",
      "batch 3388: loss 0.262257\n",
      "batch 3389: loss 0.011428\n",
      "batch 3390: loss 0.070654\n",
      "batch 3391: loss 0.006728\n",
      "batch 3392: loss 0.054345\n",
      "batch 3393: loss 0.059958\n",
      "batch 3394: loss 0.026626\n",
      "batch 3395: loss 0.023582\n",
      "batch 3396: loss 0.117238\n",
      "batch 3397: loss 0.024972\n",
      "batch 3398: loss 0.086761\n",
      "batch 3399: loss 0.191758\n",
      "batch 3400: loss 0.059485\n",
      "batch 3401: loss 0.012499\n",
      "batch 3402: loss 0.042128\n",
      "batch 3403: loss 0.023656\n",
      "batch 3404: loss 0.027847\n",
      "batch 3405: loss 0.026049\n",
      "batch 3406: loss 0.004185\n",
      "batch 3407: loss 0.006767\n",
      "batch 3408: loss 0.224200\n",
      "batch 3409: loss 0.025436\n",
      "batch 3410: loss 0.005543\n",
      "batch 3411: loss 0.033635\n",
      "batch 3412: loss 0.006685\n",
      "batch 3413: loss 0.067449\n",
      "batch 3414: loss 0.214055\n",
      "batch 3415: loss 0.007586\n",
      "batch 3416: loss 0.003190\n",
      "batch 3417: loss 0.013004\n",
      "batch 3418: loss 0.046662\n",
      "batch 3419: loss 0.048286\n",
      "batch 3420: loss 0.029331\n",
      "batch 3421: loss 0.125571\n",
      "batch 3422: loss 0.010066\n",
      "batch 3423: loss 0.049974\n",
      "batch 3424: loss 0.023853\n",
      "batch 3425: loss 0.018202\n",
      "batch 3426: loss 0.086802\n",
      "batch 3427: loss 0.021737\n",
      "batch 3428: loss 0.006833\n",
      "batch 3429: loss 0.009893\n",
      "batch 3430: loss 0.007571\n",
      "batch 3431: loss 0.003356\n",
      "batch 3432: loss 0.048457\n",
      "batch 3433: loss 0.009266\n",
      "batch 3434: loss 0.036593\n",
      "batch 3435: loss 0.015277\n",
      "batch 3436: loss 0.006473\n",
      "batch 3437: loss 0.037384\n",
      "batch 3438: loss 0.063405\n",
      "batch 3439: loss 0.006714\n",
      "batch 3440: loss 0.007213\n",
      "batch 3441: loss 0.013974\n",
      "batch 3442: loss 0.006078\n",
      "batch 3443: loss 0.012240\n",
      "batch 3444: loss 0.006676\n",
      "batch 3445: loss 0.000930\n",
      "batch 3446: loss 0.006685\n",
      "batch 3447: loss 0.121471\n",
      "batch 3448: loss 0.007636\n",
      "batch 3449: loss 0.007611\n",
      "batch 3450: loss 0.024718\n",
      "batch 3451: loss 0.004983\n",
      "batch 3452: loss 0.014658\n",
      "batch 3453: loss 0.013090\n",
      "batch 3454: loss 0.024876\n",
      "batch 3455: loss 0.046965\n",
      "batch 3456: loss 0.026576\n",
      "batch 3457: loss 0.171045\n",
      "batch 3458: loss 0.060053\n",
      "batch 3459: loss 0.028898\n",
      "batch 3460: loss 0.020021\n",
      "batch 3461: loss 0.020490\n",
      "batch 3462: loss 0.019933\n",
      "batch 3463: loss 0.137868\n",
      "batch 3464: loss 0.008048\n",
      "batch 3465: loss 0.028464\n",
      "batch 3466: loss 0.024805\n",
      "batch 3467: loss 0.009955\n",
      "batch 3468: loss 0.072308\n",
      "batch 3469: loss 0.023700\n",
      "batch 3470: loss 0.042618\n",
      "batch 3471: loss 0.028763\n",
      "batch 3472: loss 0.018523\n",
      "batch 3473: loss 0.004408\n",
      "batch 3474: loss 0.004795\n",
      "batch 3475: loss 0.025854\n",
      "batch 3476: loss 0.076412\n",
      "batch 3477: loss 0.009885\n",
      "batch 3478: loss 0.008407\n",
      "batch 3479: loss 0.030131\n",
      "batch 3480: loss 0.017392\n",
      "batch 3481: loss 0.019678\n",
      "batch 3482: loss 0.028906\n",
      "batch 3483: loss 0.054631\n",
      "batch 3484: loss 0.031347\n",
      "batch 3485: loss 0.006305\n",
      "batch 3486: loss 0.031551\n",
      "batch 3487: loss 0.041754\n",
      "batch 3488: loss 0.004105\n",
      "batch 3489: loss 0.026162\n",
      "batch 3490: loss 0.110633\n",
      "batch 3491: loss 0.025880\n",
      "batch 3492: loss 0.062936\n",
      "batch 3493: loss 0.080577\n",
      "batch 3494: loss 0.010177\n",
      "batch 3495: loss 0.003171\n",
      "batch 3496: loss 0.010841\n",
      "batch 3497: loss 0.068583\n",
      "batch 3498: loss 0.072517\n",
      "batch 3499: loss 0.019988\n",
      "batch 3500: loss 0.007421\n",
      "batch 3501: loss 0.036029\n",
      "batch 3502: loss 0.034035\n",
      "batch 3503: loss 0.012069\n",
      "batch 3504: loss 0.034894\n",
      "batch 3505: loss 0.008346\n",
      "batch 3506: loss 0.037536\n",
      "batch 3507: loss 0.013096\n",
      "batch 3508: loss 0.022007\n",
      "batch 3509: loss 0.057717\n",
      "batch 3510: loss 0.007646\n",
      "batch 3511: loss 0.017858\n",
      "batch 3512: loss 0.021189\n",
      "batch 3513: loss 0.013174\n",
      "batch 3514: loss 0.013246\n",
      "batch 3515: loss 0.007426\n",
      "batch 3516: loss 0.009893\n",
      "batch 3517: loss 0.013535\n",
      "batch 3518: loss 0.065987\n",
      "batch 3519: loss 0.005840\n",
      "batch 3520: loss 0.005340\n",
      "batch 3521: loss 0.004306\n",
      "batch 3522: loss 0.007715\n",
      "batch 3523: loss 0.006448\n",
      "batch 3524: loss 0.004000\n",
      "batch 3525: loss 0.006010\n",
      "batch 3526: loss 0.010358\n",
      "batch 3527: loss 0.003186\n",
      "batch 3528: loss 0.014372\n",
      "batch 3529: loss 0.011695\n",
      "batch 3530: loss 0.008408\n",
      "batch 3531: loss 0.009547\n",
      "batch 3532: loss 0.032139\n",
      "batch 3533: loss 0.100305\n",
      "batch 3534: loss 0.022023\n",
      "batch 3535: loss 0.092310\n",
      "batch 3536: loss 0.010997\n",
      "batch 3537: loss 0.005807\n",
      "batch 3538: loss 0.012252\n",
      "batch 3539: loss 0.003247\n",
      "batch 3540: loss 0.006809\n",
      "batch 3541: loss 0.035318\n",
      "batch 3542: loss 0.023500\n",
      "batch 3543: loss 0.018624\n",
      "batch 3544: loss 0.137279\n",
      "batch 3545: loss 0.016264\n",
      "batch 3546: loss 0.003659\n",
      "batch 3547: loss 0.017494\n",
      "batch 3548: loss 0.017707\n",
      "batch 3549: loss 0.023328\n",
      "batch 3550: loss 0.014969\n",
      "batch 3551: loss 0.014719\n",
      "batch 3552: loss 0.006790\n",
      "batch 3553: loss 0.005174\n",
      "batch 3554: loss 0.017215\n",
      "batch 3555: loss 0.015433\n",
      "batch 3556: loss 0.003831\n",
      "batch 3557: loss 0.012176\n",
      "batch 3558: loss 0.015220\n",
      "batch 3559: loss 0.020337\n",
      "batch 3560: loss 0.011382\n",
      "batch 3561: loss 0.031841\n",
      "batch 3562: loss 0.016756\n",
      "batch 3563: loss 0.011010\n",
      "batch 3564: loss 0.008990\n",
      "batch 3565: loss 0.006921\n",
      "batch 3566: loss 0.214656\n",
      "batch 3567: loss 0.009303\n",
      "batch 3568: loss 0.033289\n",
      "batch 3569: loss 0.027492\n",
      "batch 3570: loss 0.016281\n",
      "batch 3571: loss 0.021720\n",
      "batch 3572: loss 0.020596\n",
      "batch 3573: loss 0.004212\n",
      "batch 3574: loss 0.010482\n",
      "batch 3575: loss 0.031976\n",
      "batch 3576: loss 0.006055\n",
      "batch 3577: loss 0.006309\n",
      "batch 3578: loss 0.019399\n",
      "batch 3579: loss 0.208261\n",
      "batch 3580: loss 0.018760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3581: loss 0.008666\n",
      "batch 3582: loss 0.008491\n",
      "batch 3583: loss 0.015519\n",
      "batch 3584: loss 0.010104\n",
      "batch 3585: loss 0.021318\n",
      "batch 3586: loss 0.064385\n",
      "batch 3587: loss 0.033208\n",
      "batch 3588: loss 0.009559\n",
      "batch 3589: loss 0.008652\n",
      "batch 3590: loss 0.003011\n",
      "batch 3591: loss 0.001353\n",
      "batch 3592: loss 0.010710\n",
      "batch 3593: loss 0.004218\n",
      "batch 3594: loss 0.025099\n",
      "batch 3595: loss 0.045597\n",
      "batch 3596: loss 0.010128\n",
      "batch 3597: loss 0.012663\n",
      "batch 3598: loss 0.003627\n",
      "batch 3599: loss 0.001063\n",
      "batch 3600: loss 0.012485\n",
      "batch 3601: loss 0.008407\n",
      "batch 3602: loss 0.008488\n",
      "batch 3603: loss 0.003274\n",
      "batch 3604: loss 0.012903\n",
      "batch 3605: loss 0.005315\n",
      "batch 3606: loss 0.066498\n",
      "batch 3607: loss 0.036190\n",
      "batch 3608: loss 0.007680\n",
      "batch 3609: loss 0.090143\n",
      "batch 3610: loss 0.004702\n",
      "batch 3611: loss 0.051382\n",
      "batch 3612: loss 0.052815\n",
      "batch 3613: loss 0.005323\n",
      "batch 3614: loss 0.052078\n",
      "batch 3615: loss 0.070280\n",
      "batch 3616: loss 0.004184\n",
      "batch 3617: loss 0.023091\n",
      "batch 3618: loss 0.082618\n",
      "batch 3619: loss 0.008983\n",
      "batch 3620: loss 0.012432\n",
      "batch 3621: loss 0.014458\n",
      "batch 3622: loss 0.005766\n",
      "batch 3623: loss 0.016181\n",
      "batch 3624: loss 0.010682\n",
      "batch 3625: loss 0.201910\n",
      "batch 3626: loss 0.031993\n",
      "batch 3627: loss 0.007504\n",
      "batch 3628: loss 0.015108\n",
      "batch 3629: loss 0.029561\n",
      "batch 3630: loss 0.017452\n",
      "batch 3631: loss 0.010222\n",
      "batch 3632: loss 0.049028\n",
      "batch 3633: loss 0.011596\n",
      "batch 3634: loss 0.050212\n",
      "batch 3635: loss 0.032977\n",
      "batch 3636: loss 0.084480\n",
      "batch 3637: loss 0.006401\n",
      "batch 3638: loss 0.030114\n",
      "batch 3639: loss 0.005438\n",
      "batch 3640: loss 0.017023\n",
      "batch 3641: loss 0.155455\n",
      "batch 3642: loss 0.005775\n",
      "batch 3643: loss 0.143056\n",
      "batch 3644: loss 0.001982\n",
      "batch 3645: loss 0.032356\n",
      "batch 3646: loss 0.036063\n",
      "batch 3647: loss 0.003255\n",
      "batch 3648: loss 0.019035\n",
      "batch 3649: loss 0.024190\n",
      "batch 3650: loss 0.014225\n",
      "batch 3651: loss 0.017263\n",
      "batch 3652: loss 0.079958\n",
      "batch 3653: loss 0.004690\n",
      "batch 3654: loss 0.034113\n",
      "batch 3655: loss 0.079974\n",
      "batch 3656: loss 0.039107\n",
      "batch 3657: loss 0.012579\n",
      "batch 3658: loss 0.014469\n",
      "batch 3659: loss 0.043563\n",
      "batch 3660: loss 0.023240\n",
      "batch 3661: loss 0.030601\n",
      "batch 3662: loss 0.026026\n",
      "batch 3663: loss 0.013958\n",
      "batch 3664: loss 0.004196\n",
      "batch 3665: loss 0.053510\n",
      "batch 3666: loss 0.039331\n",
      "batch 3667: loss 0.011491\n",
      "batch 3668: loss 0.010623\n",
      "batch 3669: loss 0.017511\n",
      "batch 3670: loss 0.077190\n",
      "batch 3671: loss 0.014343\n",
      "batch 3672: loss 0.030888\n",
      "batch 3673: loss 0.092154\n",
      "batch 3674: loss 0.005727\n",
      "batch 3675: loss 0.020560\n",
      "batch 3676: loss 0.029332\n",
      "batch 3677: loss 0.019467\n",
      "batch 3678: loss 0.066075\n",
      "batch 3679: loss 0.156765\n",
      "batch 3680: loss 0.036966\n",
      "batch 3681: loss 0.043291\n",
      "batch 3682: loss 0.004239\n",
      "batch 3683: loss 0.006884\n",
      "batch 3684: loss 0.024765\n",
      "batch 3685: loss 0.022424\n",
      "batch 3686: loss 0.003993\n",
      "batch 3687: loss 0.041187\n",
      "batch 3688: loss 0.011598\n",
      "batch 3689: loss 0.008537\n",
      "batch 3690: loss 0.033681\n",
      "batch 3691: loss 0.126221\n",
      "batch 3692: loss 0.022022\n",
      "batch 3693: loss 0.007592\n",
      "batch 3694: loss 0.182957\n",
      "batch 3695: loss 0.015985\n",
      "batch 3696: loss 0.003459\n",
      "batch 3697: loss 0.014651\n",
      "batch 3698: loss 0.002089\n",
      "batch 3699: loss 0.076589\n",
      "batch 3700: loss 0.057694\n",
      "batch 3701: loss 0.015713\n",
      "batch 3702: loss 0.023258\n",
      "batch 3703: loss 0.023621\n",
      "batch 3704: loss 0.008790\n",
      "batch 3705: loss 0.040096\n",
      "batch 3706: loss 0.022257\n",
      "batch 3707: loss 0.007791\n",
      "batch 3708: loss 0.031408\n",
      "batch 3709: loss 0.059958\n",
      "batch 3710: loss 0.008258\n",
      "batch 3711: loss 0.009400\n",
      "batch 3712: loss 0.057418\n",
      "batch 3713: loss 0.005396\n",
      "batch 3714: loss 0.001948\n",
      "batch 3715: loss 0.017603\n",
      "batch 3716: loss 0.119980\n",
      "batch 3717: loss 0.013991\n",
      "batch 3718: loss 0.029605\n",
      "batch 3719: loss 0.027156\n",
      "batch 3720: loss 0.023780\n",
      "batch 3721: loss 0.020222\n",
      "batch 3722: loss 0.008306\n",
      "batch 3723: loss 0.055520\n",
      "batch 3724: loss 0.006647\n",
      "batch 3725: loss 0.037904\n",
      "batch 3726: loss 0.012426\n",
      "batch 3727: loss 0.011091\n",
      "batch 3728: loss 0.070771\n",
      "batch 3729: loss 0.027301\n",
      "batch 3730: loss 0.004137\n",
      "batch 3731: loss 0.058647\n",
      "batch 3732: loss 0.064872\n",
      "batch 3733: loss 0.029849\n",
      "batch 3734: loss 0.006605\n",
      "batch 3735: loss 0.003989\n",
      "batch 3736: loss 0.006068\n",
      "batch 3737: loss 0.055247\n",
      "batch 3738: loss 0.009266\n",
      "batch 3739: loss 0.021098\n",
      "batch 3740: loss 0.006311\n",
      "batch 3741: loss 0.036636\n",
      "batch 3742: loss 0.011329\n",
      "batch 3743: loss 0.004774\n",
      "batch 3744: loss 0.009779\n",
      "batch 3745: loss 0.072503\n",
      "batch 3746: loss 0.008474\n",
      "batch 3747: loss 0.051415\n",
      "batch 3748: loss 0.030770\n",
      "batch 3749: loss 0.021430\n",
      "batch 3750: loss 0.083968\n",
      "batch 3751: loss 0.058300\n",
      "batch 3752: loss 0.044703\n",
      "batch 3753: loss 0.002282\n",
      "batch 3754: loss 0.012349\n",
      "batch 3755: loss 0.004230\n",
      "batch 3756: loss 0.004288\n",
      "batch 3757: loss 0.045069\n",
      "batch 3758: loss 0.014977\n",
      "batch 3759: loss 0.021478\n",
      "batch 3760: loss 0.065625\n",
      "batch 3761: loss 0.003449\n",
      "batch 3762: loss 0.017082\n",
      "batch 3763: loss 0.047339\n",
      "batch 3764: loss 0.024970\n",
      "batch 3765: loss 0.017324\n",
      "batch 3766: loss 0.007884\n",
      "batch 3767: loss 0.045648\n",
      "batch 3768: loss 0.019490\n",
      "batch 3769: loss 0.187442\n",
      "batch 3770: loss 0.036743\n",
      "batch 3771: loss 0.031855\n",
      "batch 3772: loss 0.008433\n",
      "batch 3773: loss 0.063393\n",
      "batch 3774: loss 0.015687\n",
      "batch 3775: loss 0.035261\n",
      "batch 3776: loss 0.010469\n",
      "batch 3777: loss 0.007166\n",
      "batch 3778: loss 0.007583\n",
      "batch 3779: loss 0.003613\n",
      "batch 3780: loss 0.018773\n",
      "batch 3781: loss 0.032354\n",
      "batch 3782: loss 0.004361\n",
      "batch 3783: loss 0.010365\n",
      "batch 3784: loss 0.016046\n",
      "batch 3785: loss 0.012816\n",
      "batch 3786: loss 0.042340\n",
      "batch 3787: loss 0.007376\n",
      "batch 3788: loss 0.032411\n",
      "batch 3789: loss 0.048754\n",
      "batch 3790: loss 0.103608\n",
      "batch 3791: loss 0.009030\n",
      "batch 3792: loss 0.018000\n",
      "batch 3793: loss 0.008718\n",
      "batch 3794: loss 0.014924\n",
      "batch 3795: loss 0.009026\n",
      "batch 3796: loss 0.065069\n",
      "batch 3797: loss 0.003975\n",
      "batch 3798: loss 0.002362\n",
      "batch 3799: loss 0.014562\n",
      "batch 3800: loss 0.011537\n",
      "batch 3801: loss 0.079834\n",
      "batch 3802: loss 0.052618\n",
      "batch 3803: loss 0.020553\n",
      "batch 3804: loss 0.023234\n",
      "batch 3805: loss 0.004608\n",
      "batch 3806: loss 0.038895\n",
      "batch 3807: loss 0.008920\n",
      "batch 3808: loss 0.094808\n",
      "batch 3809: loss 0.006087\n",
      "batch 3810: loss 0.024185\n",
      "batch 3811: loss 0.025261\n",
      "batch 3812: loss 0.009029\n",
      "batch 3813: loss 0.093648\n",
      "batch 3814: loss 0.081359\n",
      "batch 3815: loss 0.017311\n",
      "batch 3816: loss 0.219683\n",
      "batch 3817: loss 0.049259\n",
      "batch 3818: loss 0.006073\n",
      "batch 3819: loss 0.005279\n",
      "batch 3820: loss 0.035404\n",
      "batch 3821: loss 0.018276\n",
      "batch 3822: loss 0.040963\n",
      "batch 3823: loss 0.013954\n",
      "batch 3824: loss 0.010791\n",
      "batch 3825: loss 0.043853\n",
      "batch 3826: loss 0.032415\n",
      "batch 3827: loss 0.023188\n",
      "batch 3828: loss 0.004136\n",
      "batch 3829: loss 0.007008\n",
      "batch 3830: loss 0.003159\n",
      "batch 3831: loss 0.034235\n",
      "batch 3832: loss 0.012470\n",
      "batch 3833: loss 0.015668\n",
      "batch 3834: loss 0.039635\n",
      "batch 3835: loss 0.006580\n",
      "batch 3836: loss 0.005204\n",
      "batch 3837: loss 0.024324\n",
      "batch 3838: loss 0.023219\n",
      "batch 3839: loss 0.001721\n",
      "batch 3840: loss 0.013859\n",
      "batch 3841: loss 0.023501\n",
      "batch 3842: loss 0.007791\n",
      "batch 3843: loss 0.051480\n",
      "batch 3844: loss 0.087823\n",
      "batch 3845: loss 0.060285\n",
      "batch 3846: loss 0.114844\n",
      "batch 3847: loss 0.083575\n",
      "batch 3848: loss 0.009461\n",
      "batch 3849: loss 0.077707\n",
      "batch 3850: loss 0.092726\n",
      "batch 3851: loss 0.073205\n",
      "batch 3852: loss 0.053414\n",
      "batch 3853: loss 0.008273\n",
      "batch 3854: loss 0.041098\n",
      "batch 3855: loss 0.011827\n",
      "batch 3856: loss 0.008769\n",
      "batch 3857: loss 0.003081\n",
      "batch 3858: loss 0.053052\n",
      "batch 3859: loss 0.047091\n",
      "batch 3860: loss 0.019550\n",
      "batch 3861: loss 0.005312\n",
      "batch 3862: loss 0.009152\n",
      "batch 3863: loss 0.021907\n",
      "batch 3864: loss 0.023264\n",
      "batch 3865: loss 0.081926\n",
      "batch 3866: loss 0.005012\n",
      "batch 3867: loss 0.034935\n",
      "batch 3868: loss 0.047019\n",
      "batch 3869: loss 0.007133\n",
      "batch 3870: loss 0.015822\n",
      "batch 3871: loss 0.025681\n",
      "batch 3872: loss 0.042744\n",
      "batch 3873: loss 0.025199\n",
      "batch 3874: loss 0.082078\n",
      "batch 3875: loss 0.049771\n",
      "batch 3876: loss 0.003656\n",
      "batch 3877: loss 0.103141\n",
      "batch 3878: loss 0.012324\n",
      "batch 3879: loss 0.075470\n",
      "batch 3880: loss 0.016676\n",
      "batch 3881: loss 0.069972\n",
      "batch 3882: loss 0.016344\n",
      "batch 3883: loss 0.015745\n",
      "batch 3884: loss 0.006160\n",
      "batch 3885: loss 0.070841\n",
      "batch 3886: loss 0.018525\n",
      "batch 3887: loss 0.033788\n",
      "batch 3888: loss 0.016971\n",
      "batch 3889: loss 0.021482\n",
      "batch 3890: loss 0.026198\n",
      "batch 3891: loss 0.010721\n",
      "batch 3892: loss 0.064949\n",
      "batch 3893: loss 0.023156\n",
      "batch 3894: loss 0.031480\n",
      "batch 3895: loss 0.005390\n",
      "batch 3896: loss 0.004766\n",
      "batch 3897: loss 0.010326\n",
      "batch 3898: loss 0.108030\n",
      "batch 3899: loss 0.049490\n",
      "batch 3900: loss 0.081940\n",
      "batch 3901: loss 0.015356\n",
      "batch 3902: loss 0.032593\n",
      "batch 3903: loss 0.008672\n",
      "batch 3904: loss 0.029309\n",
      "batch 3905: loss 0.013121\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 3906: loss 0.012235\n",
      "batch 3907: loss 0.034257\n",
      "batch 3908: loss 0.021335\n",
      "batch 3909: loss 0.005245\n",
      "batch 3910: loss 0.084467\n",
      "batch 3911: loss 0.032294\n",
      "batch 3912: loss 0.001914\n",
      "batch 3913: loss 0.036159\n",
      "batch 3914: loss 0.038977\n",
      "batch 3915: loss 0.004079\n",
      "batch 3916: loss 0.026641\n",
      "batch 3917: loss 0.039763\n",
      "batch 3918: loss 0.032168\n",
      "batch 3919: loss 0.007739\n",
      "batch 3920: loss 0.129827\n",
      "batch 3921: loss 0.014638\n",
      "batch 3922: loss 0.024856\n",
      "batch 3923: loss 0.006742\n",
      "batch 3924: loss 0.016557\n",
      "batch 3925: loss 0.010783\n",
      "batch 3926: loss 0.012093\n",
      "batch 3927: loss 0.027238\n",
      "batch 3928: loss 0.039427\n",
      "batch 3929: loss 0.018338\n",
      "batch 3930: loss 0.011016\n",
      "batch 3931: loss 0.034082\n",
      "batch 3932: loss 0.010184\n",
      "batch 3933: loss 0.024056\n",
      "batch 3934: loss 0.028443\n",
      "batch 3935: loss 0.010553\n",
      "batch 3936: loss 0.075735\n",
      "batch 3937: loss 0.115911\n",
      "batch 3938: loss 0.011311\n",
      "batch 3939: loss 0.006739\n",
      "batch 3940: loss 0.011380\n",
      "batch 3941: loss 0.008933\n",
      "batch 3942: loss 0.029300\n",
      "batch 3943: loss 0.010497\n",
      "batch 3944: loss 0.071559\n",
      "batch 3945: loss 0.007405\n",
      "batch 3946: loss 0.031974\n",
      "batch 3947: loss 0.006806\n",
      "batch 3948: loss 0.002650\n",
      "batch 3949: loss 0.015959\n",
      "batch 3950: loss 0.009305\n",
      "batch 3951: loss 0.030623\n",
      "batch 3952: loss 0.032436\n",
      "batch 3953: loss 0.155321\n",
      "batch 3954: loss 0.028718\n",
      "batch 3955: loss 0.006612\n",
      "batch 3956: loss 0.039520\n",
      "batch 3957: loss 0.002303\n",
      "batch 3958: loss 0.096349\n",
      "batch 3959: loss 0.032988\n",
      "batch 3960: loss 0.005036\n",
      "batch 3961: loss 0.040516\n",
      "batch 3962: loss 0.012466\n",
      "batch 3963: loss 0.017862\n",
      "batch 3964: loss 0.017701\n",
      "batch 3965: loss 0.017256\n",
      "batch 3966: loss 0.017957\n",
      "batch 3967: loss 0.034840\n",
      "batch 3968: loss 0.032181\n",
      "batch 3969: loss 0.016294\n",
      "batch 3970: loss 0.009815\n",
      "batch 3971: loss 0.048222\n",
      "batch 3972: loss 0.060640\n",
      "batch 3973: loss 0.019323\n",
      "batch 3974: loss 0.012807\n",
      "batch 3975: loss 0.020815\n",
      "batch 3976: loss 0.003224\n",
      "batch 3977: loss 0.014135\n",
      "batch 3978: loss 0.108863\n",
      "batch 3979: loss 0.017952\n",
      "batch 3980: loss 0.041016\n",
      "batch 3981: loss 0.011966\n",
      "batch 3982: loss 0.141037\n",
      "batch 3983: loss 0.005767\n",
      "batch 3984: loss 0.026021\n",
      "batch 3985: loss 0.008452\n",
      "batch 3986: loss 0.084616\n",
      "batch 3987: loss 0.010462\n",
      "batch 3988: loss 0.002018\n",
      "batch 3989: loss 0.033725\n",
      "batch 3990: loss 0.030853\n",
      "batch 3991: loss 0.006547\n",
      "batch 3992: loss 0.015798\n",
      "batch 3993: loss 0.098181\n",
      "batch 3994: loss 0.026112\n",
      "batch 3995: loss 0.004182\n",
      "batch 3996: loss 0.021663\n",
      "batch 3997: loss 0.010863\n",
      "batch 3998: loss 0.058229\n",
      "batch 3999: loss 0.005757\n",
      "batch 4000: loss 0.002167\n",
      "batch 4001: loss 0.010287\n",
      "batch 4002: loss 0.145721\n",
      "batch 4003: loss 0.009667\n",
      "batch 4004: loss 0.034347\n",
      "batch 4005: loss 0.069511\n",
      "batch 4006: loss 0.018402\n",
      "batch 4007: loss 0.015626\n",
      "batch 4008: loss 0.031528\n",
      "batch 4009: loss 0.014433\n",
      "batch 4010: loss 0.019915\n",
      "batch 4011: loss 0.148494\n",
      "batch 4012: loss 0.019055\n",
      "batch 4013: loss 0.058143\n",
      "batch 4014: loss 0.010408\n",
      "batch 4015: loss 0.049241\n",
      "batch 4016: loss 0.008575\n",
      "batch 4017: loss 0.008725\n",
      "batch 4018: loss 0.010675\n",
      "batch 4019: loss 0.021286\n",
      "batch 4020: loss 0.002674\n",
      "batch 4021: loss 0.053742\n",
      "batch 4022: loss 0.020305\n",
      "batch 4023: loss 0.004817\n",
      "batch 4024: loss 0.003705\n",
      "batch 4025: loss 0.017037\n",
      "batch 4026: loss 0.024342\n",
      "batch 4027: loss 0.011828\n",
      "batch 4028: loss 0.012915\n",
      "batch 4029: loss 0.008833\n",
      "batch 4030: loss 0.009222\n",
      "batch 4031: loss 0.027532\n",
      "batch 4032: loss 0.015746\n",
      "batch 4033: loss 0.013945\n",
      "batch 4034: loss 0.015698\n",
      "batch 4035: loss 0.029255\n",
      "batch 4036: loss 0.025117\n",
      "batch 4037: loss 0.013006\n",
      "batch 4038: loss 0.003804\n",
      "batch 4039: loss 0.092817\n",
      "batch 4040: loss 0.057827\n",
      "batch 4041: loss 0.007057\n",
      "batch 4042: loss 0.013389\n",
      "batch 4043: loss 0.006228\n",
      "batch 4044: loss 0.003557\n",
      "batch 4045: loss 0.023845\n",
      "batch 4046: loss 0.010596\n",
      "batch 4047: loss 0.002722\n",
      "batch 4048: loss 0.022589\n",
      "batch 4049: loss 0.015699\n",
      "batch 4050: loss 0.104458\n",
      "batch 4051: loss 0.021447\n",
      "batch 4052: loss 0.002814\n",
      "batch 4053: loss 0.005675\n",
      "batch 4054: loss 0.009385\n",
      "batch 4055: loss 0.068508\n",
      "batch 4056: loss 0.007074\n",
      "batch 4057: loss 0.003074\n",
      "batch 4058: loss 0.014461\n",
      "batch 4059: loss 0.005649\n",
      "batch 4060: loss 0.052575\n",
      "batch 4061: loss 0.042831\n",
      "batch 4062: loss 0.021128\n",
      "batch 4063: loss 0.035753\n",
      "batch 4064: loss 0.024756\n",
      "batch 4065: loss 0.045768\n",
      "batch 4066: loss 0.030260\n",
      "batch 4067: loss 0.010289\n",
      "batch 4068: loss 0.004945\n",
      "batch 4069: loss 0.003410\n",
      "batch 4070: loss 0.008031\n",
      "batch 4071: loss 0.011623\n",
      "batch 4072: loss 0.031023\n",
      "batch 4073: loss 0.034196\n",
      "batch 4074: loss 0.032129\n",
      "batch 4075: loss 0.059821\n",
      "batch 4076: loss 0.007880\n",
      "batch 4077: loss 0.034808\n",
      "batch 4078: loss 0.017195\n",
      "batch 4079: loss 0.013148\n",
      "batch 4080: loss 0.003179\n",
      "batch 4081: loss 0.058150\n",
      "batch 4082: loss 0.008220\n",
      "batch 4083: loss 0.009204\n",
      "batch 4084: loss 0.024574\n",
      "batch 4085: loss 0.056226\n",
      "batch 4086: loss 0.005872\n",
      "batch 4087: loss 0.022486\n",
      "batch 4088: loss 0.010802\n",
      "batch 4089: loss 0.019357\n",
      "batch 4090: loss 0.008586\n",
      "batch 4091: loss 0.005544\n",
      "batch 4092: loss 0.055622\n",
      "batch 4093: loss 0.002130\n",
      "batch 4094: loss 0.012177\n",
      "batch 4095: loss 0.060287\n",
      "batch 4096: loss 0.015446\n",
      "batch 4097: loss 0.008032\n",
      "batch 4098: loss 0.055172\n",
      "batch 4099: loss 0.025572\n",
      "batch 4100: loss 0.004403\n",
      "batch 4101: loss 0.009018\n",
      "batch 4102: loss 0.157056\n",
      "batch 4103: loss 0.002598\n",
      "batch 4104: loss 0.073098\n",
      "batch 4105: loss 0.023237\n",
      "batch 4106: loss 0.007965\n",
      "batch 4107: loss 0.024805\n",
      "batch 4108: loss 0.007293\n",
      "batch 4109: loss 0.000966\n",
      "batch 4110: loss 0.006886\n",
      "batch 4111: loss 0.023913\n",
      "batch 4112: loss 0.026354\n",
      "batch 4113: loss 0.011504\n",
      "batch 4114: loss 0.007969\n",
      "batch 4115: loss 0.011395\n",
      "batch 4116: loss 0.002879\n",
      "batch 4117: loss 0.009803\n",
      "batch 4118: loss 0.011493\n",
      "batch 4119: loss 0.006026\n",
      "batch 4120: loss 0.029766\n",
      "batch 4121: loss 0.007470\n",
      "batch 4122: loss 0.010062\n",
      "batch 4123: loss 0.015765\n",
      "batch 4124: loss 0.035516\n",
      "batch 4125: loss 0.025709\n",
      "batch 4126: loss 0.011529\n",
      "batch 4127: loss 0.017293\n",
      "batch 4128: loss 0.004842\n",
      "batch 4129: loss 0.010330\n",
      "batch 4130: loss 0.002687\n",
      "batch 4131: loss 0.010260\n",
      "batch 4132: loss 0.049483\n",
      "batch 4133: loss 0.014735\n",
      "batch 4134: loss 0.005800\n",
      "batch 4135: loss 0.004847\n",
      "batch 4136: loss 0.034984\n",
      "batch 4137: loss 0.029342\n",
      "batch 4138: loss 0.015395\n",
      "batch 4139: loss 0.054944\n",
      "batch 4140: loss 0.011035\n",
      "batch 4141: loss 0.090672\n",
      "batch 4142: loss 0.007664\n",
      "batch 4143: loss 0.007399\n",
      "batch 4144: loss 0.004021\n",
      "batch 4145: loss 0.010421\n",
      "batch 4146: loss 0.107317\n",
      "batch 4147: loss 0.041485\n",
      "batch 4148: loss 0.010104\n",
      "batch 4149: loss 0.076935\n",
      "batch 4150: loss 0.007574\n",
      "batch 4151: loss 0.028608\n",
      "batch 4152: loss 0.003695\n",
      "batch 4153: loss 0.006425\n",
      "batch 4154: loss 0.017895\n",
      "batch 4155: loss 0.007956\n",
      "batch 4156: loss 0.035606\n",
      "batch 4157: loss 0.007577\n",
      "batch 4158: loss 0.017692\n",
      "batch 4159: loss 0.094513\n",
      "batch 4160: loss 0.002881\n",
      "batch 4161: loss 0.013547\n",
      "batch 4162: loss 0.029478\n",
      "batch 4163: loss 0.013308\n",
      "batch 4164: loss 0.005433\n",
      "batch 4165: loss 0.002429\n",
      "batch 4166: loss 0.004434\n",
      "batch 4167: loss 0.007473\n",
      "batch 4168: loss 0.002338\n",
      "batch 4169: loss 0.015240\n",
      "batch 4170: loss 0.046265\n",
      "batch 4171: loss 0.058395\n",
      "batch 4172: loss 0.035077\n",
      "batch 4173: loss 0.053541\n",
      "batch 4174: loss 0.004394\n",
      "batch 4175: loss 0.015490\n",
      "batch 4176: loss 0.001463\n",
      "batch 4177: loss 0.030461\n",
      "batch 4178: loss 0.070757\n",
      "batch 4179: loss 0.156277\n",
      "batch 4180: loss 0.017962\n",
      "batch 4181: loss 0.015058\n",
      "batch 4182: loss 0.006397\n",
      "batch 4183: loss 0.008093\n",
      "batch 4184: loss 0.012878\n",
      "batch 4185: loss 0.006534\n",
      "batch 4186: loss 0.004569\n",
      "batch 4187: loss 0.012089\n",
      "batch 4188: loss 0.012325\n",
      "batch 4189: loss 0.013081\n",
      "batch 4190: loss 0.039492\n",
      "batch 4191: loss 0.005989\n",
      "batch 4192: loss 0.009434\n",
      "batch 4193: loss 0.012509\n",
      "batch 4194: loss 0.084111\n",
      "batch 4195: loss 0.101206\n",
      "batch 4196: loss 0.018164\n",
      "batch 4197: loss 0.014136\n",
      "batch 4198: loss 0.013906\n",
      "batch 4199: loss 0.009362\n",
      "batch 4200: loss 0.009833\n",
      "batch 4201: loss 0.012095\n",
      "batch 4202: loss 0.098004\n",
      "batch 4203: loss 0.018758\n",
      "batch 4204: loss 0.001659\n",
      "batch 4205: loss 0.021123\n",
      "batch 4206: loss 0.060963\n",
      "batch 4207: loss 0.022100\n",
      "batch 4208: loss 0.007485\n",
      "batch 4209: loss 0.015928\n",
      "batch 4210: loss 0.018635\n",
      "batch 4211: loss 0.007508\n",
      "batch 4212: loss 0.001637\n",
      "batch 4213: loss 0.047499\n",
      "batch 4214: loss 0.010088\n",
      "batch 4215: loss 0.003947\n",
      "batch 4216: loss 0.013690\n",
      "batch 4217: loss 0.172531\n",
      "batch 4218: loss 0.021712\n",
      "batch 4219: loss 0.102388\n",
      "batch 4220: loss 0.042693\n",
      "batch 4221: loss 0.089854\n",
      "batch 4222: loss 0.007247\n",
      "batch 4223: loss 0.003227\n",
      "batch 4224: loss 0.006148\n",
      "batch 4225: loss 0.001680\n",
      "batch 4226: loss 0.009470\n",
      "batch 4227: loss 0.011254\n",
      "batch 4228: loss 0.052328\n",
      "batch 4229: loss 0.038912\n",
      "batch 4230: loss 0.011827\n",
      "batch 4231: loss 0.005490\n",
      "batch 4232: loss 0.031245\n",
      "batch 4233: loss 0.016737\n",
      "batch 4234: loss 0.007432\n",
      "batch 4235: loss 0.061111\n",
      "batch 4236: loss 0.064215\n",
      "batch 4237: loss 0.085066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4238: loss 0.229798\n",
      "batch 4239: loss 0.003272\n",
      "batch 4240: loss 0.018600\n",
      "batch 4241: loss 0.033771\n",
      "batch 4242: loss 0.002585\n",
      "batch 4243: loss 0.012675\n",
      "batch 4244: loss 0.007429\n",
      "batch 4245: loss 0.019834\n",
      "batch 4246: loss 0.025956\n",
      "batch 4247: loss 0.012634\n",
      "batch 4248: loss 0.006523\n",
      "batch 4249: loss 0.001932\n",
      "batch 4250: loss 0.013837\n",
      "batch 4251: loss 0.007800\n",
      "batch 4252: loss 0.009683\n",
      "batch 4253: loss 0.058026\n",
      "batch 4254: loss 0.102437\n",
      "batch 4255: loss 0.027235\n",
      "batch 4256: loss 0.008719\n",
      "batch 4257: loss 0.098299\n",
      "batch 4258: loss 0.053622\n",
      "batch 4259: loss 0.032191\n",
      "batch 4260: loss 0.043887\n",
      "batch 4261: loss 0.012757\n",
      "batch 4262: loss 0.049538\n",
      "batch 4263: loss 0.017145\n",
      "batch 4264: loss 0.018944\n",
      "batch 4265: loss 0.041853\n",
      "batch 4266: loss 0.012616\n",
      "batch 4267: loss 0.007287\n",
      "batch 4268: loss 0.015538\n",
      "batch 4269: loss 0.004391\n",
      "batch 4270: loss 0.019361\n",
      "batch 4271: loss 0.019851\n",
      "batch 4272: loss 0.018571\n",
      "batch 4273: loss 0.040344\n",
      "batch 4274: loss 0.010943\n",
      "batch 4275: loss 0.037983\n",
      "batch 4276: loss 0.017382\n",
      "batch 4277: loss 0.006121\n",
      "batch 4278: loss 0.014666\n",
      "batch 4279: loss 0.011344\n",
      "batch 4280: loss 0.026657\n",
      "batch 4281: loss 0.038303\n",
      "batch 4282: loss 0.017082\n",
      "batch 4283: loss 0.010106\n",
      "batch 4284: loss 0.017612\n",
      "batch 4285: loss 0.018044\n",
      "batch 4286: loss 0.002222\n",
      "batch 4287: loss 0.019470\n",
      "batch 4288: loss 0.009118\n",
      "batch 4289: loss 0.041959\n",
      "batch 4290: loss 0.003238\n",
      "batch 4291: loss 0.001966\n",
      "batch 4292: loss 0.064512\n",
      "batch 4293: loss 0.003892\n",
      "batch 4294: loss 0.007414\n",
      "batch 4295: loss 0.021808\n",
      "batch 4296: loss 0.007301\n",
      "batch 4297: loss 0.046646\n",
      "batch 4298: loss 0.019193\n",
      "batch 4299: loss 0.031615\n",
      "batch 4300: loss 0.055311\n",
      "batch 4301: loss 0.022129\n",
      "batch 4302: loss 0.002895\n",
      "batch 4303: loss 0.041711\n",
      "batch 4304: loss 0.006436\n",
      "batch 4305: loss 0.054426\n",
      "batch 4306: loss 0.069072\n",
      "batch 4307: loss 0.018592\n",
      "batch 4308: loss 0.035797\n",
      "batch 4309: loss 0.024147\n",
      "batch 4310: loss 0.040225\n",
      "batch 4311: loss 0.078274\n",
      "batch 4312: loss 0.015531\n",
      "batch 4313: loss 0.036317\n",
      "batch 4314: loss 0.003116\n",
      "batch 4315: loss 0.008087\n",
      "batch 4316: loss 0.008295\n",
      "batch 4317: loss 0.021581\n",
      "batch 4318: loss 0.013189\n",
      "batch 4319: loss 0.024048\n",
      "batch 4320: loss 0.011341\n",
      "batch 4321: loss 0.007355\n",
      "batch 4322: loss 0.029585\n",
      "batch 4323: loss 0.010878\n",
      "batch 4324: loss 0.033303\n",
      "batch 4325: loss 0.001828\n",
      "batch 4326: loss 0.018588\n",
      "batch 4327: loss 0.013822\n",
      "batch 4328: loss 0.054271\n",
      "batch 4329: loss 0.007248\n",
      "batch 4330: loss 0.022192\n",
      "batch 4331: loss 0.006890\n",
      "batch 4332: loss 0.032172\n",
      "batch 4333: loss 0.001757\n",
      "batch 4334: loss 0.003304\n",
      "batch 4335: loss 0.053567\n",
      "batch 4336: loss 0.026680\n",
      "batch 4337: loss 0.007258\n",
      "batch 4338: loss 0.012714\n",
      "batch 4339: loss 0.018920\n",
      "batch 4340: loss 0.015911\n",
      "batch 4341: loss 0.006612\n",
      "batch 4342: loss 0.038700\n",
      "batch 4343: loss 0.012352\n",
      "batch 4344: loss 0.040006\n",
      "batch 4345: loss 0.066884\n",
      "batch 4346: loss 0.005711\n",
      "batch 4347: loss 0.009765\n",
      "batch 4348: loss 0.033241\n",
      "batch 4349: loss 0.016622\n",
      "batch 4350: loss 0.009908\n",
      "batch 4351: loss 0.009094\n",
      "batch 4352: loss 0.012597\n",
      "batch 4353: loss 0.002074\n",
      "batch 4354: loss 0.016232\n",
      "batch 4355: loss 0.023428\n",
      "batch 4356: loss 0.063053\n",
      "batch 4357: loss 0.054800\n",
      "batch 4358: loss 0.009015\n",
      "batch 4359: loss 0.047520\n",
      "batch 4360: loss 0.077016\n",
      "batch 4361: loss 0.014797\n",
      "batch 4362: loss 0.033778\n",
      "batch 4363: loss 0.007250\n",
      "batch 4364: loss 0.045046\n",
      "batch 4365: loss 0.006052\n",
      "batch 4366: loss 0.011218\n",
      "batch 4367: loss 0.018074\n",
      "batch 4368: loss 0.004755\n",
      "batch 4369: loss 0.102894\n",
      "batch 4370: loss 0.002389\n",
      "batch 4371: loss 0.012917\n",
      "batch 4372: loss 0.054270\n",
      "batch 4373: loss 0.099521\n",
      "batch 4374: loss 0.008319\n",
      "batch 4375: loss 0.005855\n",
      "batch 4376: loss 0.039199\n",
      "batch 4377: loss 0.104208\n",
      "batch 4378: loss 0.014350\n",
      "batch 4379: loss 0.004960\n",
      "batch 4380: loss 0.141540\n",
      "batch 4381: loss 0.006818\n",
      "batch 4382: loss 0.015675\n",
      "batch 4383: loss 0.022752\n",
      "batch 4384: loss 0.036454\n",
      "batch 4385: loss 0.001471\n",
      "batch 4386: loss 0.063674\n",
      "batch 4387: loss 0.011997\n",
      "batch 4388: loss 0.004086\n",
      "batch 4389: loss 0.081035\n",
      "batch 4390: loss 0.047650\n",
      "batch 4391: loss 0.032667\n",
      "batch 4392: loss 0.009780\n",
      "batch 4393: loss 0.007463\n",
      "batch 4394: loss 0.044988\n",
      "batch 4395: loss 0.016494\n",
      "batch 4396: loss 0.016750\n",
      "batch 4397: loss 0.003180\n",
      "batch 4398: loss 0.015447\n",
      "batch 4399: loss 0.011417\n",
      "batch 4400: loss 0.007684\n",
      "batch 4401: loss 0.019727\n",
      "batch 4402: loss 0.015106\n",
      "batch 4403: loss 0.011063\n",
      "batch 4404: loss 0.003463\n",
      "batch 4405: loss 0.004906\n",
      "batch 4406: loss 0.009683\n",
      "batch 4407: loss 0.046757\n",
      "batch 4408: loss 0.012796\n",
      "batch 4409: loss 0.059243\n",
      "batch 4410: loss 0.051340\n",
      "batch 4411: loss 0.009160\n",
      "batch 4412: loss 0.017998\n",
      "batch 4413: loss 0.008223\n",
      "batch 4414: loss 0.004451\n",
      "batch 4415: loss 0.015673\n",
      "batch 4416: loss 0.003259\n",
      "batch 4417: loss 0.007625\n",
      "batch 4418: loss 0.016386\n",
      "batch 4419: loss 0.007235\n",
      "batch 4420: loss 0.001927\n",
      "batch 4421: loss 0.009843\n",
      "batch 4422: loss 0.069651\n",
      "batch 4423: loss 0.001205\n",
      "batch 4424: loss 0.063974\n",
      "batch 4425: loss 0.007125\n",
      "batch 4426: loss 0.007322\n",
      "batch 4427: loss 0.031658\n",
      "batch 4428: loss 0.011042\n",
      "batch 4429: loss 0.140460\n",
      "batch 4430: loss 0.020078\n",
      "batch 4431: loss 0.013717\n",
      "batch 4432: loss 0.005743\n",
      "batch 4433: loss 0.012564\n",
      "batch 4434: loss 0.007270\n",
      "batch 4435: loss 0.080785\n",
      "batch 4436: loss 0.005805\n",
      "batch 4437: loss 0.086432\n",
      "batch 4438: loss 0.024368\n",
      "batch 4439: loss 0.026240\n",
      "batch 4440: loss 0.056262\n",
      "batch 4441: loss 0.018275\n",
      "batch 4442: loss 0.008048\n",
      "batch 4443: loss 0.018870\n",
      "batch 4444: loss 0.019236\n",
      "batch 4445: loss 0.053139\n",
      "batch 4446: loss 0.012347\n",
      "batch 4447: loss 0.009122\n",
      "batch 4448: loss 0.025377\n",
      "batch 4449: loss 0.022945\n",
      "batch 4450: loss 0.005547\n",
      "batch 4451: loss 0.059268\n",
      "batch 4452: loss 0.081968\n",
      "batch 4453: loss 0.008586\n",
      "batch 4454: loss 0.017523\n",
      "batch 4455: loss 0.100235\n",
      "batch 4456: loss 0.010922\n",
      "batch 4457: loss 0.006661\n",
      "batch 4458: loss 0.005761\n",
      "batch 4459: loss 0.018090\n",
      "batch 4460: loss 0.033834\n",
      "batch 4461: loss 0.008948\n",
      "batch 4462: loss 0.027089\n",
      "batch 4463: loss 0.027838\n",
      "batch 4464: loss 0.022007\n",
      "batch 4465: loss 0.092495\n",
      "batch 4466: loss 0.036855\n",
      "batch 4467: loss 0.005998\n",
      "batch 4468: loss 0.010033\n",
      "batch 4469: loss 0.021587\n",
      "batch 4470: loss 0.076942\n",
      "batch 4471: loss 0.112595\n",
      "batch 4472: loss 0.011704\n",
      "batch 4473: loss 0.011366\n",
      "batch 4474: loss 0.049201\n",
      "batch 4475: loss 0.005798\n",
      "batch 4476: loss 0.022237\n",
      "batch 4477: loss 0.027655\n",
      "batch 4478: loss 0.009094\n",
      "batch 4479: loss 0.016829\n",
      "batch 4480: loss 0.035441\n",
      "batch 4481: loss 0.013610\n",
      "batch 4482: loss 0.029753\n",
      "batch 4483: loss 0.005812\n",
      "batch 4484: loss 0.047420\n",
      "batch 4485: loss 0.004712\n",
      "batch 4486: loss 0.010925\n",
      "batch 4487: loss 0.012412\n",
      "batch 4488: loss 0.020096\n",
      "batch 4489: loss 0.008369\n",
      "batch 4490: loss 0.009169\n",
      "batch 4491: loss 0.141428\n",
      "batch 4492: loss 0.045241\n",
      "batch 4493: loss 0.041262\n",
      "batch 4494: loss 0.017495\n",
      "batch 4495: loss 0.003059\n",
      "batch 4496: loss 0.019021\n",
      "batch 4497: loss 0.018337\n",
      "batch 4498: loss 0.020742\n",
      "batch 4499: loss 0.073354\n",
      "batch 4500: loss 0.037658\n",
      "batch 4501: loss 0.003447\n",
      "batch 4502: loss 0.016788\n",
      "batch 4503: loss 0.024711\n",
      "batch 4504: loss 0.005523\n",
      "batch 4505: loss 0.038883\n",
      "batch 4506: loss 0.077466\n",
      "batch 4507: loss 0.013013\n",
      "batch 4508: loss 0.030469\n",
      "batch 4509: loss 0.004696\n",
      "batch 4510: loss 0.007567\n",
      "batch 4511: loss 0.004658\n",
      "batch 4512: loss 0.012279\n",
      "batch 4513: loss 0.005354\n",
      "batch 4514: loss 0.001656\n",
      "batch 4515: loss 0.052119\n",
      "batch 4516: loss 0.005137\n",
      "batch 4517: loss 0.021382\n",
      "batch 4518: loss 0.026108\n",
      "batch 4519: loss 0.019739\n",
      "batch 4520: loss 0.020087\n",
      "batch 4521: loss 0.027467\n",
      "batch 4522: loss 0.002983\n",
      "batch 4523: loss 0.105269\n",
      "batch 4524: loss 0.108289\n",
      "batch 4525: loss 0.006549\n",
      "batch 4526: loss 0.014404\n",
      "batch 4527: loss 0.013285\n",
      "batch 4528: loss 0.037881\n",
      "batch 4529: loss 0.051070\n",
      "batch 4530: loss 0.029619\n",
      "batch 4531: loss 0.024726\n",
      "batch 4532: loss 0.011584\n",
      "batch 4533: loss 0.011347\n",
      "batch 4534: loss 0.005190\n",
      "batch 4535: loss 0.023675\n",
      "batch 4536: loss 0.035112\n",
      "batch 4537: loss 0.008667\n",
      "batch 4538: loss 0.004729\n",
      "batch 4539: loss 0.011650\n",
      "batch 4540: loss 0.007564\n",
      "batch 4541: loss 0.009115\n",
      "batch 4542: loss 0.032740\n",
      "batch 4543: loss 0.023636\n",
      "batch 4544: loss 0.019215\n",
      "batch 4545: loss 0.003094\n",
      "batch 4546: loss 0.004101\n",
      "batch 4547: loss 0.002931\n",
      "batch 4548: loss 0.007610\n",
      "batch 4549: loss 0.010954\n",
      "batch 4550: loss 0.017510\n",
      "batch 4551: loss 0.002795\n",
      "batch 4552: loss 0.006050\n",
      "batch 4553: loss 0.015875\n",
      "batch 4554: loss 0.023719\n",
      "batch 4555: loss 0.016810\n",
      "batch 4556: loss 0.007101\n",
      "batch 4557: loss 0.031347\n",
      "batch 4558: loss 0.010989\n",
      "batch 4559: loss 0.017529\n",
      "batch 4560: loss 0.038369\n",
      "batch 4561: loss 0.034535\n",
      "batch 4562: loss 0.003767\n",
      "batch 4563: loss 0.016055\n",
      "batch 4564: loss 0.037616\n",
      "batch 4565: loss 0.011097\n",
      "batch 4566: loss 0.022711\n",
      "batch 4567: loss 0.001888\n",
      "batch 4568: loss 0.018166\n",
      "batch 4569: loss 0.009475\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4570: loss 0.005335\n",
      "batch 4571: loss 0.000651\n",
      "batch 4572: loss 0.022285\n",
      "batch 4573: loss 0.072639\n",
      "batch 4574: loss 0.035801\n",
      "batch 4575: loss 0.029677\n",
      "batch 4576: loss 0.017971\n",
      "batch 4577: loss 0.006688\n",
      "batch 4578: loss 0.019029\n",
      "batch 4579: loss 0.024749\n",
      "batch 4580: loss 0.010227\n",
      "batch 4581: loss 0.019319\n",
      "batch 4582: loss 0.079775\n",
      "batch 4583: loss 0.100155\n",
      "batch 4584: loss 0.092702\n",
      "batch 4585: loss 0.070334\n",
      "batch 4586: loss 0.015007\n",
      "batch 4587: loss 0.013493\n",
      "batch 4588: loss 0.019800\n",
      "batch 4589: loss 0.039612\n",
      "batch 4590: loss 0.008423\n",
      "batch 4591: loss 0.011145\n",
      "batch 4592: loss 0.009940\n",
      "batch 4593: loss 0.011571\n",
      "batch 4594: loss 0.068499\n",
      "batch 4595: loss 0.052960\n",
      "batch 4596: loss 0.010731\n",
      "batch 4597: loss 0.163809\n",
      "batch 4598: loss 0.010237\n",
      "batch 4599: loss 0.064604\n",
      "batch 4600: loss 0.006499\n",
      "batch 4601: loss 0.006417\n",
      "batch 4602: loss 0.011987\n",
      "batch 4603: loss 0.065023\n",
      "batch 4604: loss 0.012093\n",
      "batch 4605: loss 0.056215\n",
      "batch 4606: loss 0.025775\n",
      "batch 4607: loss 0.008937\n",
      "batch 4608: loss 0.024642\n",
      "batch 4609: loss 0.119916\n",
      "batch 4610: loss 0.006809\n",
      "batch 4611: loss 0.002005\n",
      "batch 4612: loss 0.005519\n",
      "batch 4613: loss 0.020087\n",
      "batch 4614: loss 0.006975\n",
      "batch 4615: loss 0.095188\n",
      "batch 4616: loss 0.005104\n",
      "batch 4617: loss 0.002672\n",
      "batch 4618: loss 0.004057\n",
      "batch 4619: loss 0.007725\n",
      "batch 4620: loss 0.010145\n",
      "batch 4621: loss 0.030322\n",
      "batch 4622: loss 0.010363\n",
      "batch 4623: loss 0.002293\n",
      "batch 4624: loss 0.007878\n",
      "batch 4625: loss 0.043572\n",
      "batch 4626: loss 0.001609\n",
      "batch 4627: loss 0.002154\n",
      "batch 4628: loss 0.020319\n",
      "batch 4629: loss 0.007463\n",
      "batch 4630: loss 0.005618\n",
      "batch 4631: loss 0.002254\n",
      "batch 4632: loss 0.009012\n",
      "batch 4633: loss 0.006713\n",
      "batch 4634: loss 0.007454\n",
      "batch 4635: loss 0.009008\n",
      "batch 4636: loss 0.001192\n",
      "batch 4637: loss 0.017056\n",
      "batch 4638: loss 0.010841\n",
      "batch 4639: loss 0.009663\n",
      "batch 4640: loss 0.006305\n",
      "batch 4641: loss 0.009850\n",
      "batch 4642: loss 0.009351\n",
      "batch 4643: loss 0.016862\n",
      "batch 4644: loss 0.140976\n",
      "batch 4645: loss 0.014314\n",
      "batch 4646: loss 0.023587\n",
      "batch 4647: loss 0.003737\n",
      "batch 4648: loss 0.001660\n",
      "batch 4649: loss 0.007450\n",
      "batch 4650: loss 0.003147\n",
      "batch 4651: loss 0.009785\n",
      "batch 4652: loss 0.007337\n",
      "batch 4653: loss 0.007781\n",
      "batch 4654: loss 0.009813\n",
      "batch 4655: loss 0.005026\n",
      "batch 4656: loss 0.099721\n",
      "batch 4657: loss 0.015962\n",
      "batch 4658: loss 0.039642\n",
      "batch 4659: loss 0.004482\n",
      "batch 4660: loss 0.022411\n",
      "batch 4661: loss 0.024073\n",
      "batch 4662: loss 0.002973\n",
      "batch 4663: loss 0.040875\n",
      "batch 4664: loss 0.013965\n",
      "batch 4665: loss 0.018610\n",
      "batch 4666: loss 0.105789\n",
      "batch 4667: loss 0.010278\n",
      "batch 4668: loss 0.026038\n",
      "batch 4669: loss 0.009445\n",
      "batch 4670: loss 0.098104\n",
      "batch 4671: loss 0.006014\n",
      "batch 4672: loss 0.016484\n",
      "batch 4673: loss 0.101257\n",
      "batch 4674: loss 0.066571\n",
      "batch 4675: loss 0.004228\n",
      "batch 4676: loss 0.004592\n",
      "batch 4677: loss 0.008581\n",
      "batch 4678: loss 0.046316\n",
      "batch 4679: loss 0.008892\n",
      "batch 4680: loss 0.009608\n",
      "batch 4681: loss 0.015713\n",
      "batch 4682: loss 0.009440\n",
      "batch 4683: loss 0.005095\n",
      "batch 4684: loss 0.003814\n",
      "batch 4685: loss 0.025451\n",
      "batch 4686: loss 0.020396\n",
      "batch 4687: loss 0.002619\n",
      "batch 4688: loss 0.025541\n",
      "batch 4689: loss 0.079074\n",
      "batch 4690: loss 0.037937\n",
      "batch 4691: loss 0.023429\n",
      "batch 4692: loss 0.010406\n",
      "batch 4693: loss 0.049285\n",
      "batch 4694: loss 0.010640\n",
      "batch 4695: loss 0.041811\n",
      "batch 4696: loss 0.012143\n",
      "batch 4697: loss 0.003166\n",
      "batch 4698: loss 0.019658\n",
      "batch 4699: loss 0.018905\n",
      "batch 4700: loss 0.040186\n",
      "batch 4701: loss 0.046278\n",
      "batch 4702: loss 0.004739\n",
      "batch 4703: loss 0.004117\n",
      "batch 4704: loss 0.053613\n",
      "batch 4705: loss 0.012242\n",
      "batch 4706: loss 0.035271\n",
      "batch 4707: loss 0.005512\n",
      "batch 4708: loss 0.005991\n",
      "batch 4709: loss 0.018249\n",
      "batch 4710: loss 0.044708\n",
      "batch 4711: loss 0.030804\n",
      "batch 4712: loss 0.007598\n",
      "batch 4713: loss 0.015103\n",
      "batch 4714: loss 0.018448\n",
      "batch 4715: loss 0.044895\n",
      "batch 4716: loss 0.048870\n",
      "batch 4717: loss 0.010848\n",
      "batch 4718: loss 0.006095\n",
      "batch 4719: loss 0.026640\n",
      "batch 4720: loss 0.023497\n",
      "batch 4721: loss 0.009095\n",
      "batch 4722: loss 0.077032\n",
      "batch 4723: loss 0.007509\n",
      "batch 4724: loss 0.201290\n",
      "batch 4725: loss 0.003119\n",
      "batch 4726: loss 0.030204\n",
      "batch 4727: loss 0.032006\n",
      "batch 4728: loss 0.004916\n",
      "batch 4729: loss 0.005088\n",
      "batch 4730: loss 0.009353\n",
      "batch 4731: loss 0.003388\n",
      "batch 4732: loss 0.035087\n",
      "batch 4733: loss 0.007921\n",
      "batch 4734: loss 0.007271\n",
      "batch 4735: loss 0.006796\n",
      "batch 4736: loss 0.003184\n",
      "batch 4737: loss 0.004854\n",
      "batch 4738: loss 0.089326\n",
      "batch 4739: loss 0.020198\n",
      "batch 4740: loss 0.010628\n",
      "batch 4741: loss 0.007969\n",
      "batch 4742: loss 0.015831\n",
      "batch 4743: loss 0.011159\n",
      "batch 4744: loss 0.016650\n",
      "batch 4745: loss 0.000987\n",
      "batch 4746: loss 0.024607\n",
      "batch 4747: loss 0.074327\n",
      "batch 4748: loss 0.009499\n",
      "batch 4749: loss 0.004375\n",
      "batch 4750: loss 0.002513\n",
      "batch 4751: loss 0.027361\n",
      "batch 4752: loss 0.010011\n",
      "batch 4753: loss 0.012388\n",
      "batch 4754: loss 0.005760\n",
      "batch 4755: loss 0.047420\n",
      "batch 4756: loss 0.010341\n",
      "batch 4757: loss 0.012055\n",
      "batch 4758: loss 0.000721\n",
      "batch 4759: loss 0.087183\n",
      "batch 4760: loss 0.002719\n",
      "batch 4761: loss 0.007383\n",
      "batch 4762: loss 0.008901\n",
      "batch 4763: loss 0.002011\n",
      "batch 4764: loss 0.045197\n",
      "batch 4765: loss 0.020923\n",
      "batch 4766: loss 0.011229\n",
      "batch 4767: loss 0.036653\n",
      "batch 4768: loss 0.008408\n",
      "batch 4769: loss 0.031477\n",
      "batch 4770: loss 0.014506\n",
      "batch 4771: loss 0.028850\n",
      "batch 4772: loss 0.012983\n",
      "batch 4773: loss 0.023945\n",
      "batch 4774: loss 0.016204\n",
      "batch 4775: loss 0.007629\n",
      "batch 4776: loss 0.056958\n",
      "batch 4777: loss 0.001205\n",
      "batch 4778: loss 0.039206\n",
      "batch 4779: loss 0.005843\n",
      "batch 4780: loss 0.012342\n",
      "batch 4781: loss 0.002528\n",
      "batch 4782: loss 0.293060\n",
      "batch 4783: loss 0.009905\n",
      "batch 4784: loss 0.020785\n",
      "batch 4785: loss 0.093903\n",
      "batch 4786: loss 0.006640\n",
      "batch 4787: loss 0.016445\n",
      "batch 4788: loss 0.055748\n",
      "batch 4789: loss 0.005701\n",
      "batch 4790: loss 0.014450\n",
      "batch 4791: loss 0.044656\n",
      "batch 4792: loss 0.006645\n",
      "batch 4793: loss 0.081950\n",
      "batch 4794: loss 0.002522\n",
      "batch 4795: loss 0.082587\n",
      "batch 4796: loss 0.003299\n",
      "batch 4797: loss 0.178757\n",
      "batch 4798: loss 0.015735\n",
      "batch 4799: loss 0.005148\n",
      "batch 4800: loss 0.010925\n",
      "batch 4801: loss 0.053910\n",
      "batch 4802: loss 0.063525\n",
      "batch 4803: loss 0.023488\n",
      "batch 4804: loss 0.018684\n",
      "batch 4805: loss 0.002945\n",
      "batch 4806: loss 0.072732\n",
      "batch 4807: loss 0.001440\n",
      "batch 4808: loss 0.007634\n",
      "batch 4809: loss 0.024871\n",
      "batch 4810: loss 0.008829\n",
      "batch 4811: loss 0.016101\n",
      "batch 4812: loss 0.060905\n",
      "batch 4813: loss 0.046339\n",
      "batch 4814: loss 0.015228\n",
      "batch 4815: loss 0.007976\n",
      "batch 4816: loss 0.001463\n",
      "batch 4817: loss 0.032095\n",
      "batch 4818: loss 0.007463\n",
      "batch 4819: loss 0.007220\n",
      "batch 4820: loss 0.019458\n",
      "batch 4821: loss 0.021478\n",
      "batch 4822: loss 0.001203\n",
      "batch 4823: loss 0.019510\n",
      "batch 4824: loss 0.012537\n",
      "batch 4825: loss 0.128074\n",
      "batch 4826: loss 0.023876\n",
      "batch 4827: loss 0.034844\n",
      "batch 4828: loss 0.002461\n",
      "batch 4829: loss 0.068358\n",
      "batch 4830: loss 0.009686\n",
      "batch 4831: loss 0.002080\n",
      "batch 4832: loss 0.006833\n",
      "batch 4833: loss 0.005816\n",
      "batch 4834: loss 0.062906\n",
      "batch 4835: loss 0.003701\n",
      "batch 4836: loss 0.005446\n",
      "batch 4837: loss 0.029030\n",
      "batch 4838: loss 0.005352\n",
      "batch 4839: loss 0.061127\n",
      "batch 4840: loss 0.045271\n",
      "batch 4841: loss 0.052734\n",
      "batch 4842: loss 0.011850\n",
      "batch 4843: loss 0.017818\n",
      "batch 4844: loss 0.091351\n",
      "batch 4845: loss 0.020042\n",
      "batch 4846: loss 0.001198\n",
      "batch 4847: loss 0.050887\n",
      "batch 4848: loss 0.002239\n",
      "batch 4849: loss 0.018287\n",
      "batch 4850: loss 0.008478\n",
      "batch 4851: loss 0.021956\n",
      "batch 4852: loss 0.025015\n",
      "batch 4853: loss 0.001607\n",
      "batch 4854: loss 0.021605\n",
      "batch 4855: loss 0.008549\n",
      "batch 4856: loss 0.063222\n",
      "batch 4857: loss 0.003375\n",
      "batch 4858: loss 0.007048\n",
      "batch 4859: loss 0.011281\n",
      "batch 4860: loss 0.038547\n",
      "batch 4861: loss 0.034367\n",
      "batch 4862: loss 0.045856\n",
      "batch 4863: loss 0.026500\n",
      "batch 4864: loss 0.014436\n",
      "batch 4865: loss 0.007734\n",
      "batch 4866: loss 0.006972\n",
      "batch 4867: loss 0.007711\n",
      "batch 4868: loss 0.006284\n",
      "batch 4869: loss 0.010216\n",
      "batch 4870: loss 0.098019\n",
      "batch 4871: loss 0.031038\n",
      "batch 4872: loss 0.020352\n",
      "batch 4873: loss 0.128768\n",
      "batch 4874: loss 0.002170\n",
      "batch 4875: loss 0.056607\n",
      "batch 4876: loss 0.026195\n",
      "batch 4877: loss 0.060832\n",
      "batch 4878: loss 0.050646\n",
      "batch 4879: loss 0.070578\n",
      "batch 4880: loss 0.033187\n",
      "batch 4881: loss 0.011471\n",
      "batch 4882: loss 0.031913\n",
      "batch 4883: loss 0.040794\n",
      "batch 4884: loss 0.026844\n",
      "batch 4885: loss 0.012326\n",
      "batch 4886: loss 0.049348\n",
      "batch 4887: loss 0.024022\n",
      "batch 4888: loss 0.013291\n",
      "batch 4889: loss 0.003337\n",
      "batch 4890: loss 0.153572\n",
      "batch 4891: loss 0.018039\n",
      "batch 4892: loss 0.007841\n",
      "batch 4893: loss 0.046286\n",
      "batch 4894: loss 0.011901\n",
      "batch 4895: loss 0.025959\n",
      "batch 4896: loss 0.145952\n",
      "batch 4897: loss 0.013437\n",
      "batch 4898: loss 0.065529\n",
      "batch 4899: loss 0.003227\n",
      "batch 4900: loss 0.049826\n",
      "batch 4901: loss 0.023855\n",
      "batch 4902: loss 0.009621\n",
      "batch 4903: loss 0.080219\n",
      "batch 4904: loss 0.001571\n",
      "batch 4905: loss 0.011755\n",
      "batch 4906: loss 0.018977\n",
      "batch 4907: loss 0.009684\n",
      "batch 4908: loss 0.009921\n",
      "batch 4909: loss 0.026417\n",
      "batch 4910: loss 0.010834\n",
      "batch 4911: loss 0.037767\n",
      "batch 4912: loss 0.003474\n",
      "batch 4913: loss 0.014946\n",
      "batch 4914: loss 0.040725\n",
      "batch 4915: loss 0.014528\n",
      "batch 4916: loss 0.003307\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 4917: loss 0.056275\n",
      "batch 4918: loss 0.140094\n",
      "batch 4919: loss 0.014832\n",
      "batch 4920: loss 0.099335\n",
      "batch 4921: loss 0.004263\n",
      "batch 4922: loss 0.041694\n",
      "batch 4923: loss 0.028060\n",
      "batch 4924: loss 0.175260\n",
      "batch 4925: loss 0.027695\n",
      "batch 4926: loss 0.056697\n",
      "batch 4927: loss 0.042701\n",
      "batch 4928: loss 0.011173\n",
      "batch 4929: loss 0.008568\n",
      "batch 4930: loss 0.003489\n",
      "batch 4931: loss 0.042401\n",
      "batch 4932: loss 0.005748\n",
      "batch 4933: loss 0.021833\n",
      "batch 4934: loss 0.001731\n",
      "batch 4935: loss 0.004522\n",
      "batch 4936: loss 0.032046\n",
      "batch 4937: loss 0.009649\n",
      "batch 4938: loss 0.008478\n",
      "batch 4939: loss 0.139362\n",
      "batch 4940: loss 0.046747\n",
      "batch 4941: loss 0.019312\n",
      "batch 4942: loss 0.002374\n",
      "batch 4943: loss 0.007552\n",
      "batch 4944: loss 0.006226\n",
      "batch 4945: loss 0.053583\n",
      "batch 4946: loss 0.006304\n",
      "batch 4947: loss 0.014438\n",
      "batch 4948: loss 0.072245\n",
      "batch 4949: loss 0.011468\n",
      "batch 4950: loss 0.001975\n",
      "batch 4951: loss 0.072208\n",
      "batch 4952: loss 0.050529\n",
      "batch 4953: loss 0.021710\n",
      "batch 4954: loss 0.042880\n",
      "batch 4955: loss 0.006657\n",
      "batch 4956: loss 0.015505\n",
      "batch 4957: loss 0.023042\n",
      "batch 4958: loss 0.022917\n",
      "batch 4959: loss 0.018909\n",
      "batch 4960: loss 0.086522\n",
      "batch 4961: loss 0.135728\n",
      "batch 4962: loss 0.025923\n",
      "batch 4963: loss 0.016379\n",
      "batch 4964: loss 0.011687\n",
      "batch 4965: loss 0.021180\n",
      "batch 4966: loss 0.021457\n",
      "batch 4967: loss 0.102774\n",
      "batch 4968: loss 0.008396\n",
      "batch 4969: loss 0.010705\n",
      "batch 4970: loss 0.018970\n",
      "batch 4971: loss 0.007233\n",
      "batch 4972: loss 0.065025\n",
      "batch 4973: loss 0.003351\n",
      "batch 4974: loss 0.018314\n",
      "batch 4975: loss 0.016535\n",
      "batch 4976: loss 0.027060\n",
      "batch 4977: loss 0.009253\n",
      "batch 4978: loss 0.006868\n",
      "batch 4979: loss 0.018249\n",
      "batch 4980: loss 0.003788\n",
      "batch 4981: loss 0.026892\n",
      "batch 4982: loss 0.005747\n",
      "batch 4983: loss 0.009810\n",
      "batch 4984: loss 0.045158\n",
      "batch 4985: loss 0.012091\n",
      "batch 4986: loss 0.013368\n",
      "batch 4987: loss 0.025136\n",
      "batch 4988: loss 0.059505\n",
      "batch 4989: loss 0.009766\n",
      "batch 4990: loss 0.013644\n",
      "batch 4991: loss 0.018098\n",
      "batch 4992: loss 0.040613\n",
      "batch 4993: loss 0.049461\n",
      "batch 4994: loss 0.008231\n",
      "batch 4995: loss 0.007411\n",
      "batch 4996: loss 0.019519\n",
      "batch 4997: loss 0.011558\n",
      "batch 4998: loss 0.007769\n",
      "batch 4999: loss 0.029435\n",
      "batch 5000: loss 0.018310\n",
      "batch 5001: loss 0.049550\n",
      "batch 5002: loss 0.083139\n",
      "batch 5003: loss 0.059520\n",
      "batch 5004: loss 0.002930\n",
      "batch 5005: loss 0.008470\n",
      "batch 5006: loss 0.009729\n",
      "batch 5007: loss 0.035736\n",
      "batch 5008: loss 0.050145\n",
      "batch 5009: loss 0.005895\n",
      "batch 5010: loss 0.017867\n",
      "batch 5011: loss 0.100783\n",
      "batch 5012: loss 0.014248\n",
      "batch 5013: loss 0.024497\n",
      "batch 5014: loss 0.007668\n",
      "batch 5015: loss 0.004162\n",
      "batch 5016: loss 0.005024\n",
      "batch 5017: loss 0.066055\n",
      "batch 5018: loss 0.036098\n",
      "batch 5019: loss 0.045357\n",
      "batch 5020: loss 0.004120\n",
      "batch 5021: loss 0.049111\n",
      "batch 5022: loss 0.003094\n",
      "batch 5023: loss 0.016031\n",
      "batch 5024: loss 0.018609\n",
      "batch 5025: loss 0.086270\n",
      "batch 5026: loss 0.001439\n",
      "batch 5027: loss 0.021564\n",
      "batch 5028: loss 0.153338\n",
      "batch 5029: loss 0.014733\n",
      "batch 5030: loss 0.023998\n",
      "batch 5031: loss 0.035170\n",
      "batch 5032: loss 0.017790\n",
      "batch 5033: loss 0.046810\n",
      "batch 5034: loss 0.006957\n",
      "batch 5035: loss 0.105072\n",
      "batch 5036: loss 0.003565\n",
      "batch 5037: loss 0.039583\n",
      "batch 5038: loss 0.019370\n",
      "batch 5039: loss 0.016447\n",
      "batch 5040: loss 0.027005\n",
      "batch 5041: loss 0.005449\n",
      "batch 5042: loss 0.003390\n",
      "batch 5043: loss 0.019418\n",
      "batch 5044: loss 0.020816\n",
      "batch 5045: loss 0.001808\n",
      "batch 5046: loss 0.005282\n",
      "batch 5047: loss 0.011913\n",
      "batch 5048: loss 0.003867\n",
      "batch 5049: loss 0.031735\n",
      "batch 5050: loss 0.015707\n",
      "batch 5051: loss 0.008560\n",
      "batch 5052: loss 0.002374\n",
      "batch 5053: loss 0.025030\n",
      "batch 5054: loss 0.011586\n",
      "batch 5055: loss 0.012701\n",
      "batch 5056: loss 0.033206\n",
      "batch 5057: loss 0.007680\n",
      "batch 5058: loss 0.020659\n",
      "batch 5059: loss 0.047342\n",
      "batch 5060: loss 0.005383\n",
      "batch 5061: loss 0.001044\n",
      "batch 5062: loss 0.003719\n",
      "batch 5063: loss 0.020371\n",
      "batch 5064: loss 0.010184\n",
      "batch 5065: loss 0.001611\n",
      "batch 5066: loss 0.006376\n",
      "batch 5067: loss 0.003636\n",
      "batch 5068: loss 0.023769\n",
      "batch 5069: loss 0.019057\n",
      "batch 5070: loss 0.006357\n",
      "batch 5071: loss 0.014822\n",
      "batch 5072: loss 0.023209\n",
      "batch 5073: loss 0.007873\n",
      "batch 5074: loss 0.006522\n",
      "batch 5075: loss 0.054672\n",
      "batch 5076: loss 0.030597\n",
      "batch 5077: loss 0.002342\n",
      "batch 5078: loss 0.011042\n",
      "batch 5079: loss 0.040096\n",
      "batch 5080: loss 0.004189\n",
      "batch 5081: loss 0.002366\n",
      "batch 5082: loss 0.002107\n",
      "batch 5083: loss 0.004455\n",
      "batch 5084: loss 0.022338\n",
      "batch 5085: loss 0.013100\n",
      "batch 5086: loss 0.004764\n",
      "batch 5087: loss 0.005535\n",
      "batch 5088: loss 0.003451\n",
      "batch 5089: loss 0.043102\n",
      "batch 5090: loss 0.030223\n",
      "batch 5091: loss 0.010719\n",
      "batch 5092: loss 0.003687\n",
      "batch 5093: loss 0.013989\n",
      "batch 5094: loss 0.009094\n",
      "batch 5095: loss 0.018552\n",
      "batch 5096: loss 0.017408\n",
      "batch 5097: loss 0.133340\n",
      "batch 5098: loss 0.020011\n",
      "batch 5099: loss 0.004655\n",
      "batch 5100: loss 0.022964\n",
      "batch 5101: loss 0.048830\n",
      "batch 5102: loss 0.011016\n",
      "batch 5103: loss 0.018531\n",
      "batch 5104: loss 0.013616\n",
      "batch 5105: loss 0.011179\n",
      "batch 5106: loss 0.009108\n",
      "batch 5107: loss 0.007148\n",
      "batch 5108: loss 0.005641\n",
      "batch 5109: loss 0.007496\n",
      "batch 5110: loss 0.022857\n",
      "batch 5111: loss 0.020757\n",
      "batch 5112: loss 0.013711\n",
      "batch 5113: loss 0.001894\n",
      "batch 5114: loss 0.004298\n",
      "batch 5115: loss 0.014319\n",
      "batch 5116: loss 0.002481\n",
      "batch 5117: loss 0.116200\n",
      "batch 5118: loss 0.010765\n",
      "batch 5119: loss 0.012811\n",
      "batch 5120: loss 0.009623\n",
      "batch 5121: loss 0.031889\n",
      "batch 5122: loss 0.035355\n",
      "batch 5123: loss 0.049490\n",
      "batch 5124: loss 0.008213\n",
      "batch 5125: loss 0.011154\n",
      "batch 5126: loss 0.012458\n",
      "batch 5127: loss 0.013512\n",
      "batch 5128: loss 0.011529\n",
      "batch 5129: loss 0.015571\n",
      "batch 5130: loss 0.112205\n",
      "batch 5131: loss 0.059546\n",
      "batch 5132: loss 0.017630\n",
      "batch 5133: loss 0.012118\n",
      "batch 5134: loss 0.056842\n",
      "batch 5135: loss 0.017551\n",
      "batch 5136: loss 0.008840\n",
      "batch 5137: loss 0.008912\n",
      "batch 5138: loss 0.020229\n",
      "batch 5139: loss 0.062577\n",
      "batch 5140: loss 0.022661\n",
      "batch 5141: loss 0.023333\n",
      "batch 5142: loss 0.003807\n",
      "batch 5143: loss 0.013019\n",
      "batch 5144: loss 0.009128\n",
      "batch 5145: loss 0.029923\n",
      "batch 5146: loss 0.002908\n",
      "batch 5147: loss 0.006753\n",
      "batch 5148: loss 0.006884\n",
      "batch 5149: loss 0.008253\n",
      "batch 5150: loss 0.013162\n",
      "batch 5151: loss 0.008679\n",
      "batch 5152: loss 0.034154\n",
      "batch 5153: loss 0.015478\n",
      "batch 5154: loss 0.008236\n",
      "batch 5155: loss 0.048657\n",
      "batch 5156: loss 0.003566\n",
      "batch 5157: loss 0.034933\n",
      "batch 5158: loss 0.132837\n",
      "batch 5159: loss 0.035596\n",
      "batch 5160: loss 0.003380\n",
      "batch 5161: loss 0.005615\n",
      "batch 5162: loss 0.008092\n",
      "batch 5163: loss 0.004199\n",
      "batch 5164: loss 0.028612\n",
      "batch 5165: loss 0.004819\n",
      "batch 5166: loss 0.081508\n",
      "batch 5167: loss 0.026570\n",
      "batch 5168: loss 0.004755\n",
      "batch 5169: loss 0.150702\n",
      "batch 5170: loss 0.032612\n",
      "batch 5171: loss 0.006710\n",
      "batch 5172: loss 0.054179\n",
      "batch 5173: loss 0.016449\n",
      "batch 5174: loss 0.005022\n",
      "batch 5175: loss 0.009835\n",
      "batch 5176: loss 0.001630\n",
      "batch 5177: loss 0.015070\n",
      "batch 5178: loss 0.026105\n",
      "batch 5179: loss 0.015380\n",
      "batch 5180: loss 0.029396\n",
      "batch 5181: loss 0.024075\n",
      "batch 5182: loss 0.030025\n",
      "batch 5183: loss 0.019967\n",
      "batch 5184: loss 0.089463\n",
      "batch 5185: loss 0.027322\n",
      "batch 5186: loss 0.005195\n",
      "batch 5187: loss 0.003176\n",
      "batch 5188: loss 0.010388\n",
      "batch 5189: loss 0.007850\n",
      "batch 5190: loss 0.008409\n",
      "batch 5191: loss 0.020638\n",
      "batch 5192: loss 0.056971\n",
      "batch 5193: loss 0.163682\n",
      "batch 5194: loss 0.002809\n",
      "batch 5195: loss 0.001317\n",
      "batch 5196: loss 0.017888\n",
      "batch 5197: loss 0.005077\n",
      "batch 5198: loss 0.004082\n",
      "batch 5199: loss 0.011107\n",
      "batch 5200: loss 0.034278\n",
      "batch 5201: loss 0.001880\n",
      "batch 5202: loss 0.002722\n",
      "batch 5203: loss 0.016126\n",
      "batch 5204: loss 0.074768\n",
      "batch 5205: loss 0.008440\n",
      "batch 5206: loss 0.034568\n",
      "batch 5207: loss 0.005604\n",
      "batch 5208: loss 0.030674\n",
      "batch 5209: loss 0.059785\n",
      "batch 5210: loss 0.025675\n",
      "batch 5211: loss 0.005294\n",
      "batch 5212: loss 0.024579\n",
      "batch 5213: loss 0.004693\n",
      "batch 5214: loss 0.003842\n",
      "batch 5215: loss 0.134660\n",
      "batch 5216: loss 0.050810\n",
      "batch 5217: loss 0.035471\n",
      "batch 5218: loss 0.023128\n",
      "batch 5219: loss 0.010049\n",
      "batch 5220: loss 0.021341\n",
      "batch 5221: loss 0.044535\n",
      "batch 5222: loss 0.007694\n",
      "batch 5223: loss 0.018419\n",
      "batch 5224: loss 0.033089\n",
      "batch 5225: loss 0.089330\n",
      "batch 5226: loss 0.017136\n",
      "batch 5227: loss 0.008282\n",
      "batch 5228: loss 0.009620\n",
      "batch 5229: loss 0.019890\n",
      "batch 5230: loss 0.075717\n",
      "batch 5231: loss 0.007034\n",
      "batch 5232: loss 0.026278\n",
      "batch 5233: loss 0.027837\n",
      "batch 5234: loss 0.081362\n",
      "batch 5235: loss 0.011846\n",
      "batch 5236: loss 0.002751\n",
      "batch 5237: loss 0.019768\n",
      "batch 5238: loss 0.052449\n",
      "batch 5239: loss 0.003912\n",
      "batch 5240: loss 0.034964\n",
      "batch 5241: loss 0.069696\n",
      "batch 5242: loss 0.006093\n",
      "batch 5243: loss 0.012603\n",
      "batch 5244: loss 0.011337\n",
      "batch 5245: loss 0.015680\n",
      "batch 5246: loss 0.005737\n",
      "batch 5247: loss 0.039376\n",
      "batch 5248: loss 0.030780\n",
      "batch 5249: loss 0.003278\n",
      "batch 5250: loss 0.006062\n",
      "batch 5251: loss 0.005589\n",
      "batch 5252: loss 0.012864\n",
      "batch 5253: loss 0.124650\n",
      "batch 5254: loss 0.012058\n",
      "batch 5255: loss 0.014625\n",
      "batch 5256: loss 0.004322\n",
      "batch 5257: loss 0.021388\n",
      "batch 5258: loss 0.001443\n",
      "batch 5259: loss 0.010097\n",
      "batch 5260: loss 0.017014\n",
      "batch 5261: loss 0.022403\n",
      "batch 5262: loss 0.007077\n",
      "batch 5263: loss 0.016271\n",
      "batch 5264: loss 0.069729\n",
      "batch 5265: loss 0.031852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5266: loss 0.010639\n",
      "batch 5267: loss 0.005159\n",
      "batch 5268: loss 0.011611\n",
      "batch 5269: loss 0.034774\n",
      "batch 5270: loss 0.008198\n",
      "batch 5271: loss 0.004184\n",
      "batch 5272: loss 0.009277\n",
      "batch 5273: loss 0.012570\n",
      "batch 5274: loss 0.036237\n",
      "batch 5275: loss 0.040733\n",
      "batch 5276: loss 0.026381\n",
      "batch 5277: loss 0.032353\n",
      "batch 5278: loss 0.063596\n",
      "batch 5279: loss 0.007703\n",
      "batch 5280: loss 0.052270\n",
      "batch 5281: loss 0.082478\n",
      "batch 5282: loss 0.019913\n",
      "batch 5283: loss 0.015543\n",
      "batch 5284: loss 0.052177\n",
      "batch 5285: loss 0.005066\n",
      "batch 5286: loss 0.004138\n",
      "batch 5287: loss 0.034828\n",
      "batch 5288: loss 0.072946\n",
      "batch 5289: loss 0.007886\n",
      "batch 5290: loss 0.013298\n",
      "batch 5291: loss 0.023339\n",
      "batch 5292: loss 0.026843\n",
      "batch 5293: loss 0.023509\n",
      "batch 5294: loss 0.069019\n",
      "batch 5295: loss 0.017305\n",
      "batch 5296: loss 0.042788\n",
      "batch 5297: loss 0.055065\n",
      "batch 5298: loss 0.007446\n",
      "batch 5299: loss 0.020590\n",
      "batch 5300: loss 0.004678\n",
      "batch 5301: loss 0.009577\n",
      "batch 5302: loss 0.032395\n",
      "batch 5303: loss 0.021803\n",
      "batch 5304: loss 0.003919\n",
      "batch 5305: loss 0.018436\n",
      "batch 5306: loss 0.035987\n",
      "batch 5307: loss 0.039741\n",
      "batch 5308: loss 0.005107\n",
      "batch 5309: loss 0.005785\n",
      "batch 5310: loss 0.034644\n",
      "batch 5311: loss 0.060801\n",
      "batch 5312: loss 0.012295\n",
      "batch 5313: loss 0.011746\n",
      "batch 5314: loss 0.041557\n",
      "batch 5315: loss 0.175162\n",
      "batch 5316: loss 0.006282\n",
      "batch 5317: loss 0.011955\n",
      "batch 5318: loss 0.071906\n",
      "batch 5319: loss 0.009092\n",
      "batch 5320: loss 0.004595\n",
      "batch 5321: loss 0.109727\n",
      "batch 5322: loss 0.012584\n",
      "batch 5323: loss 0.011107\n",
      "batch 5324: loss 0.003119\n",
      "batch 5325: loss 0.007182\n",
      "batch 5326: loss 0.002749\n",
      "batch 5327: loss 0.057238\n",
      "batch 5328: loss 0.013472\n",
      "batch 5329: loss 0.019717\n",
      "batch 5330: loss 0.003718\n",
      "batch 5331: loss 0.041121\n",
      "batch 5332: loss 0.016397\n",
      "batch 5333: loss 0.021609\n",
      "batch 5334: loss 0.044585\n",
      "batch 5335: loss 0.002746\n",
      "batch 5336: loss 0.025782\n",
      "batch 5337: loss 0.016968\n",
      "batch 5338: loss 0.011192\n",
      "batch 5339: loss 0.049083\n",
      "batch 5340: loss 0.017130\n",
      "batch 5341: loss 0.001256\n",
      "batch 5342: loss 0.007447\n",
      "batch 5343: loss 0.007080\n",
      "batch 5344: loss 0.003683\n",
      "batch 5345: loss 0.010240\n",
      "batch 5346: loss 0.144518\n",
      "batch 5347: loss 0.002043\n",
      "batch 5348: loss 0.008563\n",
      "batch 5349: loss 0.007585\n",
      "batch 5350: loss 0.005014\n",
      "batch 5351: loss 0.020041\n",
      "batch 5352: loss 0.003623\n",
      "batch 5353: loss 0.003889\n",
      "batch 5354: loss 0.003096\n",
      "batch 5355: loss 0.037107\n",
      "batch 5356: loss 0.006625\n",
      "batch 5357: loss 0.007775\n",
      "batch 5358: loss 0.019809\n",
      "batch 5359: loss 0.016016\n",
      "batch 5360: loss 0.018380\n",
      "batch 5361: loss 0.033796\n",
      "batch 5362: loss 0.006943\n",
      "batch 5363: loss 0.052479\n",
      "batch 5364: loss 0.005823\n",
      "batch 5365: loss 0.099018\n",
      "batch 5366: loss 0.004531\n",
      "batch 5367: loss 0.038207\n",
      "batch 5368: loss 0.016314\n",
      "batch 5369: loss 0.037921\n",
      "batch 5370: loss 0.030414\n",
      "batch 5371: loss 0.013771\n",
      "batch 5372: loss 0.003112\n",
      "batch 5373: loss 0.063806\n",
      "batch 5374: loss 0.024188\n",
      "batch 5375: loss 0.005735\n",
      "batch 5376: loss 0.048703\n",
      "batch 5377: loss 0.008676\n",
      "batch 5378: loss 0.005246\n",
      "batch 5379: loss 0.005064\n",
      "batch 5380: loss 0.010354\n",
      "batch 5381: loss 0.008814\n",
      "batch 5382: loss 0.008123\n",
      "batch 5383: loss 0.005342\n",
      "batch 5384: loss 0.006159\n",
      "batch 5385: loss 0.020063\n",
      "batch 5386: loss 0.009261\n",
      "batch 5387: loss 0.004041\n",
      "batch 5388: loss 0.018876\n",
      "batch 5389: loss 0.027817\n",
      "batch 5390: loss 0.012541\n",
      "batch 5391: loss 0.026994\n",
      "batch 5392: loss 0.005809\n",
      "batch 5393: loss 0.059963\n",
      "batch 5394: loss 0.004855\n",
      "batch 5395: loss 0.063284\n",
      "batch 5396: loss 0.082544\n",
      "batch 5397: loss 0.005874\n",
      "batch 5398: loss 0.006902\n",
      "batch 5399: loss 0.010338\n",
      "batch 5400: loss 0.045252\n",
      "batch 5401: loss 0.012542\n",
      "batch 5402: loss 0.010884\n",
      "batch 5403: loss 0.022736\n",
      "batch 5404: loss 0.003146\n",
      "batch 5405: loss 0.030996\n",
      "batch 5406: loss 0.002582\n",
      "batch 5407: loss 0.010521\n",
      "batch 5408: loss 0.015216\n",
      "batch 5409: loss 0.008549\n",
      "batch 5410: loss 0.032834\n",
      "batch 5411: loss 0.182440\n",
      "batch 5412: loss 0.007207\n",
      "batch 5413: loss 0.082745\n",
      "batch 5414: loss 0.013370\n",
      "batch 5415: loss 0.032913\n",
      "batch 5416: loss 0.007704\n",
      "batch 5417: loss 0.003962\n",
      "batch 5418: loss 0.002769\n",
      "batch 5419: loss 0.016271\n",
      "batch 5420: loss 0.004592\n",
      "batch 5421: loss 0.035584\n",
      "batch 5422: loss 0.070914\n",
      "batch 5423: loss 0.020931\n",
      "batch 5424: loss 0.024781\n",
      "batch 5425: loss 0.021766\n",
      "batch 5426: loss 0.003124\n",
      "batch 5427: loss 0.005604\n",
      "batch 5428: loss 0.004782\n",
      "batch 5429: loss 0.001810\n",
      "batch 5430: loss 0.033285\n",
      "batch 5431: loss 0.027450\n",
      "batch 5432: loss 0.011167\n",
      "batch 5433: loss 0.083572\n",
      "batch 5434: loss 0.030147\n",
      "batch 5435: loss 0.028004\n",
      "batch 5436: loss 0.042802\n",
      "batch 5437: loss 0.110993\n",
      "batch 5438: loss 0.002074\n",
      "batch 5439: loss 0.020704\n",
      "batch 5440: loss 0.004908\n",
      "batch 5441: loss 0.011216\n",
      "batch 5442: loss 0.045941\n",
      "batch 5443: loss 0.009649\n",
      "batch 5444: loss 0.024610\n",
      "batch 5445: loss 0.034628\n",
      "batch 5446: loss 0.002940\n",
      "batch 5447: loss 0.025035\n",
      "batch 5448: loss 0.017691\n",
      "batch 5449: loss 0.021094\n",
      "batch 5450: loss 0.039774\n",
      "batch 5451: loss 0.011111\n",
      "batch 5452: loss 0.004283\n",
      "batch 5453: loss 0.027527\n",
      "batch 5454: loss 0.036132\n",
      "batch 5455: loss 0.019639\n",
      "batch 5456: loss 0.004026\n",
      "batch 5457: loss 0.035258\n",
      "batch 5458: loss 0.031281\n",
      "batch 5459: loss 0.002713\n",
      "batch 5460: loss 0.014117\n",
      "batch 5461: loss 0.027613\n",
      "batch 5462: loss 0.012402\n",
      "batch 5463: loss 0.009874\n",
      "batch 5464: loss 0.145840\n",
      "batch 5465: loss 0.002643\n",
      "batch 5466: loss 0.029956\n",
      "batch 5467: loss 0.068762\n",
      "batch 5468: loss 0.004800\n",
      "batch 5469: loss 0.038313\n",
      "batch 5470: loss 0.019696\n",
      "batch 5471: loss 0.056937\n",
      "batch 5472: loss 0.016907\n",
      "batch 5473: loss 0.008937\n",
      "batch 5474: loss 0.023799\n",
      "batch 5475: loss 0.022441\n",
      "batch 5476: loss 0.018829\n",
      "batch 5477: loss 0.007681\n",
      "batch 5478: loss 0.006251\n",
      "batch 5479: loss 0.025541\n",
      "batch 5480: loss 0.006182\n",
      "batch 5481: loss 0.010403\n",
      "batch 5482: loss 0.038061\n",
      "batch 5483: loss 0.145115\n",
      "batch 5484: loss 0.035405\n",
      "batch 5485: loss 0.002359\n",
      "batch 5486: loss 0.018867\n",
      "batch 5487: loss 0.016192\n",
      "batch 5488: loss 0.020361\n",
      "batch 5489: loss 0.037376\n",
      "batch 5490: loss 0.024273\n",
      "batch 5491: loss 0.009667\n",
      "batch 5492: loss 0.027362\n",
      "batch 5493: loss 0.002557\n",
      "batch 5494: loss 0.030204\n",
      "batch 5495: loss 0.008879\n",
      "batch 5496: loss 0.014738\n",
      "batch 5497: loss 0.082498\n",
      "batch 5498: loss 0.008128\n",
      "batch 5499: loss 0.039713\n",
      "batch 5500: loss 0.008078\n",
      "batch 5501: loss 0.007506\n",
      "batch 5502: loss 0.005681\n",
      "batch 5503: loss 0.002734\n",
      "batch 5504: loss 0.005162\n",
      "batch 5505: loss 0.021728\n",
      "batch 5506: loss 0.009494\n",
      "batch 5507: loss 0.007560\n",
      "batch 5508: loss 0.013904\n",
      "batch 5509: loss 0.004519\n",
      "batch 5510: loss 0.003011\n",
      "batch 5511: loss 0.018500\n",
      "batch 5512: loss 0.015162\n",
      "batch 5513: loss 0.030264\n",
      "batch 5514: loss 0.013515\n",
      "batch 5515: loss 0.006216\n",
      "batch 5516: loss 0.014307\n",
      "batch 5517: loss 0.060422\n",
      "batch 5518: loss 0.002380\n",
      "batch 5519: loss 0.001940\n",
      "batch 5520: loss 0.007113\n",
      "batch 5521: loss 0.022720\n",
      "batch 5522: loss 0.029454\n",
      "batch 5523: loss 0.044259\n",
      "batch 5524: loss 0.007457\n",
      "batch 5525: loss 0.010552\n",
      "batch 5526: loss 0.004605\n",
      "batch 5527: loss 0.009485\n",
      "batch 5528: loss 0.005418\n",
      "batch 5529: loss 0.014597\n",
      "batch 5530: loss 0.006899\n",
      "batch 5531: loss 0.027242\n",
      "batch 5532: loss 0.010612\n",
      "batch 5533: loss 0.008954\n",
      "batch 5534: loss 0.024912\n",
      "batch 5535: loss 0.115322\n",
      "batch 5536: loss 0.016618\n",
      "batch 5537: loss 0.032059\n",
      "batch 5538: loss 0.007086\n",
      "batch 5539: loss 0.006521\n",
      "batch 5540: loss 0.002362\n",
      "batch 5541: loss 0.014188\n",
      "batch 5542: loss 0.011402\n",
      "batch 5543: loss 0.016268\n",
      "batch 5544: loss 0.016626\n",
      "batch 5545: loss 0.038821\n",
      "batch 5546: loss 0.008177\n",
      "batch 5547: loss 0.004964\n",
      "batch 5548: loss 0.009594\n",
      "batch 5549: loss 0.002851\n",
      "batch 5550: loss 0.002928\n",
      "batch 5551: loss 0.006045\n",
      "batch 5552: loss 0.008816\n",
      "batch 5553: loss 0.009357\n",
      "batch 5554: loss 0.010459\n",
      "batch 5555: loss 0.032980\n",
      "batch 5556: loss 0.027292\n",
      "batch 5557: loss 0.105017\n",
      "batch 5558: loss 0.003080\n",
      "batch 5559: loss 0.007125\n",
      "batch 5560: loss 0.016666\n",
      "batch 5561: loss 0.018093\n",
      "batch 5562: loss 0.011715\n",
      "batch 5563: loss 0.116698\n",
      "batch 5564: loss 0.052387\n",
      "batch 5565: loss 0.015906\n",
      "batch 5566: loss 0.028698\n",
      "batch 5567: loss 0.040713\n",
      "batch 5568: loss 0.009812\n",
      "batch 5569: loss 0.044516\n",
      "batch 5570: loss 0.002351\n",
      "batch 5571: loss 0.066709\n",
      "batch 5572: loss 0.101974\n",
      "batch 5573: loss 0.004398\n",
      "batch 5574: loss 0.004809\n",
      "batch 5575: loss 0.010952\n",
      "batch 5576: loss 0.004877\n",
      "batch 5577: loss 0.038015\n",
      "batch 5578: loss 0.006263\n",
      "batch 5579: loss 0.005636\n",
      "batch 5580: loss 0.011849\n",
      "batch 5581: loss 0.045775\n",
      "batch 5582: loss 0.131418\n",
      "batch 5583: loss 0.002576\n",
      "batch 5584: loss 0.029706\n",
      "batch 5585: loss 0.013618\n",
      "batch 5586: loss 0.004640\n",
      "batch 5587: loss 0.002923\n",
      "batch 5588: loss 0.024168\n",
      "batch 5589: loss 0.008156\n",
      "batch 5590: loss 0.018895\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5591: loss 0.004674\n",
      "batch 5592: loss 0.003827\n",
      "batch 5593: loss 0.021927\n",
      "batch 5594: loss 0.002634\n",
      "batch 5595: loss 0.007584\n",
      "batch 5596: loss 0.012809\n",
      "batch 5597: loss 0.004530\n",
      "batch 5598: loss 0.002025\n",
      "batch 5599: loss 0.004796\n",
      "batch 5600: loss 0.062279\n",
      "batch 5601: loss 0.082775\n",
      "batch 5602: loss 0.025398\n",
      "batch 5603: loss 0.025844\n",
      "batch 5604: loss 0.004766\n",
      "batch 5605: loss 0.019091\n",
      "batch 5606: loss 0.048089\n",
      "batch 5607: loss 0.015933\n",
      "batch 5608: loss 0.004664\n",
      "batch 5609: loss 0.014718\n",
      "batch 5610: loss 0.017375\n",
      "batch 5611: loss 0.003807\n",
      "batch 5612: loss 0.005718\n",
      "batch 5613: loss 0.011243\n",
      "batch 5614: loss 0.013858\n",
      "batch 5615: loss 0.027359\n",
      "batch 5616: loss 0.102820\n",
      "batch 5617: loss 0.044013\n",
      "batch 5618: loss 0.001655\n",
      "batch 5619: loss 0.014798\n",
      "batch 5620: loss 0.002931\n",
      "batch 5621: loss 0.017120\n",
      "batch 5622: loss 0.065747\n",
      "batch 5623: loss 0.039446\n",
      "batch 5624: loss 0.003116\n",
      "batch 5625: loss 0.006188\n",
      "batch 5626: loss 0.014805\n",
      "batch 5627: loss 0.027907\n",
      "batch 5628: loss 0.094886\n",
      "batch 5629: loss 0.018980\n",
      "batch 5630: loss 0.044578\n",
      "batch 5631: loss 0.056634\n",
      "batch 5632: loss 0.013089\n",
      "batch 5633: loss 0.013483\n",
      "batch 5634: loss 0.016710\n",
      "batch 5635: loss 0.009856\n",
      "batch 5636: loss 0.014153\n",
      "batch 5637: loss 0.018839\n",
      "batch 5638: loss 0.016634\n",
      "batch 5639: loss 0.002921\n",
      "batch 5640: loss 0.020990\n",
      "batch 5641: loss 0.012066\n",
      "batch 5642: loss 0.005756\n",
      "batch 5643: loss 0.009043\n",
      "batch 5644: loss 0.030871\n",
      "batch 5645: loss 0.011173\n",
      "batch 5646: loss 0.017388\n",
      "batch 5647: loss 0.061056\n",
      "batch 5648: loss 0.036326\n",
      "batch 5649: loss 0.005279\n",
      "batch 5650: loss 0.021609\n",
      "batch 5651: loss 0.049813\n",
      "batch 5652: loss 0.042062\n",
      "batch 5653: loss 0.018396\n",
      "batch 5654: loss 0.005840\n",
      "batch 5655: loss 0.003466\n",
      "batch 5656: loss 0.054404\n",
      "batch 5657: loss 0.004803\n",
      "batch 5658: loss 0.026524\n",
      "batch 5659: loss 0.017243\n",
      "batch 5660: loss 0.003514\n",
      "batch 5661: loss 0.002764\n",
      "batch 5662: loss 0.005465\n",
      "batch 5663: loss 0.012730\n",
      "batch 5664: loss 0.052460\n",
      "batch 5665: loss 0.032400\n",
      "batch 5666: loss 0.002447\n",
      "batch 5667: loss 0.034041\n",
      "batch 5668: loss 0.013404\n",
      "batch 5669: loss 0.317745\n",
      "batch 5670: loss 0.015878\n",
      "batch 5671: loss 0.081231\n",
      "batch 5672: loss 0.017001\n",
      "batch 5673: loss 0.006564\n",
      "batch 5674: loss 0.021350\n",
      "batch 5675: loss 0.017919\n",
      "batch 5676: loss 0.036722\n",
      "batch 5677: loss 0.030081\n",
      "batch 5678: loss 0.037901\n",
      "batch 5679: loss 0.019420\n",
      "batch 5680: loss 0.094220\n",
      "batch 5681: loss 0.057506\n",
      "batch 5682: loss 0.009320\n",
      "batch 5683: loss 0.028388\n",
      "batch 5684: loss 0.003024\n",
      "batch 5685: loss 0.020196\n",
      "batch 5686: loss 0.041013\n",
      "batch 5687: loss 0.114222\n",
      "batch 5688: loss 0.015050\n",
      "batch 5689: loss 0.010891\n",
      "batch 5690: loss 0.015497\n",
      "batch 5691: loss 0.013042\n",
      "batch 5692: loss 0.005085\n",
      "batch 5693: loss 0.053200\n",
      "batch 5694: loss 0.001775\n",
      "batch 5695: loss 0.047081\n",
      "batch 5696: loss 0.001679\n",
      "batch 5697: loss 0.008986\n",
      "batch 5698: loss 0.012510\n",
      "batch 5699: loss 0.013742\n",
      "batch 5700: loss 0.036224\n",
      "batch 5701: loss 0.002406\n",
      "batch 5702: loss 0.004200\n",
      "batch 5703: loss 0.033600\n",
      "batch 5704: loss 0.013058\n",
      "batch 5705: loss 0.045182\n",
      "batch 5706: loss 0.010999\n",
      "batch 5707: loss 0.008098\n",
      "batch 5708: loss 0.021598\n",
      "batch 5709: loss 0.003796\n",
      "batch 5710: loss 0.013648\n",
      "batch 5711: loss 0.021159\n",
      "batch 5712: loss 0.002702\n",
      "batch 5713: loss 0.029412\n",
      "batch 5714: loss 0.004508\n",
      "batch 5715: loss 0.019543\n",
      "batch 5716: loss 0.002169\n",
      "batch 5717: loss 0.017852\n",
      "batch 5718: loss 0.050585\n",
      "batch 5719: loss 0.002442\n",
      "batch 5720: loss 0.003869\n",
      "batch 5721: loss 0.016075\n",
      "batch 5722: loss 0.001607\n",
      "batch 5723: loss 0.009379\n",
      "batch 5724: loss 0.009346\n",
      "batch 5725: loss 0.010675\n",
      "batch 5726: loss 0.006477\n",
      "batch 5727: loss 0.010007\n",
      "batch 5728: loss 0.038819\n",
      "batch 5729: loss 0.016973\n",
      "batch 5730: loss 0.002633\n",
      "batch 5731: loss 0.014031\n",
      "batch 5732: loss 0.010917\n",
      "batch 5733: loss 0.108404\n",
      "batch 5734: loss 0.002479\n",
      "batch 5735: loss 0.020265\n",
      "batch 5736: loss 0.007585\n",
      "batch 5737: loss 0.005040\n",
      "batch 5738: loss 0.004308\n",
      "batch 5739: loss 0.004506\n",
      "batch 5740: loss 0.001134\n",
      "batch 5741: loss 0.011077\n",
      "batch 5742: loss 0.008581\n",
      "batch 5743: loss 0.005357\n",
      "batch 5744: loss 0.034400\n",
      "batch 5745: loss 0.027279\n",
      "batch 5746: loss 0.006458\n",
      "batch 5747: loss 0.007536\n",
      "batch 5748: loss 0.095505\n",
      "batch 5749: loss 0.018877\n",
      "batch 5750: loss 0.081869\n",
      "batch 5751: loss 0.018659\n",
      "batch 5752: loss 0.060079\n",
      "batch 5753: loss 0.042750\n",
      "batch 5754: loss 0.007524\n",
      "batch 5755: loss 0.000631\n",
      "batch 5756: loss 0.039812\n",
      "batch 5757: loss 0.026922\n",
      "batch 5758: loss 0.006767\n",
      "batch 5759: loss 0.006056\n",
      "batch 5760: loss 0.000756\n",
      "batch 5761: loss 0.013639\n",
      "batch 5762: loss 0.045041\n",
      "batch 5763: loss 0.043559\n",
      "batch 5764: loss 0.011674\n",
      "batch 5765: loss 0.008801\n",
      "batch 5766: loss 0.008836\n",
      "batch 5767: loss 0.003334\n",
      "batch 5768: loss 0.004698\n",
      "batch 5769: loss 0.004063\n",
      "batch 5770: loss 0.014868\n",
      "batch 5771: loss 0.020111\n",
      "batch 5772: loss 0.005277\n",
      "batch 5773: loss 0.008157\n",
      "batch 5774: loss 0.029468\n",
      "batch 5775: loss 0.015467\n",
      "batch 5776: loss 0.058059\n",
      "batch 5777: loss 0.058357\n",
      "batch 5778: loss 0.005957\n",
      "batch 5779: loss 0.018863\n",
      "batch 5780: loss 0.011160\n",
      "batch 5781: loss 0.005160\n",
      "batch 5782: loss 0.010890\n",
      "batch 5783: loss 0.001322\n",
      "batch 5784: loss 0.022231\n",
      "batch 5785: loss 0.002879\n",
      "batch 5786: loss 0.067654\n",
      "batch 5787: loss 0.007501\n",
      "batch 5788: loss 0.003954\n",
      "batch 5789: loss 0.030872\n",
      "batch 5790: loss 0.032210\n",
      "batch 5791: loss 0.006513\n",
      "batch 5792: loss 0.013804\n",
      "batch 5793: loss 0.001852\n",
      "batch 5794: loss 0.002678\n",
      "batch 5795: loss 0.029089\n",
      "batch 5796: loss 0.019851\n",
      "batch 5797: loss 0.021925\n",
      "batch 5798: loss 0.045246\n",
      "batch 5799: loss 0.005271\n",
      "batch 5800: loss 0.010832\n",
      "batch 5801: loss 0.022138\n",
      "batch 5802: loss 0.012568\n",
      "batch 5803: loss 0.002824\n",
      "batch 5804: loss 0.004781\n",
      "batch 5805: loss 0.012446\n",
      "batch 5806: loss 0.033556\n",
      "batch 5807: loss 0.001187\n",
      "batch 5808: loss 0.024496\n",
      "batch 5809: loss 0.005598\n",
      "batch 5810: loss 0.006759\n",
      "batch 5811: loss 0.008501\n",
      "batch 5812: loss 0.043949\n",
      "batch 5813: loss 0.013852\n",
      "batch 5814: loss 0.052333\n",
      "batch 5815: loss 0.025841\n",
      "batch 5816: loss 0.017195\n",
      "batch 5817: loss 0.026255\n",
      "batch 5818: loss 0.015976\n",
      "batch 5819: loss 0.015859\n",
      "batch 5820: loss 0.035636\n",
      "batch 5821: loss 0.005078\n",
      "batch 5822: loss 0.018149\n",
      "batch 5823: loss 0.025106\n",
      "batch 5824: loss 0.005970\n",
      "batch 5825: loss 0.023398\n",
      "batch 5826: loss 0.004182\n",
      "batch 5827: loss 0.034869\n",
      "batch 5828: loss 0.003124\n",
      "batch 5829: loss 0.024186\n",
      "batch 5830: loss 0.006359\n",
      "batch 5831: loss 0.006167\n",
      "batch 5832: loss 0.005159\n",
      "batch 5833: loss 0.052850\n",
      "batch 5834: loss 0.001823\n",
      "batch 5835: loss 0.011747\n",
      "batch 5836: loss 0.011183\n",
      "batch 5837: loss 0.007040\n",
      "batch 5838: loss 0.002132\n",
      "batch 5839: loss 0.007276\n",
      "batch 5840: loss 0.010830\n",
      "batch 5841: loss 0.007696\n",
      "batch 5842: loss 0.011794\n",
      "batch 5843: loss 0.026758\n",
      "batch 5844: loss 0.019576\n",
      "batch 5845: loss 0.008564\n",
      "batch 5846: loss 0.125528\n",
      "batch 5847: loss 0.083197\n",
      "batch 5848: loss 0.015552\n",
      "batch 5849: loss 0.002995\n",
      "batch 5850: loss 0.021632\n",
      "batch 5851: loss 0.005389\n",
      "batch 5852: loss 0.005382\n",
      "batch 5853: loss 0.009053\n",
      "batch 5854: loss 0.091151\n",
      "batch 5855: loss 0.013217\n",
      "batch 5856: loss 0.005765\n",
      "batch 5857: loss 0.037982\n",
      "batch 5858: loss 0.029425\n",
      "batch 5859: loss 0.049206\n",
      "batch 5860: loss 0.019758\n",
      "batch 5861: loss 0.013736\n",
      "batch 5862: loss 0.005792\n",
      "batch 5863: loss 0.007808\n",
      "batch 5864: loss 0.013486\n",
      "batch 5865: loss 0.004710\n",
      "batch 5866: loss 0.002827\n",
      "batch 5867: loss 0.008125\n",
      "batch 5868: loss 0.008949\n",
      "batch 5869: loss 0.021743\n",
      "batch 5870: loss 0.006160\n",
      "batch 5871: loss 0.023393\n",
      "batch 5872: loss 0.002345\n",
      "batch 5873: loss 0.006502\n",
      "batch 5874: loss 0.034052\n",
      "batch 5875: loss 0.005671\n",
      "batch 5876: loss 0.018450\n",
      "batch 5877: loss 0.010767\n",
      "batch 5878: loss 0.001619\n",
      "batch 5879: loss 0.014001\n",
      "batch 5880: loss 0.007707\n",
      "batch 5881: loss 0.020194\n",
      "batch 5882: loss 0.003988\n",
      "batch 5883: loss 0.011219\n",
      "batch 5884: loss 0.005592\n",
      "batch 5885: loss 0.073043\n",
      "batch 5886: loss 0.052550\n",
      "batch 5887: loss 0.025571\n",
      "batch 5888: loss 0.018429\n",
      "batch 5889: loss 0.030299\n",
      "batch 5890: loss 0.011247\n",
      "batch 5891: loss 0.016050\n",
      "batch 5892: loss 0.010941\n",
      "batch 5893: loss 0.002914\n",
      "batch 5894: loss 0.008967\n",
      "batch 5895: loss 0.008228\n",
      "batch 5896: loss 0.007655\n",
      "batch 5897: loss 0.048900\n",
      "batch 5898: loss 0.007590\n",
      "batch 5899: loss 0.004741\n",
      "batch 5900: loss 0.004858\n",
      "batch 5901: loss 0.005276\n",
      "batch 5902: loss 0.065462\n",
      "batch 5903: loss 0.088522\n",
      "batch 5904: loss 0.045606\n",
      "batch 5905: loss 0.005286\n",
      "batch 5906: loss 0.003477\n",
      "batch 5907: loss 0.010131\n",
      "batch 5908: loss 0.002358\n",
      "batch 5909: loss 0.047892\n",
      "batch 5910: loss 0.017080\n",
      "batch 5911: loss 0.002453\n",
      "batch 5912: loss 0.009687\n",
      "batch 5913: loss 0.001401\n",
      "batch 5914: loss 0.002802\n",
      "batch 5915: loss 0.001364\n",
      "batch 5916: loss 0.006879\n",
      "batch 5917: loss 0.017900\n",
      "batch 5918: loss 0.011730\n",
      "batch 5919: loss 0.028325\n",
      "batch 5920: loss 0.016599\n",
      "batch 5921: loss 0.003354\n",
      "batch 5922: loss 0.009757\n",
      "batch 5923: loss 0.013671\n",
      "batch 5924: loss 0.009292\n",
      "batch 5925: loss 0.002831\n",
      "batch 5926: loss 0.035938\n",
      "batch 5927: loss 0.108868\n",
      "batch 5928: loss 0.000947\n",
      "batch 5929: loss 0.001620\n",
      "batch 5930: loss 0.006790\n",
      "batch 5931: loss 0.004809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch 5932: loss 0.019662\n",
      "batch 5933: loss 0.046207\n",
      "batch 5934: loss 0.011227\n",
      "batch 5935: loss 0.004120\n",
      "batch 5936: loss 0.008962\n",
      "batch 5937: loss 0.061059\n",
      "batch 5938: loss 0.001567\n",
      "batch 5939: loss 0.004447\n",
      "batch 5940: loss 0.007740\n",
      "batch 5941: loss 0.019300\n",
      "batch 5942: loss 0.003518\n",
      "batch 5943: loss 0.011017\n",
      "batch 5944: loss 0.032036\n",
      "batch 5945: loss 0.012708\n",
      "batch 5946: loss 0.007838\n",
      "batch 5947: loss 0.012349\n",
      "batch 5948: loss 0.001157\n",
      "batch 5949: loss 0.017833\n",
      "batch 5950: loss 0.001841\n",
      "batch 5951: loss 0.025660\n",
      "batch 5952: loss 0.025307\n",
      "batch 5953: loss 0.020590\n",
      "batch 5954: loss 0.005130\n",
      "batch 5955: loss 0.010181\n",
      "batch 5956: loss 0.002960\n",
      "batch 5957: loss 0.009564\n",
      "batch 5958: loss 0.019505\n",
      "batch 5959: loss 0.003893\n",
      "batch 5960: loss 0.029474\n",
      "batch 5961: loss 0.011348\n",
      "batch 5962: loss 0.001135\n",
      "batch 5963: loss 0.021151\n",
      "batch 5964: loss 0.010434\n",
      "batch 5965: loss 0.009614\n",
      "batch 5966: loss 0.006904\n",
      "batch 5967: loss 0.015484\n",
      "batch 5968: loss 0.022732\n",
      "batch 5969: loss 0.046728\n",
      "batch 5970: loss 0.003516\n",
      "batch 5971: loss 0.004380\n",
      "batch 5972: loss 0.010549\n",
      "batch 5973: loss 0.015404\n",
      "batch 5974: loss 0.005443\n",
      "batch 5975: loss 0.002563\n",
      "batch 5976: loss 0.011625\n",
      "batch 5977: loss 0.005308\n",
      "batch 5978: loss 0.006472\n",
      "batch 5979: loss 0.002762\n",
      "batch 5980: loss 0.004086\n",
      "batch 5981: loss 0.025170\n",
      "batch 5982: loss 0.002802\n",
      "batch 5983: loss 0.011204\n",
      "batch 5984: loss 0.048909\n",
      "batch 5985: loss 0.011087\n",
      "batch 5986: loss 0.017358\n",
      "batch 5987: loss 0.004671\n",
      "batch 5988: loss 0.008831\n",
      "batch 5989: loss 0.114993\n",
      "batch 5990: loss 0.004517\n",
      "batch 5991: loss 0.044876\n",
      "batch 5992: loss 0.006028\n",
      "batch 5993: loss 0.004795\n",
      "batch 5994: loss 0.009030\n",
      "batch 5995: loss 0.097509\n",
      "batch 5996: loss 0.018564\n",
      "batch 5997: loss 0.003727\n",
      "batch 5998: loss 0.162008\n",
      "batch 5999: loss 0.004520\n"
     ]
    }
   ],
   "source": [
    "num_batches = int(data_loader.num_train_data // batch_size * num_epochs)\n",
    "for batch_index in range(num_batches):\n",
    "    X, y = data_loader.get_batch(batch_size)\n",
    "    with tf.GradientTape() as tape:\n",
    "        y_pred = model(X)\n",
    "        loss = tf.keras.losses.sparse_categorical_crossentropy(y_true=y, y_pred=y_pred)\n",
    "        loss = tf.reduce_mean(loss)\n",
    "        print(\"batch %d: loss %f\" % (batch_index, loss.numpy()))\n",
    "    grads = tape.gradient(loss, model.variables)\n",
    "    _ = optimizer.apply_gradients(grads_and_vars=zip(grads, model.variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('tf2.0': conda)",
   "language": "python",
   "name": "python37064bittf20conda6f2e3f475a1a467f9157e7cb1cbbc090"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
