{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM by Hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "来源: https://www.bilibili.com/video/BV1FV41117Uz/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paddle enabled successfully......\n"
     ]
    }
   ],
   "source": [
    "jieba.enable_paddle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "sequence_length = 5\n",
    "input_size = 30\n",
    "output_size = 20\n",
    "\n",
    "x = tf.random.uniform((batch_size, sequence_length, input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 5, 30])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM's input: [batch_size, sequence_length, input_size]\n",
    "# LSTM's output1: [batch_size, sequence_length, input_size]\n",
    "#        output2: [batch_size, input_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = x[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 30])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = tf.random.uniform((input_size, output_size))\n",
    "wi = tf.random.uniform((input_size, output_size))\n",
    "wo = tf.random.uniform((input_size, output_size))\n",
    "wc = tf.random.uniform((input_size, output_size))\n",
    "\n",
    "uf = tf.random.uniform((output_size, output_size))\n",
    "ui = tf.random.uniform((output_size, output_size))\n",
    "uo = tf.random.uniform((output_size, output_size))\n",
    "uc = tf.random.uniform((output_size, output_size))\n",
    "\n",
    "bf = tf.random.uniform((1, output_size))\n",
    "bi = tf.random.uniform((1, output_size))\n",
    "bo = tf.random.uniform((1, output_size))\n",
    "bc = tf.random.uniform((1, output_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_outputs = []\n",
    "for i in range(sequence_length):\n",
    "\n",
    "    if i == 0:\n",
    "        xt = x[:, 0, :]\n",
    "        ft = tf.sigmoid(tf.matmul(xt, wf) + bf)\n",
    "        it = tf.sigmoid(tf.matmul(xt, wi) + bi)\n",
    "        ot = tf.sigmoid(tf.matmul(xt, wo) + bo)\n",
    "        cht = tf.tanh(tf.matmul(xt, wc) + bc)\n",
    "\n",
    "        ct = it * cht\n",
    "        ht = ot * tf.tanh(ct)\n",
    "    \n",
    "    else:\n",
    "        xt = x[:, 0, :]\n",
    "        ft = tf.sigmoid(tf.matmul(xt, wf) + bf)\n",
    "        it = tf.sigmoid(tf.matmul(xt, wi) + bi)\n",
    "        ot = tf.sigmoid(tf.matmul(xt, wo) + bo)\n",
    "        cht = tf.tanh(tf.matmul(xt, wc) + bc)\n",
    "\n",
    "        ct = ft * ct + it * cht\n",
    "        ht = ot * tf.tanh(ct)\n",
    "    \n",
    "    sequence_outputs.append(ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_outputs = tf.stack(sequence_outputs)\n",
    "sequence_outputs = tf.transpose(sequence_outputs, (1, 0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 5, 20), dtype=float32, numpy=\n",
       "array([[[0.75968313, 0.7612307 , 0.7609331 , 0.7608878 , 0.76081806,\n",
       "         0.7610073 , 0.760796  , 0.76098645, 0.76131004, 0.7606621 ,\n",
       "         0.76035756, 0.76084065, 0.7612073 , 0.7608161 , 0.760411  ,\n",
       "         0.7610628 , 0.7610523 , 0.7607056 , 0.7611117 , 0.76004195],\n",
       "        [0.9616596 , 0.9637002 , 0.9633146 , 0.9633101 , 0.963115  ,\n",
       "         0.96330076, 0.963086  , 0.96334845, 0.9634829 , 0.96290797,\n",
       "         0.96283597, 0.9633642 , 0.9636256 , 0.9633425 , 0.96293634,\n",
       "         0.9635948 , 0.96340144, 0.9630325 , 0.96349764, 0.9626773 ],\n",
       "        [0.9926386 , 0.99477166, 0.9944598 , 0.99443686, 0.9941524 ,\n",
       "         0.9944042 , 0.99414885, 0.9944644 , 0.9947988 , 0.99392563,\n",
       "         0.99400395, 0.9945192 , 0.99468374, 0.99447703, 0.99409807,\n",
       "         0.9947011 , 0.9945429 , 0.99406916, 0.9945493 , 0.9938628 ],\n",
       "        [0.9969111 , 0.99905956, 0.9987818 , 0.9987481 , 0.99843496,\n",
       "         0.9987157 , 0.9984424 , 0.9987761 , 0.9992084 , 0.9982025 ,\n",
       "         0.998325  , 0.99883515, 0.9989693 , 0.99878407, 0.9984135 ,\n",
       "         0.9989978 , 0.99886626, 0.99834865, 0.99883366, 0.9981781 ],\n",
       "        [0.99749154, 0.9996426 , 0.99937445, 0.9993375 , 0.9990174 ,\n",
       "         0.99930584, 0.9990276 , 0.99936587, 0.99982643, 0.9987833 ,\n",
       "         0.99891615, 0.999425  , 0.9995521 , 0.99937147, 0.9990029 ,\n",
       "         0.99958265, 0.9994595 , 0.99893   , 0.999416  , 0.99876636]],\n",
       "\n",
       "       [[0.74865615, 0.7602273 , 0.75927824, 0.7596573 , 0.7597537 ,\n",
       "         0.76034117, 0.75981593, 0.76033527, 0.75963503, 0.7581691 ,\n",
       "         0.7590157 , 0.75980705, 0.7609554 , 0.7595375 , 0.75793076,\n",
       "         0.75941575, 0.75982773, 0.7596846 , 0.75962466, 0.75792515],\n",
       "        [0.9478721 , 0.96308565, 0.9617746 , 0.9626858 , 0.9621065 ,\n",
       "         0.96251786, 0.96210635, 0.962721  , 0.96189624, 0.95979005,\n",
       "         0.9622184 , 0.9625124 , 0.9632999 , 0.962422  , 0.96007484,\n",
       "         0.96209   , 0.96217346, 0.9620737 , 0.9618849 , 0.9612861 ],\n",
       "        [0.9784793 , 0.9943841 , 0.99303657, 0.99422204, 0.99327886,\n",
       "         0.99372494, 0.9932988 , 0.99391514, 0.9935804 , 0.9907803 ,\n",
       "         0.99370664, 0.99383867, 0.9943862 , 0.9937915 , 0.9913784 ,\n",
       "         0.9934269 , 0.9933416 , 0.9931913 , 0.9930066 , 0.99284136],\n",
       "        [0.98271024, 0.99873203, 0.9973876 , 0.9986531 , 0.99760604,\n",
       "         0.99808264, 0.99763894, 0.9982531 , 0.9981268 , 0.9950712 ,\n",
       "         0.99810106, 0.9982056 , 0.9986866 , 0.9981624 , 0.9957616 ,\n",
       "         0.9977977 , 0.9976681 , 0.9974929 , 0.9973181 , 0.99724513],\n",
       "        [0.9832869 , 0.99932796, 0.9979857 , 0.9992703 , 0.9981991 ,\n",
       "         0.99868554, 0.9982359 , 0.9988495 , 0.9987814 , 0.99565756,\n",
       "         0.99870676, 0.99880755, 0.99927366, 0.9987638 , 0.9963697 ,\n",
       "         0.9984003 , 0.99826103, 0.9980787 , 0.99790746, 0.99785113]],\n",
       "\n",
       "       [[0.7596916 , 0.760667  , 0.7609264 , 0.76119417, 0.76128614,\n",
       "         0.76135653, 0.76080245, 0.7612173 , 0.76126313, 0.7609814 ,\n",
       "         0.76088643, 0.7599169 , 0.7614467 , 0.7608699 , 0.7606221 ,\n",
       "         0.7607214 , 0.7613568 , 0.7612036 , 0.7604001 , 0.76089954],\n",
       "        [0.9616394 , 0.9635181 , 0.96321046, 0.9636881 , 0.9638012 ,\n",
       "         0.9635933 , 0.9629134 , 0.96357346, 0.9636609 , 0.9632681 ,\n",
       "         0.9633889 , 0.96263707, 0.9638836 , 0.96327674, 0.9633655 ,\n",
       "         0.9635451 , 0.96375215, 0.9636184 , 0.962619  , 0.9633971 ],\n",
       "        [0.9926096 , 0.99476665, 0.99429864, 0.9948104 , 0.99488133,\n",
       "         0.9947334 , 0.99401295, 0.99465257, 0.9948128 , 0.9942906 ,\n",
       "         0.9944999 , 0.99404114, 0.99492496, 0.99437976, 0.99458516,\n",
       "         0.99476904, 0.9948139 , 0.9946618 , 0.9936441 , 0.9944926 ],\n",
       "        [0.99688065, 0.99909765, 0.99860364, 0.9991173 , 0.9991698 ,\n",
       "         0.99906605, 0.9983337 , 0.99895114, 0.99913883, 0.99856883,\n",
       "         0.9987992 , 0.9984403 , 0.9992039 , 0.99868226, 0.99891126,\n",
       "         0.999092  , 0.9991036 , 0.9989414 , 0.9979242 , 0.99878615],\n",
       "        [0.9974608 , 0.9996894 , 0.9991922 , 0.9997052 , 0.99975276,\n",
       "         0.9996627 , 0.9989273 , 0.99953777, 0.9997326 , 0.99915016,\n",
       "         0.99938494, 0.99905086, 0.9997851 , 0.99926955, 0.9995024 ,\n",
       "         0.9996819 , 0.9996875 , 0.9995227 , 0.99850583, 0.9993702 ]],\n",
       "\n",
       "       [[0.7585644 , 0.7609141 , 0.7595902 , 0.7611067 , 0.7604327 ,\n",
       "         0.7603087 , 0.7599383 , 0.76080674, 0.76040447, 0.7607099 ,\n",
       "         0.75914663, 0.7602693 , 0.7607822 , 0.76049834, 0.7605416 ,\n",
       "         0.7589567 , 0.7604983 , 0.76078624, 0.7607895 , 0.7596205 ],\n",
       "        [0.9602877 , 0.96364075, 0.9616127 , 0.9635556 , 0.962712  ,\n",
       "         0.962428  , 0.96220493, 0.9631182 , 0.96302134, 0.9630462 ,\n",
       "         0.96180207, 0.96288645, 0.96313995, 0.96318245, 0.96322376,\n",
       "         0.96261096, 0.962835  , 0.9631321 , 0.96325547, 0.96248895],\n",
       "        [0.99124223, 0.994844  , 0.99281   , 0.9947234 , 0.9937928 ,\n",
       "         0.9937641 , 0.99333113, 0.99430245, 0.9943135 , 0.99409896,\n",
       "         0.99313533, 0.99418736, 0.9942309 , 0.99438006, 0.9944887 ,\n",
       "         0.99421805, 0.99395126, 0.99417186, 0.99436975, 0.9937722 ],\n",
       "        [0.9955141 , 0.9991663 , 0.99716866, 0.9990514 , 0.9980917 ,\n",
       "         0.99817896, 0.99764615, 0.99864453, 0.9986765 , 0.99838465,\n",
       "         0.9975042 , 0.9985531 , 0.99853134, 0.99870044, 0.99883693,\n",
       "         0.99863076, 0.99826133, 0.9984518 , 0.9986723 , 0.9981091 ],\n",
       "        [0.9960949 , 0.9997568 , 0.9977724 , 0.99964523, 0.99867815,\n",
       "         0.9987981 , 0.9982367 , 0.9992426 , 0.99927825, 0.99896735,\n",
       "         0.9981061 , 0.9991554 , 0.99911785, 0.99929   , 0.99943453,\n",
       "         0.999238  , 0.99885046, 0.9990331 , 0.99925894, 0.9987016 ]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLSTM(tf.keras.layers.Layer):\n",
    "    \n",
    "    \"\"\"\n",
    "    LSTM's input: [batch_size, sequence_length, input_size]\n",
    "    LSTM's output1: [batch_size, sequence_length, input_size]\n",
    "           output2: [batch_size, input_size]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, output_size, return_sequence=False):\n",
    "        super(CustomLSTM, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.return_sequence = return_sequence\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        super(CustomLSTM, self).build(input_shape)\n",
    "        input_size = int(input_shape[-1])\n",
    "        \n",
    "        self.wf = self.add_weight('wf', shape=(input_size, self.output_size))\n",
    "        self.wi = self.add_weight('wi', shape=(input_size, self.output_size))\n",
    "        self.wo = self.add_weight('wo', shape=(input_size, self.output_size))\n",
    "        self.wc = self.add_weight('wc', shape=(input_size, self.output_size))\n",
    "\n",
    "        self.uf = self.add_weight('uf', shape=(self.output_size, self.output_size))\n",
    "        self.ui = self.add_weight('ui', shape=(self.output_size, self.output_size))\n",
    "        self.uo = self.add_weight('uo', shape=(self.output_size, self.output_size))\n",
    "        self.uc = self.add_weight('uc', shape=(self.output_size, self.output_size))\n",
    "\n",
    "        self.bf = self.add_weight('bf', shape=(1, self.output_size))\n",
    "        self.bi = self.add_weight('bi', shape=(1, self.output_size))\n",
    "        self.bo = self.add_weight('bo', shape=(1, self.output_size))\n",
    "        self.bc = self.add_weight('bc', shape=(1, self.output_size))\n",
    "\n",
    "    def call(self, x):\n",
    "        sequence_outputs = []\n",
    "        for i in range(sequence_length):\n",
    "            if i == 0:\n",
    "                xt  = x[:, 0, :]\n",
    "                ft  = tf.sigmoid(tf.matmul(xt, self.wf) + self.bf)\n",
    "                it  = tf.sigmoid(tf.matmul(xt, self.wi) + self.bi)\n",
    "                ot  = tf.sigmoid(tf.matmul(xt, self.wo) + self.bo)\n",
    "                cht = tf.tanh(   tf.matmul(xt, self.wc) + self.bc)\n",
    "                ct  = it * cht\n",
    "                ht  = ot * tf.tanh(ct)\n",
    "\n",
    "            else:\n",
    "                xt  = x[:, 0, :]\n",
    "                ft  = tf.sigmoid(tf.matmul(xt, self.wf) + self.bf)\n",
    "                it  = tf.sigmoid(tf.matmul(xt, self.wi) + self.bi)\n",
    "                ot  = tf.sigmoid(tf.matmul(xt, self.wo) + self.bo)\n",
    "                cht = tf.tanh(  tf.matmul(xt, self.wc) + self.bc)\n",
    "                ct  = ft * ct + it * cht\n",
    "                ht  = ot * tf.tanh(ct)\n",
    "                \n",
    "            sequence_outputs.append(ht)\n",
    "            \n",
    "        sequence_outputs = tf.stack(sequence_outputs)\n",
    "        sequence_outputs = tf.transpose(sequence_outputs, (1, 0, 2))\n",
    "        if self.return_sequence:\n",
    "            return sequence_outputs\n",
    "        return sequence_outputs[:, -1, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.uniform((batch_size, sequence_length, input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = CustomLSTM(output_size=output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 20), dtype=float32, numpy=\n",
       "array([[-0.02465984,  0.24337918, -0.01038667,  0.18872677,  0.25175014,\n",
       "         0.21659058, -0.3161729 , -0.02962111, -0.11237445,  0.52755046,\n",
       "        -0.51885635, -0.24678676,  0.26010892, -0.19956557,  0.44766775,\n",
       "         0.07805736,  0.56003   ,  0.17517935,  0.12646793, -0.17871073],\n",
       "       [ 0.08170585,  0.34328038, -0.2221587 ,  0.1857989 ,  0.34343675,\n",
       "         0.22039437, -0.13987061, -0.03365904, -0.04686617,  0.30995008,\n",
       "        -0.48257637, -0.21904732,  0.21090023, -0.19042602,  0.5343647 ,\n",
       "         0.19197959,  0.4998687 ,  0.06068008, -0.01904575, -0.0856628 ],\n",
       "       [-0.20344037,  0.14708847, -0.01317312,  0.18910876,  0.2624301 ,\n",
       "         0.20066454, -0.25570446,  0.04223626, -0.0492571 ,  0.4126082 ,\n",
       "        -0.5265868 , -0.07792316,  0.16856897, -0.19315873,  0.61615115,\n",
       "        -0.19891731,  0.55206233,  0.19993803,  0.20309655, -0.0655907 ],\n",
       "       [ 0.03935883,  0.31329268, -0.13026157,  0.14405465,  0.4169662 ,\n",
       "         0.17643069, -0.18185888,  0.01598078, -0.13051683,  0.324436  ,\n",
       "        -0.27166787,  0.03704268,  0.24445914, -0.22810079,  0.31751847,\n",
       "         0.16102493,  0.42171934,  0.15271541,  0.05820363, -0.17413893]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    CustomLSTM(output_size=32), \n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-5f15418b3570>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/tf2.0/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36msummary\u001b[0;34m(self, line_length, positions, print_fn)\u001b[0m\n\u001b[1;32m   2349\u001b[0m     \"\"\"\n\u001b[1;32m   2350\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2351\u001b[0;31m       raise ValueError('This model has not yet been built. '\n\u001b[0m\u001b[1;32m   2352\u001b[0m                        \u001b[0;34m'Build the model first by calling `build()` or calling '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2353\u001b[0m                        \u001b[0;34m'`fit()` with some data, or specify '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: This model has not yet been built. Build the model first by calling `build()` or calling `fit()` with some data, or specify an `input_shape` argument in the first layer(s) for automatic build."
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch = tf.random.uniform((batch_size, sequence_length, input_size))\n",
    "y_batch = tf.random.uniform((batch_size,), maxval=2, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.train_on_batch(x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = tf.random.uniform((batch_size * 1000, sequence_length, input_size))\n",
    "y_data = tf.random.uniform((batch_size * 1000,), maxval=2, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_data, y_data, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_data, y_data, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_data, y_data, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zh_dataset_inews import title_train, label_train, content_train, title_test, label_test, content_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_train_cut = [' '.join(jieba.cut(x, cut_all=False)) for x in title_train]\n",
    "title_test_cut  = [' '.join(jieba.cut(x, cut_all=False)) for x in title_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(title_train_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_train_cut[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vector = tf.keras.layers.experimental.preprocessing.TextVectorization()\n",
    "# 学习词表\n",
    "text_vector.adapt(title_train_cut)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "type(x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 text_vector('你 好') 和  text_vector('你好')对比发现，这里没有进行分词   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vector('你 好')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "text_vector('你好')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_train_text_vector = text_vector(title_train_cut) # [text_vector(x) for x in title_train_cut]\n",
    "title_test_text_vector  = text_vector(title_test_cut) # [text_vector(x) for x in title_test_cut]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_train_text_vector[:10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.convert_to_tensor(title_train_text_vector)\n",
    "x_test  = tf.convert_to_tensor(title_test_text_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.convert_to_tensor(label_train)\n",
    "y_test  = tf.convert_to_tensor(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_text = tf.keras.Sequential([\n",
    "    CustomLSTM(output_size=32), \n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model_text.compile(\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_text.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_model_text = model_text.fit(x_train, y_train, )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.0 64-bit ('tf2.0': conda)",
   "language": "python",
   "name": "python37064bittf20conda6f2e3f475a1a467f9157e7cb1cbbc090"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
