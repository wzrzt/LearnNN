{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTM by Hand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过自定义层实现LSTM，学习自Tensorflow Codelab线下活动(20201114)  \n",
    "分享内容参考      https://zhuanlan.zhihu.com/p/293208563  \n",
    "自定义LSTM层来源: https://www.bilibili.com/video/BV1FV41117Uz/  \n",
    "  \n",
    "  \n",
    "[LSTM简介](https://zh.wikipedia.org/wiki/%E9%95%B7%E7%9F%AD%E6%9C%9F%E8%A8%98%E6%86%B6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import jieba\n",
    "import pandas as pd\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "pd.options.display.max_columns = None\n",
    "pd.options.display.max_colwidth = 80\n",
    "pd.options.display.precision = 4\n",
    "pd.options.display.max_rows = 999\n",
    "pd.options.display.float_format = '{:.4f}'.format  # 防止科学计数法，小数显示4位"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Paddle enabled successfully......\n"
     ]
    }
   ],
   "source": [
    "jieba.enable_paddle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "sequence_length = 5\n",
    "input_size = 30\n",
    "output_size = 20\n",
    "\n",
    "x = tf.random.uniform((batch_size, sequence_length, input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 5, 30])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LSTM's input: [batch_size, sequence_length, input_size]\n",
    "# LSTM's output1: [batch_size, sequence_length, input_size]\n",
    "#        output2: [batch_size, input_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt = x[:, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 30])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 按照LSTM的公式写出计算过程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wf = tf.random.uniform((input_size, output_size))\n",
    "wi = tf.random.uniform((input_size, output_size))\n",
    "wo = tf.random.uniform((input_size, output_size))\n",
    "wc = tf.random.uniform((input_size, output_size))\n",
    "\n",
    "uf = tf.random.uniform((output_size, output_size))\n",
    "ui = tf.random.uniform((output_size, output_size))\n",
    "uo = tf.random.uniform((output_size, output_size))\n",
    "uc = tf.random.uniform((output_size, output_size))\n",
    "\n",
    "bf = tf.random.uniform((1, output_size))\n",
    "bi = tf.random.uniform((1, output_size))\n",
    "bo = tf.random.uniform((1, output_size))\n",
    "bc = tf.random.uniform((1, output_size))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_outputs = []\n",
    "for i in range(sequence_length):\n",
    "\n",
    "    if i == 0:\n",
    "        xt = x[:, 0, :]\n",
    "        ft = tf.sigmoid(tf.matmul(xt, wf) + bf)\n",
    "        it = tf.sigmoid(tf.matmul(xt, wi) + bi)\n",
    "        ot = tf.sigmoid(tf.matmul(xt, wo) + bo)\n",
    "        cht = tf.tanh(tf.matmul(xt, wc) + bc)\n",
    "\n",
    "        ct = it * cht\n",
    "        ht = ot * tf.tanh(ct)\n",
    "    \n",
    "    else:\n",
    "        xt = x[:, 0, :]\n",
    "        ft = tf.sigmoid(tf.matmul(xt, wf) + bf)\n",
    "        it = tf.sigmoid(tf.matmul(xt, wi) + bi)\n",
    "        ot = tf.sigmoid(tf.matmul(xt, wo) + bo)\n",
    "        cht = tf.tanh(tf.matmul(xt, wc) + bc)\n",
    "\n",
    "        ct = ft * ct + it * cht\n",
    "        ht = ot * tf.tanh(ct)\n",
    "    \n",
    "    sequence_outputs.append(ht)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_outputs = tf.stack(sequence_outputs)\n",
    "sequence_outputs = tf.transpose(sequence_outputs, (1, 0, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 5, 20), dtype=float32, numpy=\n",
       "array([[[0.7571146 , 0.76023316, 0.75638837, 0.7600371 , 0.7607675 ,\n",
       "         0.76129615, 0.7582463 , 0.7598633 , 0.76045233, 0.7598843 ,\n",
       "         0.7596849 , 0.7601457 , 0.75801605, 0.7604064 , 0.76047444,\n",
       "         0.75955904, 0.7567714 , 0.7599652 , 0.7603811 , 0.7583166 ],\n",
       "        [0.9596851 , 0.9629085 , 0.9577052 , 0.9630542 , 0.96312475,\n",
       "         0.9633364 , 0.96006715, 0.96258503, 0.9626385 , 0.9621381 ,\n",
       "         0.9618838 , 0.96242076, 0.96143407, 0.96283245, 0.9631819 ,\n",
       "         0.96082014, 0.9594744 , 0.9626155 , 0.96266365, 0.96117103],\n",
       "        [0.9909878 , 0.99412656, 0.9886444 , 0.9943617 , 0.9942011 ,\n",
       "         0.9946081 , 0.99110043, 0.9939784 , 0.9937889 , 0.99327695,\n",
       "         0.9929588 , 0.9934904 , 0.99324894, 0.99398035, 0.9944741 ,\n",
       "         0.9922902 , 0.99102724, 0.99385715, 0.9938059 , 0.99254787],\n",
       "        [0.99533576, 0.9984539 , 0.99292237, 0.99870116, 0.9984954 ,\n",
       "         0.9990082 , 0.9953959 , 0.9983723 , 0.998123  , 0.99759793,\n",
       "         0.9972556 , 0.9977831 , 0.9977581 , 0.9982968 , 0.9988317 ,\n",
       "         0.99681586, 0.99546766, 0.9981944 , 0.99812955, 0.99691546],\n",
       "        [0.99593073, 0.9990453 , 0.99350584, 0.99929386, 0.99908036,\n",
       "         0.9996246 , 0.99598235, 0.9989817 , 0.9987195 , 0.99819   ,\n",
       "         0.9978415 , 0.9983676 , 0.9983925 , 0.99888706, 0.99943143,\n",
       "         0.9974711 , 0.9960866 , 0.9987884 , 0.99872273, 0.99751514]],\n",
       "\n",
       "       [[0.7601835 , 0.76111156, 0.7593534 , 0.76083356, 0.76135904,\n",
       "         0.7615316 , 0.76104957, 0.7611747 , 0.76120377, 0.76107323,\n",
       "         0.76128787, 0.76148593, 0.76072526, 0.7611838 , 0.76142526,\n",
       "         0.76105225, 0.76018685, 0.7610923 , 0.76133317, 0.76055336],\n",
       "        [0.9625797 , 0.9636797 , 0.961309  , 0.9637441 , 0.963767  ,\n",
       "         0.9639421 , 0.96340156, 0.9636836 , 0.96356285, 0.96343195,\n",
       "         0.9636735 , 0.96391183, 0.9633262 , 0.9635646 , 0.96391684,\n",
       "         0.96325266, 0.9628697 , 0.96358764, 0.9637768 , 0.9633347 ],\n",
       "        [0.9936712 , 0.9947854 , 0.992291  , 0.9949686 , 0.99480635,\n",
       "         0.9949989 , 0.99443257, 0.994802  , 0.9946358 , 0.9944694 ,\n",
       "         0.9947058 , 0.9949454 , 0.99463135, 0.99461406, 0.9949924 ,\n",
       "         0.99432796, 0.9940706 , 0.994696  , 0.9948324 , 0.99453354],\n",
       "        [0.9979651 , 0.99907994, 0.99656385, 0.99928683, 0.999086  ,\n",
       "         0.9992863 , 0.99871045, 0.99910593, 0.9989312 , 0.99874973,\n",
       "         0.9989834 , 0.9992221 , 0.999003  , 0.9988983 , 0.99928164,\n",
       "         0.9986344 , 0.9983901 , 0.9989964 , 0.99911624, 0.99884796],\n",
       "        [0.99854904, 0.9996639 , 0.99714416, 0.9998749 , 0.99966735,\n",
       "         0.99987006, 0.99929136, 0.999693  , 0.9995172 , 0.99933124,\n",
       "         0.99956435, 0.99980265, 0.99960756, 0.999481  , 0.999865  ,\n",
       "         0.99922395, 0.9989792 , 0.9995824 , 0.99969834, 0.99943566]],\n",
       "\n",
       "       [[0.759897  , 0.76127744, 0.7608912 , 0.7608886 , 0.76146   ,\n",
       "         0.7615371 , 0.7614227 , 0.7612723 , 0.7613014 , 0.7611775 ,\n",
       "         0.7613043 , 0.7614978 , 0.7608819 , 0.7613151 , 0.7613845 ,\n",
       "         0.76132154, 0.7607378 , 0.7613234 , 0.76143336, 0.7605463 ],\n",
       "        [0.96229345, 0.9637742 , 0.9632159 , 0.9637483 , 0.963894  ,\n",
       "         0.96391857, 0.9638625 , 0.96370304, 0.96367335, 0.963586  ,\n",
       "         0.9637039 , 0.96392643, 0.9633309 , 0.9637011 , 0.9638954 ,\n",
       "         0.96365404, 0.9633535 , 0.96371704, 0.9638677 , 0.96358323],\n",
       "        [0.9934066 , 0.994859  , 0.99424845, 0.99495274, 0.9949318 ,\n",
       "         0.99497867, 0.9949034 , 0.994868  , 0.99473983, 0.99463326,\n",
       "         0.9947375 , 0.99496454, 0.99446213, 0.9947416 , 0.99498904,\n",
       "         0.9946957 , 0.9945486 , 0.9948063 , 0.9949079 , 0.99486536],\n",
       "        [0.9977071 , 0.9991508 , 0.99852794, 0.9992662 , 0.9992095 ,\n",
       "         0.99926984, 0.9991818 , 0.9991969 , 0.99903274, 0.99891484,\n",
       "         0.9990148 , 0.9992432 , 0.9987733 , 0.99902284, 0.9992842 ,\n",
       "         0.998981  , 0.998874  , 0.9991069 , 0.9991865 , 0.99919677],\n",
       "        [0.998293  , 0.9997347 , 0.9991091 , 0.9998537 , 0.99979043,\n",
       "         0.9998543 , 0.9997625 , 0.9997914 , 0.9996177 , 0.9994966 ,\n",
       "         0.9995955 , 0.99982405, 0.9993626 , 0.99960464, 0.99986905,\n",
       "         0.99956435, 0.99946594, 0.99969405, 0.9997675 , 0.99978745]],\n",
       "\n",
       "       [[0.7526409 , 0.7582475 , 0.75422   , 0.75942886, 0.76039875,\n",
       "         0.7609635 , 0.7582997 , 0.76075035, 0.7584041 , 0.75904435,\n",
       "         0.75977457, 0.7604993 , 0.7554406 , 0.75937945, 0.7599606 ,\n",
       "         0.7591188 , 0.75708455, 0.759133  , 0.7600732 , 0.7577903 ],\n",
       "        [0.9543891 , 0.96133643, 0.95511603, 0.9630261 , 0.9629003 ,\n",
       "         0.9631034 , 0.96015656, 0.9631217 , 0.9603457 , 0.96156996,\n",
       "         0.96219337, 0.96289533, 0.959026  , 0.96166277, 0.96303403,\n",
       "         0.96077275, 0.9605482 , 0.96161526, 0.9622264 , 0.96195745],\n",
       "        [0.98565656, 0.99278915, 0.98609895, 0.9945538 , 0.99408615,\n",
       "         0.9943801 , 0.99121326, 0.9944085 , 0.9918186 , 0.9927931 ,\n",
       "         0.993348  , 0.99399763, 0.99123925, 0.99291074, 0.99444634,\n",
       "         0.99204063, 0.9923358 , 0.9930666 , 0.9933505 , 0.9937743 ],\n",
       "        [0.990015  , 0.9971714 , 0.9904091 , 0.9989408 , 0.9984132 ,\n",
       "         0.9987733 , 0.9955165 , 0.99878854, 0.9962899 , 0.99712455,\n",
       "         0.9976633 , 0.99829805, 0.9958863 , 0.99727124, 0.9988247 ,\n",
       "         0.9964507 , 0.9968236 , 0.99749637, 0.9976734 , 0.99823046],\n",
       "        [0.99061406, 0.99777347, 0.99100155, 0.99954206, 0.99900573,\n",
       "         0.9993869 , 0.9961046 , 0.99939686, 0.99692416, 0.99771684,\n",
       "         0.998253  , 0.9988844 , 0.9965563 , 0.99787325, 0.99942744,\n",
       "         0.9970705 , 0.9974512 , 0.998116  , 0.9982667 , 0.99884546]]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequence_outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 利用LSTM计算过程创建自定义LSTM层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomLSTM(tf.keras.layers.Layer):\n",
    "    \n",
    "    \"\"\"\n",
    "    LSTM's input: [batch_size, sequence_length, input_size]\n",
    "    LSTM's output1: [batch_size, sequence_length, input_size]\n",
    "           output2: [batch_size, input_size]\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, output_size, return_sequence=False):\n",
    "        super(CustomLSTM, self).__init__()\n",
    "        self.output_size = output_size\n",
    "        self.return_sequence = return_sequence\n",
    "    \n",
    "    def build(self, input_shape):\n",
    "        super(CustomLSTM, self).build(input_shape)\n",
    "        input_size = int(input_shape[-1])\n",
    "        \n",
    "        self.wf = self.add_weight('wf', shape=(input_size, self.output_size))\n",
    "        self.wi = self.add_weight('wi', shape=(input_size, self.output_size))\n",
    "        self.wo = self.add_weight('wo', shape=(input_size, self.output_size))\n",
    "        self.wc = self.add_weight('wc', shape=(input_size, self.output_size))\n",
    "\n",
    "        self.uf = self.add_weight('uf', shape=(self.output_size, self.output_size))\n",
    "        self.ui = self.add_weight('ui', shape=(self.output_size, self.output_size))\n",
    "        self.uo = self.add_weight('uo', shape=(self.output_size, self.output_size))\n",
    "        self.uc = self.add_weight('uc', shape=(self.output_size, self.output_size))\n",
    "\n",
    "        self.bf = self.add_weight('bf', shape=(1, self.output_size))\n",
    "        self.bi = self.add_weight('bi', shape=(1, self.output_size))\n",
    "        self.bo = self.add_weight('bo', shape=(1, self.output_size))\n",
    "        self.bc = self.add_weight('bc', shape=(1, self.output_size))\n",
    "\n",
    "    def call(self, x):\n",
    "        sequence_outputs = []\n",
    "        for i in range(sequence_length):\n",
    "            if i == 0:\n",
    "                xt  = x[:, 0, :]\n",
    "                ft  = tf.sigmoid(tf.matmul(xt, self.wf) + self.bf)\n",
    "                it  = tf.sigmoid(tf.matmul(xt, self.wi) + self.bi)\n",
    "                ot  = tf.sigmoid(tf.matmul(xt, self.wo) + self.bo)\n",
    "                cht = tf.tanh(   tf.matmul(xt, self.wc) + self.bc)\n",
    "                ct  = it * cht\n",
    "                ht  = ot * tf.tanh(ct)\n",
    "\n",
    "            else:\n",
    "                xt  = x[:, 0, :]\n",
    "                ft  = tf.sigmoid(tf.matmul(xt, self.wf) + self.bf)\n",
    "                it  = tf.sigmoid(tf.matmul(xt, self.wi) + self.bi)\n",
    "                ot  = tf.sigmoid(tf.matmul(xt, self.wo) + self.bo)\n",
    "                cht = tf.tanh(  tf.matmul(xt, self.wc) + self.bc)\n",
    "                ct  = ft * ct + it * cht\n",
    "                ht  = ot * tf.tanh(ct)\n",
    "                \n",
    "            sequence_outputs.append(ht)\n",
    "            \n",
    "        sequence_outputs = tf.stack(sequence_outputs)\n",
    "        sequence_outputs = tf.transpose(sequence_outputs, (1, 0, 2))\n",
    "        if self.return_sequence:\n",
    "            return sequence_outputs\n",
    "        return sequence_outputs[:, -1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 模拟数据观察自定义LSTM层的输出结果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.random.uniform((batch_size, sequence_length, input_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm = CustomLSTM(output_size=output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4, 20), dtype=float32, numpy=\n",
       "array([[-1.13457926e-01, -1.16072342e-01,  1.11910909e-01,\n",
       "        -7.60515332e-02,  5.98283000e-02, -7.51171052e-01,\n",
       "         2.45601207e-01,  1.67988434e-01, -2.49476284e-01,\n",
       "         1.23574570e-01, -1.69230461e-01,  2.44344841e-03,\n",
       "         2.81893879e-01, -1.09449737e-01,  5.97361065e-02,\n",
       "        -5.30856311e-01, -3.31262834e-02, -8.70979056e-02,\n",
       "        -3.75998281e-02,  1.13871396e-01],\n",
       "       [-3.98984402e-01, -2.50022531e-01,  3.39957178e-01,\n",
       "        -7.99013376e-02,  1.78711563e-01, -7.31003881e-01,\n",
       "         1.55839369e-01, -7.69722238e-02, -4.26059775e-02,\n",
       "        -2.04587296e-01, -1.92697451e-01,  1.14462167e-01,\n",
       "         2.89757639e-01, -4.26560223e-01,  2.42148545e-02,\n",
       "        -3.62793118e-01, -1.44181341e-01, -5.50301820e-02,\n",
       "        -2.69002914e-01, -6.95905909e-02],\n",
       "       [-1.25852779e-01, -2.03309968e-01,  1.47665858e-01,\n",
       "        -5.91915734e-02,  3.53709096e-03, -6.62378013e-01,\n",
       "         1.45682007e-01,  1.52762264e-01, -1.74808758e-03,\n",
       "         2.14426830e-01, -2.03656420e-01,  1.57856628e-01,\n",
       "         1.47408038e-01, -3.30268711e-01,  2.88306653e-01,\n",
       "        -4.25408900e-01, -1.44751176e-01, -5.73085658e-02,\n",
       "        -3.41587031e-04, -2.24666744e-01],\n",
       "       [-2.88401753e-01, -4.02334780e-02,  2.61044323e-01,\n",
       "        -1.57290176e-01,  2.80911792e-02, -6.23378396e-01,\n",
       "         1.97507948e-01, -1.26765957e-02, -1.74736887e-01,\n",
       "        -2.19738055e-02, -2.61798441e-01, -9.51701477e-02,\n",
       "         1.56538814e-01, -2.05456793e-01, -1.32791713e-01,\n",
       "        -3.97805929e-01, -5.91387926e-03,  4.65692841e-02,\n",
       "        -3.30106884e-01,  3.53776366e-01]], dtype=float32)>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用自定义的LSTM层使用随机数据进行训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    CustomLSTM(output_size=32), \n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_batch = tf.random.uniform((batch_size, sequence_length, input_size))\n",
    "y_batch = tf.random.uniform((batch_size,), maxval=2, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 5, 30])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(4,), dtype=int32, numpy=array([0, 1, 0, 1], dtype=int32)>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['custom_lstm_1/uf:0', 'custom_lstm_1/ui:0', 'custom_lstm_1/uo:0', 'custom_lstm_1/uc:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['custom_lstm_1/uf:0', 'custom_lstm_1/ui:0', 'custom_lstm_1/uo:0', 'custom_lstm_1/uc:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['custom_lstm_1/uf:0', 'custom_lstm_1/ui:0', 'custom_lstm_1/uo:0', 'custom_lstm_1/uc:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['custom_lstm_1/uf:0', 'custom_lstm_1/ui:0', 'custom_lstm_1/uo:0', 'custom_lstm_1/uc:0'] when minimizing the loss.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.720816969871521"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train_on_batch(x_batch, y_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = tf.random.uniform((batch_size * 1000, sequence_length, input_size))\n",
    "y_data = tf.random.uniform((batch_size * 1000,), maxval=2, dtype=tf.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6990\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa1861d6390>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_data, y_data, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6939\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa18d48c550>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_data, y_data, batch_size=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 2s 2ms/step - loss: 0.6930\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa18d4b2710>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_data, y_data, batch_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用自定义LSTM层对文本数据集进行实战"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from zh_dataset_inews import title_train, label_train, content_train, title_test, label_test, content_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "周六晚到卖场听夜场摇滚 1\n",
      "北京老教授泄露，持有山河药辅节后下跌公告，速速看看！！！ 1\n",
      "张滩镇积极开展基干民兵训练活动 0\n",
      "俩小伙无证骑摩托，未成年还试图闯卡！ 2\n",
      "不好意思，你不配做深圳人!_搜狐汽车_搜狐网 2\n",
      "蔡英文元旦升旗遇抗议 民众：枪毙蔡英文 2\n",
      "巢湖市绞吸机械清淤公司重在回访-照明器材项目合作–光波网 1\n",
      "出租屋半年被偷8次：整栋楼共用一个锁芯 2\n",
      "从林芝到拉萨，还可以这样玩! 1\n",
      "为何说奇瑞是技术达人? 看了“雄狮”你就懂了 1\n"
     ]
    }
   ],
   "source": [
    "for x, y in zip(title_train[:10], label_train[:10]):\n",
    "    print(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /var/folders/w2/n3x0x93n5klgjv3j05dp2wqc0000gp/T/jieba.cache\n",
      "Loading model cost 1.064 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    }
   ],
   "source": [
    "title_train_cut = [' '.join(jieba.cut(x, cut_all=False)) for x in title_train]\n",
    "title_test_cut  = [' '.join(jieba.cut(x, cut_all=False)) for x in title_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5355"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(title_train_cut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['周六 晚到 卖场 听 夜场 摇滚',\n",
       " '北京 老 教授 泄露 ， 持有 山河 药辅 节后 下跌 公告 ， 速速 看看 ！ ！ ！',\n",
       " '张滩 镇 积极开展 基干民兵 训练 活动',\n",
       " '俩 小伙 无证 骑 摩托 ， 未成年 还 试图 闯卡 ！',\n",
       " '不好意思 ， 你 不配 做 深圳 人 ! _ 搜狐 汽车 _ 搜狐网',\n",
       " '蔡 英文 元旦 升旗 遇 抗议   民众 ： 枪毙 蔡 英文',\n",
       " '巢湖市 绞吸 机械 清淤 公司 重在 回访 - 照明 器材 项目 合作 – 光波 网',\n",
       " '出租屋 半年 被 偷 8 次 ： 整栋 楼 共用 一个 锁 芯',\n",
       " '从 林芝 到 拉萨 ， 还 可以 这样 玩 !',\n",
       " '为何 说 奇瑞 是 技术 达 人 ?   看 了 “ 雄狮 ” 你 就 懂 了']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_train_cut[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vector = tf.keras.layers.experimental.preprocessing.TextVectorization()\n",
    "# 学习词表\n",
    "text_vector.adapt(title_train_cut)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(text_vector.get_vocabulary())\n",
    "embedding_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过 text_vector('你 好') 和  text_vector('你好')对比发现，这里没有进行分词   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int64, numpy=array([18, 98])>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vector('你 好')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1,), dtype=int64, numpy=array([2896])>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_vector('你好')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "title_train_text_vector = text_vector(title_train_cut) # [text_vector(x) for x in title_train_cut]\n",
    "title_test_text_vector  = text_vector(title_test_cut) # [text_vector(x) for x in title_test_cut]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input_dataset = tf.data.Dataset.from_tensor_slices(title_train_text_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 44])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "title_train_text_vector[:10].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = tf.convert_to_tensor(title_train_text_vector)\n",
    "x_test  = tf.convert_to_tensor(title_test_text_vector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.framework.ops.EagerTensor"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.convert_to_tensor(label_train)\n",
    "y_test  = tf.convert_to_tensor(label_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_embedding_layer = tf.keras.layers.Embedding(vocab_size, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5355, 44])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_embedding = test_embedding_layer(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5355, 44, 128])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_text = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim),\n",
    "    CustomLSTM(output_size=32), \n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model_text.compile(\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5355, 44])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5355])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, None, 128)         2328064   \n",
      "_________________________________________________________________\n",
      "custom_lstm_3 (CustomLSTM)   (None, 32)                20608     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 99        \n",
      "=================================================================\n",
      "Total params: 2,348,771\n",
      "Trainable params: 2,348,771\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_text.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['custom_lstm_3/uf:0', 'custom_lstm_3/ui:0', 'custom_lstm_3/uo:0', 'custom_lstm_3/uc:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['custom_lstm_3/uf:0', 'custom_lstm_3/ui:0', 'custom_lstm_3/uo:0', 'custom_lstm_3/uc:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['custom_lstm_3/uf:0', 'custom_lstm_3/ui:0', 'custom_lstm_3/uo:0', 'custom_lstm_3/uc:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['custom_lstm_3/uf:0', 'custom_lstm_3/ui:0', 'custom_lstm_3/uo:0', 'custom_lstm_3/uc:0'] when minimizing the loss.\n",
      "151/151 [==============================] - 6s 39ms/step - loss: 0.9489 - accuracy: 0.5358 - val_loss: 0.9400 - val_accuracy: 0.5317\n",
      "Epoch 2/20\n",
      "151/151 [==============================] - 6s 37ms/step - loss: 0.7199 - accuracy: 0.7551 - val_loss: 1.0305 - val_accuracy: 0.5336\n",
      "Epoch 3/20\n",
      "151/151 [==============================] - 7s 48ms/step - loss: 0.4769 - accuracy: 0.8016 - val_loss: 1.0893 - val_accuracy: 0.5205\n",
      "Epoch 4/20\n",
      "151/151 [==============================] - 7s 45ms/step - loss: 0.3915 - accuracy: 0.8226 - val_loss: 1.1321 - val_accuracy: 0.5131\n",
      "Epoch 5/20\n",
      "151/151 [==============================] - 7s 44ms/step - loss: 0.3700 - accuracy: 0.8193 - val_loss: 1.1392 - val_accuracy: 0.5205\n",
      "Epoch 6/20\n",
      "151/151 [==============================] - 6s 39ms/step - loss: 0.3535 - accuracy: 0.8228 - val_loss: 1.1628 - val_accuracy: 0.5485\n",
      "Epoch 7/20\n",
      "151/151 [==============================] - 6s 40ms/step - loss: 0.3464 - accuracy: 0.8178 - val_loss: 1.1769 - val_accuracy: 0.5354\n",
      "Epoch 8/20\n",
      "151/151 [==============================] - 6s 36ms/step - loss: 0.3367 - accuracy: 0.8247 - val_loss: 1.1979 - val_accuracy: 0.5056\n",
      "Epoch 9/20\n",
      "151/151 [==============================] - 5s 35ms/step - loss: 0.3298 - accuracy: 0.8253 - val_loss: 1.2210 - val_accuracy: 0.5280\n",
      "Epoch 10/20\n",
      "151/151 [==============================] - 4s 29ms/step - loss: 0.3254 - accuracy: 0.8263 - val_loss: 1.2376 - val_accuracy: 0.5354\n",
      "Epoch 11/20\n",
      "151/151 [==============================] - 7s 44ms/step - loss: 0.3211 - accuracy: 0.8276 - val_loss: 1.2549 - val_accuracy: 0.5466\n",
      "Epoch 12/20\n",
      "151/151 [==============================] - 7s 48ms/step - loss: 0.3166 - accuracy: 0.8276 - val_loss: 1.2778 - val_accuracy: 0.5280\n",
      "Epoch 13/20\n",
      "151/151 [==============================] - 6s 42ms/step - loss: 0.3133 - accuracy: 0.8330 - val_loss: 1.3031 - val_accuracy: 0.5317\n",
      "Epoch 14/20\n",
      "151/151 [==============================] - 6s 42ms/step - loss: 0.3094 - accuracy: 0.8300 - val_loss: 1.3110 - val_accuracy: 0.5336\n",
      "Epoch 15/20\n",
      "151/151 [==============================] - 7s 43ms/step - loss: 0.3071 - accuracy: 0.8357 - val_loss: 1.3228 - val_accuracy: 0.5336\n",
      "Epoch 16/20\n",
      "151/151 [==============================] - 6s 41ms/step - loss: 0.3051 - accuracy: 0.8344 - val_loss: 1.3505 - val_accuracy: 0.5336\n",
      "Epoch 17/20\n",
      "151/151 [==============================] - 6s 42ms/step - loss: 0.3040 - accuracy: 0.8344 - val_loss: 1.3683 - val_accuracy: 0.5243\n",
      "Epoch 18/20\n",
      "151/151 [==============================] - 6s 42ms/step - loss: 0.3019 - accuracy: 0.8379 - val_loss: 1.3956 - val_accuracy: 0.5373\n",
      "Epoch 19/20\n",
      "151/151 [==============================] - 7s 44ms/step - loss: 0.3006 - accuracy: 0.8419 - val_loss: 1.4036 - val_accuracy: 0.5504\n",
      "Epoch 20/20\n",
      "151/151 [==============================] - 6s 43ms/step - loss: 0.3004 - accuracy: 0.8359 - val_loss: 1.3992 - val_accuracy: 0.5485\n"
     ]
    }
   ],
   "source": [
    "history_model_text = model_text.fit(\n",
    "    x_train, y_train, \n",
    "    validation_split=0.1, \n",
    "    epochs=20\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_text_after_embedding = tf.keras.Sequential([\n",
    "    CustomLSTM(output_size=32), \n",
    "    tf.keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "\n",
    "model_text_after_embedding.compile(\n",
    "    loss = tf.keras.losses.SparseCategoricalCrossentropy(), \n",
    "    optimizer = tf.keras.optimizers.Adam(),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['custom_lstm_2/uf:0', 'custom_lstm_2/ui:0', 'custom_lstm_2/uo:0', 'custom_lstm_2/uc:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['custom_lstm_2/uf:0', 'custom_lstm_2/ui:0', 'custom_lstm_2/uo:0', 'custom_lstm_2/uc:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['custom_lstm_2/uf:0', 'custom_lstm_2/ui:0', 'custom_lstm_2/uo:0', 'custom_lstm_2/uc:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['custom_lstm_2/uf:0', 'custom_lstm_2/ui:0', 'custom_lstm_2/uo:0', 'custom_lstm_2/uc:0'] when minimizing the loss.\n",
      "38/38 [==============================] - 1s 23ms/step - loss: 1.0770 - accuracy: 0.3787 - val_loss: 1.0405 - val_accuracy: 0.4925\n",
      "Epoch 2/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 1.0035 - accuracy: 0.5150 - val_loss: 0.9986 - val_accuracy: 0.5037\n",
      "Epoch 3/20\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.9651 - accuracy: 0.5155 - val_loss: 0.9821 - val_accuracy: 0.5056\n",
      "Epoch 4/20\n",
      "38/38 [==============================] - 0s 7ms/step - loss: 0.9479 - accuracy: 0.5150 - val_loss: 0.9773 - val_accuracy: 0.5056\n",
      "Epoch 5/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.9402 - accuracy: 0.5198 - val_loss: 0.9765 - val_accuracy: 0.5093\n",
      "Epoch 6/20\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.9362 - accuracy: 0.5254 - val_loss: 0.9762 - val_accuracy: 0.5056\n",
      "Epoch 7/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.9329 - accuracy: 0.5271 - val_loss: 0.9754 - val_accuracy: 0.4981\n",
      "Epoch 8/20\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.9298 - accuracy: 0.5358 - val_loss: 0.9735 - val_accuracy: 0.5056\n",
      "Epoch 9/20\n",
      "38/38 [==============================] - 1s 14ms/step - loss: 0.9269 - accuracy: 0.5389 - val_loss: 0.9725 - val_accuracy: 0.5112\n",
      "Epoch 10/20\n",
      "38/38 [==============================] - 0s 11ms/step - loss: 0.9240 - accuracy: 0.5443 - val_loss: 0.9712 - val_accuracy: 0.5112\n",
      "Epoch 11/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.9213 - accuracy: 0.5412 - val_loss: 0.9701 - val_accuracy: 0.5075\n",
      "Epoch 12/20\n",
      "38/38 [==============================] - 0s 8ms/step - loss: 0.9190 - accuracy: 0.5435 - val_loss: 0.9700 - val_accuracy: 0.5075\n",
      "Epoch 13/20\n",
      "38/38 [==============================] - 0s 6ms/step - loss: 0.9169 - accuracy: 0.5418 - val_loss: 0.9698 - val_accuracy: 0.5112\n",
      "Epoch 14/20\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.9149 - accuracy: 0.5443 - val_loss: 0.9690 - val_accuracy: 0.5131\n",
      "Epoch 15/20\n",
      "38/38 [==============================] - 0s 13ms/step - loss: 0.9131 - accuracy: 0.5449 - val_loss: 0.9690 - val_accuracy: 0.5205\n",
      "Epoch 16/20\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.9116 - accuracy: 0.5447 - val_loss: 0.9694 - val_accuracy: 0.5056\n",
      "Epoch 17/20\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.9102 - accuracy: 0.5464 - val_loss: 0.9693 - val_accuracy: 0.5093\n",
      "Epoch 18/20\n",
      "38/38 [==============================] - 0s 9ms/step - loss: 0.9089 - accuracy: 0.5499 - val_loss: 0.9693 - val_accuracy: 0.5112\n",
      "Epoch 19/20\n",
      "38/38 [==============================] - 0s 12ms/step - loss: 0.9084 - accuracy: 0.5462 - val_loss: 0.9703 - val_accuracy: 0.5131\n",
      "Epoch 20/20\n",
      "38/38 [==============================] - 1s 15ms/step - loss: 0.9075 - accuracy: 0.5505 - val_loss: 0.9694 - val_accuracy: 0.5131\n"
     ]
    }
   ],
   "source": [
    "history_model_text_after_embedding = model_text_after_embedding.fit(\n",
    "    x_train_embedding, y_train, \n",
    "    validation_split=0.1, \n",
    "    epochs=20,\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4, 44, 128])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_embedding_batch = x_train_embedding[:4, :, :]\n",
    "x_train_embedding_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([4])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_embedding_batch = y_train[:4]\n",
    "y_train_embedding_batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Gradients do not exist for variables ['custom_lstm_2/uf:0', 'custom_lstm_2/ui:0', 'custom_lstm_2/uo:0', 'custom_lstm_2/uc:0'] when minimizing the loss.\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['custom_lstm_2/uf:0', 'custom_lstm_2/ui:0', 'custom_lstm_2/uo:0', 'custom_lstm_2/uc:0'] when minimizing the loss.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9686881899833679, 0.5148147940635681]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_text_after_embedding.train_on_batch(x_train_embedding_batch, y_train_embedding_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5355, 44, 128])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "536/536 [==============================] - 2s 3ms/step - loss: 0.9158 - accuracy: 0.5414\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa1118b1f10>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_text_after_embedding.fit(x_train_embedding, y_train, batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([5355, 44, 128])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_embedding.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_text.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_pred = model_text.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_test_pred.argmax(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_check = pd.DataFrame({'title_test': title_test, 'label_test': label_test, 'y_test_pred': y_test_pred.argmax(axis=1)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_check.query('label_test != y_test_pred')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf2",
   "language": "python",
   "name": "tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
